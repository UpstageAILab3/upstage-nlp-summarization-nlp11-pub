{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNq_LylZa1ug"
   },
   "source": [
    "## ⚙️ 데이터 및 환경설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjCiuI_V4glr"
   },
   "source": [
    "### 1) 필요한 라이브러리 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYqDF_-r2ToB"
   },
   "source": [
    "- 필요한 라이브러리를 설치한 후 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zbZ7SU9P2TYN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from rouge import Rouge\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration, T5Config\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "import wandb\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "from zoneinfo import ZoneInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Qq46k6_CNQn"
   },
   "source": [
    "### 2) Config file 만들기 (선택)\n",
    "- 모델 생성에 필요한 다양한 매개변수 정보를 저장할 수 있습니다.  \n",
    "  따라서, 코드 상에서 모델의 매개변수를 설정할 수도 있지만 독립적인 매개변수 정보 파일을 생성하여 관리할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0903-104953'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_time = datetime.fromtimestamp(time.time(), tz=ZoneInfo(\"Asia/Seoul\")).strftime(\"%m%d-%H%M%S\")\n",
    "train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197,
     "referenced_widgets": [
      "e920dbc173c045d1a32143349f1dff8e",
      "58c794fb7ce543a39fdf66d757f6eeab",
      "8a6464a355f7464c989033965d418a8a",
      "3645438ace1f4596a8dbc157b48c1521",
      "58001a60eacc44d5b38a68648adccde4",
      "6f5fde5b0ac840a18bd5cc380e564ff6",
      "45187decb58b4ad39ad532259c6277e5",
      "2307c6dcbe0141acb5e61baae19cade7",
      "4747b668e2fa4ab58a449446f80030f5",
      "14f6c91d6c634379b498586c51e606e0",
      "08d05bc20a96432badd459e1ffaf868e",
      "5dfcf310ca9e4e2794076098a5d69cea",
      "3c284a826f6843f6aa47eacad478ac30",
      "6caedd60c6b747469c82930be1f95d6d",
      "64f2218f899d446393cfea44f206f0a6",
      "d068f541df3f438dbd5138863e64b2f2",
      "affff1d8a89e4c14955d1b2aa39ff1ab",
      "13651c09564a4337b8274c1cb436faa5",
      "3bcd6b6b956347b29e1efa20a1d00542",
      "2fd3d7bbcd6948d8904d33001f95ea03",
      "d22fbc2c5dbf422399e496c9b500025a",
      "775d8bbeceac4e2da4f21ab6235c89ed",
      "de1a3f7701c243839fe03b930a9b9e30",
      "ebc22683058a4f229c5588e52fc93536",
      "52095cc7087243ac916055e569fd22f3",
      "a15af9e8158f4903b9189f3d322a5ef3",
      "21d2e54b5a0a4f79973a512105da43eb",
      "083ea69907bb48d4a8fff919bac51aad",
      "2a190bda0b72407e9a953cd2104dd3b2",
      "c18f0e3bc35e44d9915c3f84cd282a26",
      "3a04e871b74b45d7bf02fd33bb103577",
      "ac00d6c2cf974b33a628acb3f1471316",
      "285007b45236478ca147c6df752c8da4"
     ]
    },
    "id": "gZOE9TInCQHJ",
    "outputId": "8ce58487-6199-408c-cb37-49af1e218bc2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# config 설정에 tokenizer 모듈이 사용되므로 미리 tokenizer를 정의해줍니다.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"eenzeenee/t5-base-korean-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5vsACJI7CVb8"
   },
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"./data/\", # 모델 생성에 필요한 데이터 경로를 사용자 환경에 맞게 지정합니다.\n",
    "        \"model_name\": \"eenzeenee/t5-base-korean-summarization\", # 불러올 모델의 이름을 사용자 환경에 맞게 지정할 수 있습니다.\n",
    "        \"output_dir\": f\"./model/{train_time}/\" # 모델의 최종 출력 값을 저장할 경로를 설정합니다.\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 300,\n",
    "        \"decoder_max_len\": 50,\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        # 특정 단어들이 분해되어 tokenization이 수행되지 않도록 special_tokens을 지정해줍니다.\n",
    "        \"special_tokens\": ['#Address#', '#CarNumber#', '#CardNumber#', '#DateOfBirth#', '#Email#', '#PassportNumber#', '#Person1#', '#Person2#', '#Person3#', '#Person4#', '#Person5#', '#Person6#', '#Person7#','#PhoneNumber#', '#SSN#']\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"overwrite_output_dir\": False,\n",
    "        \"num_train_epochs\": 20,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"per_device_train_batch_size\": 32,\n",
    "        \"per_device_eval_batch_size\": 32,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"lr_scheduler_type\": 'cosine',\n",
    "        \"optim\": 'adamw_torch',\n",
    "        \"gradient_accumulation_steps\": 2,\n",
    "        \"evaluation_strategy\": 'epoch',\n",
    "        \"save_strategy\": 'epoch',\n",
    "        \"save_total_limit\": 5,\n",
    "        \"fp16\": True,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"seed\": 42,\n",
    "        \"logging_dir\": \"./logs\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 100,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"early_stopping_patience\": 3,\n",
    "        \"early_stopping_threshold\": 0.001,\n",
    "        \"report_to\": \"wandb\" # (선택) wandb를 사용할 때 설정합니다.\n",
    "    },\n",
    "    # (선택) wandb 홈페이지에 가입하여 얻은 정보를 기반으로 작성합니다.\n",
    "    \"wandb\": {\n",
    "        \"project\": \"project_name\",\n",
    "        \"name\": \"run_name\"\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"result_path\": \"./prediction/\",\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"early_stopping\": False,\n",
    "        \"generate_max_length\": 100,\n",
    "        \"num_beams\": 4,\n",
    "        \"batch_size\" : 32,\n",
    "        # 정확한 모델 평가를 위해 제거할 불필요한 생성 토큰들을 정의합니다.\n",
    "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cm7ob25lHBkR"
   },
   "source": [
    "- 참고✅    \n",
    ": wandb 라이브러리를 사용하기 위해선 entity, project, name를 지정해주어야 합니다. wandb 홈페이지에 가입한 후 얻은 정보를 입력하여 작동할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "REJybO5UCabF"
   },
   "outputs": [],
   "source": [
    "# 모델의 구성 정보를 YAML 파일로 저장합니다.\n",
    "config_path = \"./config.yaml\"\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObEASD6Wj6pl"
   },
   "source": [
    "### 3) Configuration 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUBm_6RqlYpV",
    "outputId": "4b1c8c44-c6a9-40f1-adbd-72d48f0c983b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': {'data_path': './data/',\n",
      "             'model_name': 'eenzeenee/t5-base-korean-summarization',\n",
      "             'output_dir': './model/0903-104953/'},\n",
      " 'inference': {'batch_size': 32,\n",
      "               'early_stopping': False,\n",
      "               'generate_max_length': 100,\n",
      "               'no_repeat_ngram_size': 2,\n",
      "               'num_beams': 4,\n",
      "               'remove_tokens': ['<usr>', 'None', '</s>', '<pad>'],\n",
      "               'result_path': './prediction/'},\n",
      " 'tokenizer': {'bos_token': 'None',\n",
      "               'decoder_max_len': 50,\n",
      "               'encoder_max_len': 300,\n",
      "               'eos_token': '</s>',\n",
      "               'special_tokens': ['#Address#',\n",
      "                                  '#CarNumber#',\n",
      "                                  '#CardNumber#',\n",
      "                                  '#DateOfBirth#',\n",
      "                                  '#Email#',\n",
      "                                  '#PassportNumber#',\n",
      "                                  '#Person1#',\n",
      "                                  '#Person2#',\n",
      "                                  '#Person3#',\n",
      "                                  '#Person4#',\n",
      "                                  '#Person5#',\n",
      "                                  '#Person6#',\n",
      "                                  '#Person7#',\n",
      "                                  '#PhoneNumber#',\n",
      "                                  '#SSN#']},\n",
      " 'training': {'do_eval': True,\n",
      "              'do_train': True,\n",
      "              'early_stopping_patience': 3,\n",
      "              'early_stopping_threshold': 0.001,\n",
      "              'evaluation_strategy': 'epoch',\n",
      "              'fp16': True,\n",
      "              'generation_max_length': 100,\n",
      "              'gradient_accumulation_steps': 2,\n",
      "              'learning_rate': 1e-05,\n",
      "              'load_best_model_at_end': True,\n",
      "              'logging_dir': './logs',\n",
      "              'logging_strategy': 'epoch',\n",
      "              'lr_scheduler_type': 'cosine',\n",
      "              'num_train_epochs': 20,\n",
      "              'optim': 'adamw_torch',\n",
      "              'overwrite_output_dir': False,\n",
      "              'per_device_eval_batch_size': 32,\n",
      "              'per_device_train_batch_size': 32,\n",
      "              'predict_with_generate': True,\n",
      "              'report_to': 'wandb',\n",
      "              'save_strategy': 'epoch',\n",
      "              'save_total_limit': 5,\n",
      "              'seed': 42,\n",
      "              'warmup_ratio': 0.1,\n",
      "              'weight_decay': 0.01},\n",
      " 'wandb': {'name': 'run_name', 'project': 'project_name'}}\n"
     ]
    }
   ],
   "source": [
    "# 저장된 config 파일을 불러옵니다.\n",
    "config_path = \"./config.yaml\"\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "\n",
    "# 불러온 config 파일의 전체 내용을 확인합니다.\n",
    "pprint(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRSbKEVslhwO",
    "outputId": "40ba5c67-574e-4f86-cbac-13e9f01c588a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_path': './data/',\n",
       " 'model_name': 'eenzeenee/t5-base-korean-summarization',\n",
       " 'output_dir': './model/0903-104953/'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실험에 쓰일 데이터의 경로, 사용될 모델, 모델의 최종 출력 결과를 저장할 경로에 대해 확인합니다.\n",
    "loaded_config['general']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1pvFmIOqljv1",
    "outputId": "958c9b06-90de-4872-b2fb-cf739a655b4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': 'None',\n",
       " 'decoder_max_len': 50,\n",
       " 'encoder_max_len': 300,\n",
       " 'eos_token': '</s>',\n",
       " 'special_tokens': ['#Address#',\n",
       "  '#CarNumber#',\n",
       "  '#CardNumber#',\n",
       "  '#DateOfBirth#',\n",
       "  '#Email#',\n",
       "  '#PassportNumber#',\n",
       "  '#Person1#',\n",
       "  '#Person2#',\n",
       "  '#Person3#',\n",
       "  '#Person4#',\n",
       "  '#Person5#',\n",
       "  '#Person6#',\n",
       "  '#Person7#',\n",
       "  '#PhoneNumber#',\n",
       "  '#SSN#']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리를 하기 위해 tokenization 과정에서 필요한 정보들을 확인합니다.\n",
    "loaded_config['tokenizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEvwCIBVll-h",
    "outputId": "ca010ac3-05be-4983-d665-2a653f0ced0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'do_eval': True,\n",
       " 'do_train': True,\n",
       " 'early_stopping_patience': 3,\n",
       " 'early_stopping_threshold': 0.001,\n",
       " 'evaluation_strategy': 'epoch',\n",
       " 'fp16': True,\n",
       " 'generation_max_length': 100,\n",
       " 'gradient_accumulation_steps': 2,\n",
       " 'learning_rate': 1e-05,\n",
       " 'load_best_model_at_end': True,\n",
       " 'logging_dir': './logs',\n",
       " 'logging_strategy': 'epoch',\n",
       " 'lr_scheduler_type': 'cosine',\n",
       " 'num_train_epochs': 20,\n",
       " 'optim': 'adamw_torch',\n",
       " 'overwrite_output_dir': False,\n",
       " 'per_device_eval_batch_size': 32,\n",
       " 'per_device_train_batch_size': 32,\n",
       " 'predict_with_generate': True,\n",
       " 'report_to': 'wandb',\n",
       " 'save_strategy': 'epoch',\n",
       " 'save_total_limit': 5,\n",
       " 'seed': 42,\n",
       " 'warmup_ratio': 0.1,\n",
       " 'weight_decay': 0.01}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델이 훈련 시 적용될 매개변수를 확인합니다.\n",
    "loaded_config['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xhqHf1njlnyg",
    "outputId": "be9519c6-118b-4e4f-ea11-4bcca0ac42bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'run_name', 'project': 'project_name'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 과정에 대한 정보를 제공해주는 wandb 설정 내용을 확인합니다.\n",
    "loaded_config['wandb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (선택) 이곳에 사용자가 사용할 wandb config 설정\n",
    "loaded_config['wandb']['name'] = train_time\n",
    "loaded_config['wandb']['project'] = \"dialogue-summarization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fm4gxPRVlppj",
    "outputId": "1342aa36-3934-4f73-c912-e7d35fe6df06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'early_stopping': False,\n",
       " 'generate_max_length': 100,\n",
       " 'no_repeat_ngram_size': 2,\n",
       " 'num_beams': 4,\n",
       " 'remove_tokens': ['<usr>', 'None', '</s>', '<pad>'],\n",
       " 'result_path': './prediction/'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델이 최종 결과를 출력하기 위한 매개변수 정보를 확인합니다.\n",
    "loaded_config['inference']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2zt0b-8ogCL"
   },
   "source": [
    "### 4) 데이터 불러와서 확인해보기\n",
    "- 실험에서 쓰일 데이터를 load하여 데이터의 구조와 내용을 살펴보겠습니다.\n",
    "- Train, dev, test 순서대로 12457, 499, 250개 씩 데이터가 구성되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "QFHIE2G04y-K",
    "outputId": "19312d21-f5bf-495f-c626-cc17b82024a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12452</th>\n",
       "      <td>train_12455</td>\n",
       "      <td>#Person1#: 실례합니다. 맨체스터 출신의 그린 씨이신가요?\\n#Person2...</td>\n",
       "      <td>탄 링은 흰머리와 수염으로 쉽게 인식되는 그린 씨를 만나 호텔로 데려갈 예정입니다....</td>\n",
       "      <td>누군가를 태우다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12453</th>\n",
       "      <td>train_12456</td>\n",
       "      <td>#Person1#: 이윙 씨가 우리가 컨퍼런스 센터에 오후 4시에 도착해야 한다고 ...</td>\n",
       "      <td>#Person1#과 #Person2#는 이윙 씨가 늦지 않도록 요청했기 때문에 컨퍼...</td>\n",
       "      <td>컨퍼런스 센터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12454</th>\n",
       "      <td>train_12457</td>\n",
       "      <td>#Person1#: 오늘 어떻게 도와드릴까요?\\n#Person2#: 차를 빌리고 싶...</td>\n",
       "      <td>#Person2#는 #Person1#의 도움으로 5일 동안 소형 차를 빌립니다.</td>\n",
       "      <td>차 렌트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12455</th>\n",
       "      <td>train_12458</td>\n",
       "      <td>#Person1#: 오늘 좀 행복해 보이지 않아. 무슨 일 있어?\\n#Person2...</td>\n",
       "      <td>#Person2#의 엄마가 일자리를 잃었다. #Person2#는 엄마가 우울해하지 ...</td>\n",
       "      <td>실직</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12456</th>\n",
       "      <td>train_12459</td>\n",
       "      <td>#Person1#: 엄마, 다음 토요일에 이 삼촌네 가족을 방문하기 위해 비행기를 ...</td>\n",
       "      <td>#Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...</td>\n",
       "      <td>짐 싸기</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fname                                           dialogue  \\\n",
       "12452  train_12455  #Person1#: 실례합니다. 맨체스터 출신의 그린 씨이신가요?\\n#Person2...   \n",
       "12453  train_12456  #Person1#: 이윙 씨가 우리가 컨퍼런스 센터에 오후 4시에 도착해야 한다고 ...   \n",
       "12454  train_12457  #Person1#: 오늘 어떻게 도와드릴까요?\\n#Person2#: 차를 빌리고 싶...   \n",
       "12455  train_12458  #Person1#: 오늘 좀 행복해 보이지 않아. 무슨 일 있어?\\n#Person2...   \n",
       "12456  train_12459  #Person1#: 엄마, 다음 토요일에 이 삼촌네 가족을 방문하기 위해 비행기를 ...   \n",
       "\n",
       "                                                 summary     topic  \n",
       "12452  탄 링은 흰머리와 수염으로 쉽게 인식되는 그린 씨를 만나 호텔로 데려갈 예정입니다....  누군가를 태우다  \n",
       "12453  #Person1#과 #Person2#는 이윙 씨가 늦지 않도록 요청했기 때문에 컨퍼...   컨퍼런스 센터  \n",
       "12454       #Person2#는 #Person1#의 도움으로 5일 동안 소형 차를 빌립니다.      차 렌트  \n",
       "12455  #Person2#의 엄마가 일자리를 잃었다. #Person2#는 엄마가 우울해하지 ...        실직  \n",
       "12456  #Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...      짐 싸기  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config에 저장된 데이터 경로를 통해 train과 validation data를 불러옵니다.\n",
    "data_path = loaded_config['general']['data_path']\n",
    "\n",
    "# train data의 구조와 내용을 확인합니다.\n",
    "train_df = pd.read_csv(os.path.join(data_path,'train.csv'))\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "FAGaYvNZ09Sq",
    "outputId": "bf8bf286-19e7-469d-ffae-41e6ad795ae6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>dev_495</td>\n",
       "      <td>#Person1#: 이제 새해가 되어서 새로운 시작을 하려고 결심했어. \\r\\n#P...</td>\n",
       "      <td>#Person1#은 새해에 금연을 하고 커밍아웃하기로 결정했습니다. #Person2...</td>\n",
       "      <td>새해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>dev_496</td>\n",
       "      <td>#Person1#: 너, 조랑 결혼했지? \\r\\n#Person2#: 조? 무슨 말인...</td>\n",
       "      <td>#Person1#은 #Person2#가 조와 결혼했다고 생각했다. #Person2#...</td>\n",
       "      <td>사랑에 빠지다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>dev_497</td>\n",
       "      <td>#Person1#: 무엇을 도와드릴까요, 부인?\\r\\n#Person2#: 몇 주 동...</td>\n",
       "      <td>#Person2#의 차에서 이상한 소리가 납니다. #Person1#는 브레이크를 교...</td>\n",
       "      <td>소음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>dev_498</td>\n",
       "      <td>#Person1#: 안녕하세요, 아마존 고객 서비스입니다. 무엇을 도와드릴까요?\\n...</td>\n",
       "      <td>#Person2#님이 아마존 고객 서비스에 전화하여 아마존에서 받은 책에 한 페이지...</td>\n",
       "      <td>빠진 페이지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>dev_499</td>\n",
       "      <td>#Person1#: 여름이 다 되어간다는 게 믿기지 않아.\\r\\n#Person2#:...</td>\n",
       "      <td>#Person2#는 #Person1#에게 여름 휴가 동안 파티를 도와주는 회사에서 ...</td>\n",
       "      <td>여름 휴가</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fname                                           dialogue  \\\n",
       "494  dev_495  #Person1#: 이제 새해가 되어서 새로운 시작을 하려고 결심했어. \\r\\n#P...   \n",
       "495  dev_496  #Person1#: 너, 조랑 결혼했지? \\r\\n#Person2#: 조? 무슨 말인...   \n",
       "496  dev_497  #Person1#: 무엇을 도와드릴까요, 부인?\\r\\n#Person2#: 몇 주 동...   \n",
       "497  dev_498  #Person1#: 안녕하세요, 아마존 고객 서비스입니다. 무엇을 도와드릴까요?\\n...   \n",
       "498  dev_499  #Person1#: 여름이 다 되어간다는 게 믿기지 않아.\\r\\n#Person2#:...   \n",
       "\n",
       "                                               summary    topic  \n",
       "494  #Person1#은 새해에 금연을 하고 커밍아웃하기로 결정했습니다. #Person2...       새해  \n",
       "495  #Person1#은 #Person2#가 조와 결혼했다고 생각했다. #Person2#...  사랑에 빠지다  \n",
       "496  #Person2#의 차에서 이상한 소리가 납니다. #Person1#는 브레이크를 교...       소음  \n",
       "497  #Person2#님이 아마존 고객 서비스에 전화하여 아마존에서 받은 책에 한 페이지...   빠진 페이지  \n",
       "498  #Person2#는 #Person1#에게 여름 휴가 동안 파티를 도와주는 회사에서 ...    여름 휴가  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation data의 구조와 내용을 확인합니다.\n",
    "val_df = pd.read_csv(os.path.join(data_path,'dev.csv'))\n",
    "val_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IIaIrpH4kWo"
   },
   "source": [
    "## 1. 데이터 가공 및 데이터셋 클래스 구축\n",
    "- csv file 을 불러와서 encoder 와 decoder의 입력형태로 가공해줍니다.\n",
    "- 가공된 데이터를 torch dataset class 로 구축하여 모델에 입력가능한 형태로 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "oWPawUUflwHa"
   },
   "outputs": [],
   "source": [
    "# 데이터 전처리를 위한 클래스로, 데이터셋을 데이터프레임으로 변환하고 인코더와 디코더의 입력을 생성합니다.\n",
    "class Preprocess:\n",
    "    def __init__(self,\n",
    "            bos_token: str,\n",
    "            eos_token: str,\n",
    "        ) -> None:\n",
    "\n",
    "        self.bos_token = bos_token\n",
    "        self.eos_token = eos_token\n",
    "\n",
    "    @staticmethod\n",
    "    # 실험에 필요한 컬럼을 가져옵니다.\n",
    "    def make_set_as_df(file_path, is_train = True):\n",
    "        if is_train:\n",
    "            df = pd.read_csv(file_path)\n",
    "            train_df = df[['fname','dialogue','summary']]\n",
    "            return train_df\n",
    "        else:\n",
    "            df = pd.read_csv(file_path)\n",
    "            test_df = df[['fname','dialogue']]\n",
    "            return test_df\n",
    "\n",
    "    def make_input(self, dataset, is_test=False):\n",
    "        def process_dialogue(dialogue):\n",
    "            # 각 발화를 <s></s> 토큰으로 감싸기\n",
    "            structured_dialogue = \"\".join([f\"<s>{turn.strip()}</s>\" for turn in dialogue.split('\\n')])\n",
    "            return structured_dialogue\n",
    "\n",
    "        encoder_input = dataset['dialogue'].apply(process_dialogue)\n",
    "        \n",
    "        if is_test:\n",
    "            decoder_input = [self.bos_token] * len(dataset['dialogue'])\n",
    "            return encoder_input.tolist(), list(decoder_input)\n",
    "        else:\n",
    "            decoder_input = dataset['summary'].apply(lambda x: self.bos_token + str(x))\n",
    "            decoder_output = dataset['summary'].apply(lambda x: str(x) + self.eos_token)\n",
    "            return encoder_input.tolist(), decoder_input.tolist(), decoder_output.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6GDvodoF8sED"
   },
   "outputs": [],
   "source": [
    "# Train에 사용되는 Dataset 클래스를 정의합니다.\n",
    "class DatasetForTrain(Dataset):\n",
    "    def __init__(self, encoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}\n",
    "        item['labels'] = self.labels['input_ids'][idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Validation에 사용되는 Dataset 클래스를 정의합니다.\n",
    "class DatasetForVal(Dataset):\n",
    "    def __init__(self, encoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}\n",
    "        item['labels'] = self.labels['input_ids'][idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Test에 사용되는 Dataset 클래스를 정의합니다.\n",
    "class DatasetForInference(Dataset):\n",
    "    def __init__(self, encoder_input, test_id, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.test_id = test_id\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}\n",
    "        item['ID'] = self.test_id[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "hT9z4vvS2CCb"
   },
   "outputs": [],
   "source": [
    "# tokenization 과정까지 진행된 최종적으로 모델에 입력될 데이터를 출력합니다.\n",
    "def prepare_train_dataset(config, preprocessor, data_path, tokenizer):\n",
    "    train_file_path = os.path.join(data_path,'train.csv')\n",
    "    val_file_path = os.path.join(data_path,'dev.csv')\n",
    "\n",
    "    # train, validation에 대해 각각 데이터프레임을 구축합니다.\n",
    "    train_data = preprocessor.make_set_as_df(train_file_path)\n",
    "    val_data = preprocessor.make_set_as_df(val_file_path)\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'train_data:\\n {train_data[\"dialogue\"][0]}')\n",
    "    print(f'train_label:\\n {train_data[\"summary\"][0]}')\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'val_data:\\n {val_data[\"dialogue\"][0]}')\n",
    "    print(f'val_label:\\n {val_data[\"summary\"][0]}')\n",
    "\n",
    "    encoder_input_train , _, decoder_output_train = preprocessor.make_input(train_data)\n",
    "    encoder_input_val , _, decoder_output_val = preprocessor.make_input(val_data)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "\n",
    "    tokenized_encoder_inputs = tokenizer(encoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                            add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_ouputs = tokenizer(decoder_output_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    train_inputs_dataset = DatasetForTrain(tokenized_encoder_inputs, tokenized_decoder_ouputs, len(encoder_input_train))\n",
    "\n",
    "    val_tokenized_encoder_inputs = tokenizer(encoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_ouputs = tokenizer(decoder_output_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    val_inputs_dataset = DatasetForVal(val_tokenized_encoder_inputs, val_tokenized_decoder_ouputs, len(encoder_input_val))\n",
    "\n",
    "    print('-' * 10, 'Make dataset complete', '-' * 10)\n",
    "    return train_inputs_dataset, val_inputs_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5sKIJ5K5Pz1"
   },
   "source": [
    "## 2. Trainer 및 Trainingargs 구축하기\n",
    "- Huggingface 의 Trainer 와 Training arguments를 활용하여 모델 학습을 일괄적으로 처리해주는 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "aQk8ILcEeGNz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 모델 성능에 대한 평가 지표를 정의합니다. 본 대회에서는 ROUGE 점수를 통해 모델의 성능을 평가합니다.\n",
    "def compute_metrics(config,tokenizer,pred):\n",
    "    rouge = Rouge()\n",
    "    predictions = pred.predictions\n",
    "    print(predictions)\n",
    "    labels = pred.label_ids\n",
    "    print(labels)\n",
    "\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # predictions가 3차원 텐서일 경우 argmax를 사용해 토큰 ID로 변환\n",
    "    if isinstance(predictions, torch.Tensor) or isinstance(predictions, np.ndarray):\n",
    "        # argmax를 사용하여 가장 높은 점수의 인덱스를 토큰 ID로 선택\n",
    "        predictions = np.argmax(predictions, axis=-1)  # torch.Tensor인 경우 torch.argmax(predictions, dim=-1) 사용\n",
    "        predictions = predictions.tolist()        \n",
    "\n",
    "    # predictions가 리스트의 리스트인지 확인\n",
    "    if isinstance(predictions[0], list):\n",
    "        decoded_preds = tokenizer.batch_decode(predictions, clean_up_tokenization_spaces=True)\n",
    "    else:\n",
    "        # 예기치 않은 경우: 예외 처리 또는 디버깅 메시지 출력\n",
    "        print(predictions)\n",
    "        raise ValueError(\"predictions가 잘못된 형식입니다. 리스트의 리스트 형식이어야 합니다.\")\n",
    "\n",
    "    # predictions를 디코딩\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, clean_up_tokenization_spaces=True)\n",
    "    labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    # 정확한 평가를 위해 미리 정의된 불필요한 생성토큰들을 제거합니다.\n",
    "    replaced_predictions = decoded_preds.copy()\n",
    "    replaced_labels = labels.copy()\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    for token in remove_tokens:\n",
    "        replaced_predictions = [sentence.replace(token,\" \") for sentence in replaced_predictions]\n",
    "        replaced_labels = [sentence.replace(token,\" \") for sentence in replaced_labels]\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[0]}\")\n",
    "    print(f\"GOLD: {replaced_labels[0]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[1]}\")\n",
    "    print(f\"GOLD: {replaced_labels[1]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[2]}\")\n",
    "    print(f\"GOLD: {replaced_labels[2]}\")\n",
    "\n",
    "    # 최종적인 ROUGE 점수를 계산합니다.\n",
    "    results = rouge.get_scores(replaced_predictions, replaced_labels,avg=True)\n",
    "\n",
    "    # ROUGE 점수 중 F-1 score를 통해 평가합니다.\n",
    "    result = {key: value[\"f\"] for key, value in results.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "RInkG8g-HjBi"
   },
   "outputs": [],
   "source": [
    "# 학습을 위한 trainer 클래스와 매개변수를 정의합니다.\n",
    "def load_trainer_for_train(config, generate_model, tokenizer, train_dataset, val_dataset):\n",
    "    print('-' * 10, 'Make training arguments', '-' * 10)\n",
    "    # set training args\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=config['general']['output_dir'],\n",
    "        overwrite_output_dir=config['training']['overwrite_output_dir'],\n",
    "        num_train_epochs=config['training']['num_train_epochs'],\n",
    "        learning_rate=config['training']['learning_rate'],\n",
    "        per_device_train_batch_size=config['training']['per_device_train_batch_size'],\n",
    "        per_device_eval_batch_size=config['training']['per_device_eval_batch_size'],\n",
    "        warmup_ratio=config['training']['warmup_ratio'],\n",
    "        weight_decay=config['training']['weight_decay'],\n",
    "        lr_scheduler_type=config['training']['lr_scheduler_type'],\n",
    "        optim=config['training']['optim'],\n",
    "        gradient_accumulation_steps=config['training']['gradient_accumulation_steps'],\n",
    "        evaluation_strategy=config['training']['evaluation_strategy'],\n",
    "        save_strategy=config['training']['save_strategy'],\n",
    "        save_total_limit=config['training']['save_total_limit'],\n",
    "        fp16=config['training']['fp16'],\n",
    "        load_best_model_at_end=config['training']['load_best_model_at_end'],\n",
    "        seed=config['training']['seed'],\n",
    "        logging_dir=config['training']['logging_dir'],\n",
    "        logging_strategy=config['training']['logging_strategy'],\n",
    "        report_to=config['training']['report_to']\n",
    "    )\n",
    "\n",
    "    # (선택) 모델의 학습 과정을 추적하는 wandb를 사용하기 위해 초기화 해줍니다.\n",
    "    wandb.init(\n",
    "        project=config['wandb']['project'],\n",
    "        name=config['wandb']['name'],\n",
    "    )\n",
    "\n",
    "    # (선택) 모델 checkpoint를 wandb에 저장하도록 환경 변수를 설정합니다.\n",
    "    os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "    os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "\n",
    "    # Validation loss가 더 이상 개선되지 않을 때 학습을 중단시키는 EarlyStopping 기능을 사용합니다.\n",
    "    MyCallback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=config['training']['early_stopping_patience'],\n",
    "        early_stopping_threshold=config['training']['early_stopping_threshold']\n",
    "    )\n",
    "    print('-'*10, 'Make training arguments complete', '-'*10,)\n",
    "    print('-'*10, 'Make trainer', '-'*10,)\n",
    "\n",
    "    # Trainer 클래스를 정의합니다.\n",
    "    trainer = Trainer(\n",
    "        model=generate_model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=lambda pred: compute_metrics(config, tokenizer, pred),\n",
    "        callbacks=[MyCallback]\n",
    "    )\n",
    "    print('-'*10, 'Make trainer complete', '-'*10,)\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "KKWHe8dE5fSx"
   },
   "outputs": [],
   "source": [
    "# 학습을 위한 tokenizer와 사전 학습된 모델을 불러옵니다.\n",
    "def load_tokenizer_and_model_for_train(config,device):\n",
    "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
    "    print('-'*10, f'Model Name : {config[\"general\"][\"model_name\"]}', '-'*10,)\n",
    "    model_name = config['general']['model_name']\n",
    "    t5_config = T5Config().from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    generate_model = T5ForConditionalGeneration.from_pretrained(config['general']['model_name'],config=t5_config)\n",
    "\n",
    "    special_tokens_dict={'additional_special_tokens':config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    generate_model.resize_token_embeddings(len(tokenizer))\n",
    "    generate_model.to(device)\n",
    "    print(generate_model.config)\n",
    "\n",
    "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
    "    return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvutzKQYvQgl"
   },
   "source": [
    "## 3. 모델 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImZUb-BC42J-"
   },
   "source": [
    "- 앞에서 구축한 클래스 및 함수를 활용하여 학습 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qnA96wmR44is"
   },
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    # 사용할 device를 정의합니다.\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print('-'*10, f'device : {device}', '-'*10,)\n",
    "    print(torch.__version__)\n",
    "\n",
    "    # 사용할 모델과 tokenizer를 불러옵니다.\n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_train(config,device)\n",
    "    print('-'*10,\"tokenizer special tokens : \",tokenizer.special_tokens_map,'-'*10)\n",
    "\n",
    "    # 학습에 사용할 데이터셋을 불러옵니다.\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token']) # decoder_start_token: str, eos_token: str\n",
    "    data_path = config['general']['data_path']\n",
    "    train_inputs_dataset, val_inputs_dataset = prepare_train_dataset(config, preprocessor, data_path, tokenizer)\n",
    "\n",
    "    # Trainer 클래스를 불러옵니다.\n",
    "    trainer = load_trainer_for_train(config, generate_model, tokenizer, train_inputs_dataset, val_inputs_dataset)\n",
    "    trainer.train()   # 모델 학습을 시작합니다.\n",
    "\n",
    "    # (선택) 모델 학습이 완료된 후 wandb를 종료합니다.\n",
    "    wandb.finish()\n",
    "\n",
    "    return trainer.state.best_model_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1DMS60wL-Dhv",
    "outputId": "cbb6aba7-18ff-4d12-b9e7-2a2ef31d94d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda:0 ----------\n",
      "2.4.0+cu121\n",
      "---------- Load tokenizer & model ----------\n",
      "---------- Model Name : eenzeenee/t5-base-korean-summarization ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5Config {\n",
      "  \"_name_or_path\": \"eenzeenee/t5-base-korean-summarization\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"max_length\": 128,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50373\n",
      "}\n",
      "\n",
      "---------- Load tokenizer & model complete ----------\n",
      "---------- tokenizer special tokens :  {'eos_token': '</s>', 'unk_token': '<pad>', 'pad_token': '<pad>', 'additional_special_tokens': ['#Email#', '#PhoneNumber#', '#Person5#', '#DateOfBirth#', '#SSN#', '#PassportNumber#', '#Person2#', '#Address#', '#Person7#', '#Person1#', '#Person6#', '#Person4#', '#Person3#', '#CardNumber#', '#CarNumber#']} ----------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "train_data:\n",
      " #Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
      "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
      "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
      "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
      "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
      "#Person2#: 알겠습니다.\n",
      "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
      "#Person2#: 네.\n",
      "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
      "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
      "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
      "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
      "train_label:\n",
      " 스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니다. 호킨스 의사는 스미스씨가 담배를 끊는 데 도움이 될 수 있는 수업과 약물에 대한 정보를 제공할 것입니다.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "val_data:\n",
      " #Person1#: 안녕하세요, 오늘 하루 어떠셨어요? \n",
      "#Person2#: 요즘 숨쉬기가 좀 힘들어요.\n",
      "#Person1#: 최근에 감기 같은 것에 걸리신 적이 있나요?\n",
      "#Person2#: 아니요, 감기는 아니에요. 그냥 숨을 쉴 때마다 가슴이 무겁게 느껴져요.\n",
      "#Person1#: 알고 있는 알레르기가 있나요?\n",
      "#Person2#: 아니요, 알고 있는 알레르기는 없어요.\n",
      "#Person1#: 이런 증상이 항상 나타나나요, 아니면 활동할 때 주로 나타나나요?\n",
      "#Person2#: 운동을 할 때 많이 나타나요.\n",
      "#Person1#: 저는 당신을 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 거예요.\n",
      "#Person2#: 도와주셔서 감사합니다, 의사 선생님.\n",
      "val_label:\n",
      " #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다. \n",
      "---------- Load data complete ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Make dataset complete ----------\n",
      "---------- Make training arguments ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msyaseuta\u001b[0m (\u001b[33mupstage-ai-lab-3rd-cv11\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/projects/dialogue-summarization/wandb/run-20240903_015001-0hxywt1p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/upstage-ai-lab-3rd-cv11/dialogue-summarization/runs/0hxywt1p' target=\"_blank\">0903-104953</a></strong> to <a href='https://wandb.ai/upstage-ai-lab-3rd-cv11/dialogue-summarization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/upstage-ai-lab-3rd-cv11/dialogue-summarization' target=\"_blank\">https://wandb.ai/upstage-ai-lab-3rd-cv11/dialogue-summarization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/upstage-ai-lab-3rd-cv11/dialogue-summarization/runs/0hxywt1p' target=\"_blank\">https://wandb.ai/upstage-ai-lab-3rd-cv11/dialogue-summarization/runs/0hxywt1p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:439: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Make training arguments complete ----------\n",
      "---------- Make trainer ----------\n",
      "---------- Make trainer complete ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='196' max='3900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 196/3900 02:28 < 47:07, 1.31 it/s, Epoch 1/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[ 1.06718750e+01,  3.83007812e+00,  2.24218750e+00, ...,\n",
      "          1.84173584e-02,  3.20312500e-01,  3.54003906e-02],\n",
      "        [-6.89843750e+00,  5.59375000e+00, -1.08691406e+00, ...,\n",
      "         -1.12060547e-01,  8.59375000e-02,  6.95190430e-02],\n",
      "        [-7.34765625e+00,  8.11718750e+00, -1.51855469e+00, ...,\n",
      "         -1.64672852e-01,  2.38647461e-01,  1.91192627e-02],\n",
      "        ...,\n",
      "        [ 3.26875000e+01,  5.23046875e+00,  8.09375000e+00, ...,\n",
      "         -3.46435547e-01,  5.93261719e-01,  1.68579102e-01],\n",
      "        [ 3.25625000e+01,  5.22656250e+00,  8.11718750e+00, ...,\n",
      "         -3.32275391e-01,  5.83496094e-01,  1.46484375e-01],\n",
      "        [ 3.23437500e+01,  5.19921875e+00,  8.07812500e+00, ...,\n",
      "         -3.19091797e-01,  5.75683594e-01,  1.31713867e-01]],\n",
      "\n",
      "       [[ 1.02187500e+01,  4.31640625e+00,  1.78906250e+00, ...,\n",
      "         -2.25677490e-02,  1.19934082e-01, -5.79223633e-02],\n",
      "        [-7.25390625e+00,  6.00390625e+00, -8.30566406e-01, ...,\n",
      "         -1.82861328e-01,  1.55029297e-01, -8.13598633e-02],\n",
      "        [-6.46093750e+00,  8.71093750e+00, -1.03988647e-02, ...,\n",
      "         -3.24218750e-01,  8.14819336e-02, -1.45629883e-01],\n",
      "        ...,\n",
      "        [ 2.86718750e+01,  5.19531250e+00,  7.65625000e+00, ...,\n",
      "         -2.93945312e-01,  3.41308594e-01, -2.89611816e-02],\n",
      "        [ 2.85156250e+01,  5.18359375e+00,  7.63281250e+00, ...,\n",
      "         -2.91748047e-01,  3.39111328e-01, -2.93579102e-02],\n",
      "        [ 2.82500000e+01,  5.19140625e+00,  7.55468750e+00, ...,\n",
      "         -2.84667969e-01,  3.35205078e-01, -2.93121338e-02]],\n",
      "\n",
      "       [[ 6.63281250e+00,  3.85546875e+00,  4.48974609e-01, ...,\n",
      "          1.28051758e-01,  1.37329102e-01,  4.72412109e-02],\n",
      "        [-7.38281250e+00,  5.91015625e+00, -9.23339844e-01, ...,\n",
      "         -1.36962891e-01,  1.09436035e-01, -5.39855957e-02],\n",
      "        [-7.48046875e+00,  8.94531250e+00, -1.46289062e+00, ...,\n",
      "         -1.19628906e-01,  1.22497559e-01, -6.73217773e-02],\n",
      "        ...,\n",
      "        [ 2.42656250e+01,  6.01171875e+00,  4.30859375e+00, ...,\n",
      "         -1.84814453e-01,  4.13085938e-01,  2.37304688e-01],\n",
      "        [ 2.53906250e+01,  5.91406250e+00,  4.92968750e+00, ...,\n",
      "         -1.82128906e-01,  4.10400391e-01,  2.12280273e-01],\n",
      "        [ 2.58437500e+01,  5.79687500e+00,  5.28125000e+00, ...,\n",
      "         -1.71997070e-01,  4.04785156e-01,  1.89697266e-01]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 9.75781250e+00,  3.89062500e+00,  1.26562500e+00, ...,\n",
      "          2.90527344e-02,  2.00073242e-01,  2.10571289e-01],\n",
      "        [-7.12109375e+00,  6.03906250e+00, -1.33300781e+00, ...,\n",
      "         -1.72119141e-01,  3.70178223e-02,  1.07604980e-01],\n",
      "        [-9.50781250e+00,  8.55468750e+00, -3.53515625e+00, ...,\n",
      "         -2.70507812e-01,  1.86645508e-01, -5.06591797e-02],\n",
      "        ...,\n",
      "        [-8.31250000e+00,  1.33828125e+01,  4.82812500e+00, ...,\n",
      "         -2.46429443e-02,  5.42602539e-02, -1.16149902e-01],\n",
      "        [-8.85156250e+00,  1.90156250e+01, -1.48828125e+00, ...,\n",
      "         -1.71997070e-01, -5.29479980e-02, -6.61010742e-02],\n",
      "        [ 5.06347656e-01,  5.82421875e+00,  1.00878906e+00, ...,\n",
      "          6.51855469e-02,  8.97216797e-02,  2.47436523e-01]],\n",
      "\n",
      "       [[ 1.30234375e+01,  4.41796875e+00,  3.31054688e+00, ...,\n",
      "         -3.38134766e-02,  1.93481445e-01,  5.13305664e-02],\n",
      "        [-6.93750000e+00,  5.63671875e+00, -1.14160156e+00, ...,\n",
      "         -1.04614258e-01,  9.56726074e-03,  1.11694336e-01],\n",
      "        [-8.67187500e+00,  6.05859375e+00,  3.09179688e+00, ...,\n",
      "         -1.57104492e-01,  5.87463379e-02, -5.78308105e-03],\n",
      "        ...,\n",
      "        [-9.46875000e+00,  9.72656250e+00, -1.57617188e+00, ...,\n",
      "         -2.63824463e-02,  8.92639160e-03,  1.65893555e-01],\n",
      "        [-5.49218750e+00,  4.18750000e+00, -2.51708984e-01, ...,\n",
      "          9.25903320e-02, -1.25610352e-01,  1.39892578e-01],\n",
      "        [-6.69921875e+00,  6.87890625e+00,  6.69921875e-01, ...,\n",
      "          2.17163086e-01,  3.16162109e-02, -5.67245483e-03]],\n",
      "\n",
      "       [[ 8.33593750e+00,  3.81054688e+00,  1.26855469e+00, ...,\n",
      "         -9.55200195e-03,  1.03759766e-01,  2.13012695e-01],\n",
      "        [-6.96093750e+00,  5.83984375e+00, -1.07519531e+00, ...,\n",
      "         -1.17553711e-01,  5.39550781e-02,  5.54809570e-02],\n",
      "        [-7.43750000e+00,  9.62500000e+00, -7.95410156e-01, ...,\n",
      "         -2.59765625e-01,  1.92871094e-01,  1.16455078e-01],\n",
      "        ...,\n",
      "        [ 3.19218750e+01,  5.72265625e+00,  7.68750000e+00, ...,\n",
      "         -4.30175781e-01,  3.92333984e-01,  3.93066406e-01],\n",
      "        [ 3.28750000e+01,  5.66015625e+00,  8.28125000e+00, ...,\n",
      "         -4.18945312e-01,  3.64501953e-01,  3.53027344e-01],\n",
      "        [ 3.33750000e+01,  5.55859375e+00,  8.64062500e+00, ...,\n",
      "         -4.05273438e-01,  3.42529297e-01,  3.22509766e-01]]],\n",
      "      dtype=float32), array([[[-0.31157553,  0.00744203, -0.0831283 , ...,  0.03570064,\n",
      "          0.22554922,  0.04765807],\n",
      "        [-0.07339045, -0.29180413,  0.37238678, ...,  0.2753536 ,\n",
      "          0.31401873, -0.13743615],\n",
      "        [ 0.16006854, -0.05592908,  0.20529681, ...,  0.12740274,\n",
      "          0.06621153,  0.05295148],\n",
      "        ...,\n",
      "        [ 0.14549032, -0.20594805,  0.2058344 , ...,  0.22525108,\n",
      "         -0.01781886, -0.00644744],\n",
      "        [ 0.14129744, -0.19753857,  0.19169779, ...,  0.22466631,\n",
      "         -0.03388707, -0.02173881],\n",
      "        [ 0.14241517, -0.19817588,  0.18950398, ...,  0.22358896,\n",
      "         -0.03447606, -0.02996875]],\n",
      "\n",
      "       [[-0.33262104,  0.00092195, -0.11388728, ..., -0.00815947,\n",
      "          0.17103805,  0.01275201],\n",
      "        [-0.1270138 , -0.27460298,  0.34313735, ...,  0.2915718 ,\n",
      "          0.299685  , -0.1898042 ],\n",
      "        [ 0.11042108, -0.08850387,  0.17479384, ...,  0.13167697,\n",
      "          0.03325394, -0.02109015],\n",
      "        ...,\n",
      "        [ 0.12137156, -0.17427099,  0.2764827 , ...,  0.23333164,\n",
      "         -0.0137268 , -0.18371549],\n",
      "        [ 0.12240996, -0.17011754,  0.2793954 , ...,  0.22722147,\n",
      "         -0.01231446, -0.18417363],\n",
      "        [ 0.13146484, -0.17850825,  0.2766779 , ...,  0.2126623 ,\n",
      "         -0.01986828, -0.1985324 ]],\n",
      "\n",
      "       [[-0.34871188,  0.0028437 , -0.11551154, ..., -0.02169869,\n",
      "          0.20041935,  0.03043509],\n",
      "        [-0.13202734, -0.28850007,  0.3522354 , ...,  0.29720956,\n",
      "          0.32268897, -0.15336445],\n",
      "        [ 0.09765215, -0.08120923,  0.2380764 , ...,  0.13513538,\n",
      "          0.02362175, -0.00901949],\n",
      "        ...,\n",
      "        [ 0.09638525, -0.22178178,  0.11675075, ...,  0.2658834 ,\n",
      "         -0.06229914, -0.05424882],\n",
      "        [ 0.0964445 , -0.2248208 ,  0.11992697, ...,  0.26688161,\n",
      "         -0.06086876, -0.05247134],\n",
      "        [ 0.09490278, -0.22735472,  0.11516059, ...,  0.2683117 ,\n",
      "         -0.06858527, -0.06015481]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.33867955,  0.0168929 , -0.10166671, ...,  0.00432531,\n",
      "          0.1940634 ,  0.03844179],\n",
      "        [-0.12880862, -0.24219385,  0.36671734, ...,  0.25670642,\n",
      "          0.3186369 , -0.16091716],\n",
      "        [ 0.122761  , -0.0474927 ,  0.21009469, ...,  0.12718119,\n",
      "          0.07177395,  0.03011149],\n",
      "        ...,\n",
      "        [ 0.11207063, -0.03145479,  0.11373927, ...,  0.05215641,\n",
      "          0.045093  , -0.19614458],\n",
      "        [ 0.09111132, -0.15461719,  0.15145783, ..., -0.18045953,\n",
      "         -0.0980384 , -0.05177643],\n",
      "        [ 0.0489742 , -0.09407672, -0.06658589, ..., -0.08515224,\n",
      "          0.00584359, -0.06491981]],\n",
      "\n",
      "       [[-0.3281505 , -0.01171648, -0.10026809, ..., -0.02524788,\n",
      "          0.12583351,  0.02917285],\n",
      "        [-0.06627358, -0.27423847,  0.35741514, ...,  0.21277289,\n",
      "          0.27931526, -0.21274497],\n",
      "        [ 0.16662027, -0.03485871,  0.18359822, ...,  0.12119277,\n",
      "         -0.01756576,  0.03092935],\n",
      "        ...,\n",
      "        [ 0.00387691,  0.00541273, -0.00553723, ...,  0.00535623,\n",
      "         -0.01138395,  0.00782355],\n",
      "        [ 0.03966382, -0.20750922,  0.04585668, ..., -0.07463224,\n",
      "         -0.22623864, -0.11500864],\n",
      "        [ 0.08978967, -0.10316087, -0.08346459, ..., -0.19467631,\n",
      "         -0.11736847,  0.07503808]],\n",
      "\n",
      "       [[-0.33505684, -0.01517221, -0.12439178, ...,  0.01868497,\n",
      "          0.17332542,  0.02533475],\n",
      "        [-0.12411654, -0.3059189 ,  0.3600254 , ...,  0.3061343 ,\n",
      "          0.33147126, -0.19034784],\n",
      "        [ 0.11225379, -0.09708969,  0.20726448, ...,  0.13825268,\n",
      "          0.04005448, -0.00778727],\n",
      "        ...,\n",
      "        [-0.09000234, -0.02965832, -0.03778071, ...,  0.21130456,\n",
      "         -0.12614368, -0.24220794],\n",
      "        [-0.04028079,  0.08955024,  0.07663742, ...,  0.03822098,\n",
      "         -0.05416997,  0.0249475 ],\n",
      "        [ 0.06235269,  0.06218569, -0.13174519, ..., -0.05776591,\n",
      "          0.01219205,  0.01012008]]], dtype=float32))\n",
      "[[50364   274   222 ...     0     0     0]\n",
      " [50367   311   222 ...     0     0     0]\n",
      " [50367   311   222 ...     0     0     0]\n",
      " ...\n",
      " [50364   302   222 ...    15   222     1]\n",
      " [50364   549   262 ...   222  1097     1]\n",
      " [50364   274   222 ...     0     0     0]]\n",
      "(array([[[ 1.06718750e+01,  3.83007812e+00,  2.24218750e+00, ...,\n",
      "          1.84173584e-02,  3.20312500e-01,  3.54003906e-02],\n",
      "        [-6.89843750e+00,  5.59375000e+00, -1.08691406e+00, ...,\n",
      "         -1.12060547e-01,  8.59375000e-02,  6.95190430e-02],\n",
      "        [-7.34765625e+00,  8.11718750e+00, -1.51855469e+00, ...,\n",
      "         -1.64672852e-01,  2.38647461e-01,  1.91192627e-02],\n",
      "        ...,\n",
      "        [ 3.26875000e+01,  5.23046875e+00,  8.09375000e+00, ...,\n",
      "         -3.46435547e-01,  5.93261719e-01,  1.68579102e-01],\n",
      "        [ 3.25625000e+01,  5.22656250e+00,  8.11718750e+00, ...,\n",
      "         -3.32275391e-01,  5.83496094e-01,  1.46484375e-01],\n",
      "        [ 3.23437500e+01,  5.19921875e+00,  8.07812500e+00, ...,\n",
      "         -3.19091797e-01,  5.75683594e-01,  1.31713867e-01]],\n",
      "\n",
      "       [[ 1.02187500e+01,  4.31640625e+00,  1.78906250e+00, ...,\n",
      "         -2.25677490e-02,  1.19934082e-01, -5.79223633e-02],\n",
      "        [-7.25390625e+00,  6.00390625e+00, -8.30566406e-01, ...,\n",
      "         -1.82861328e-01,  1.55029297e-01, -8.13598633e-02],\n",
      "        [-6.46093750e+00,  8.71093750e+00, -1.03988647e-02, ...,\n",
      "         -3.24218750e-01,  8.14819336e-02, -1.45629883e-01],\n",
      "        ...,\n",
      "        [ 2.86718750e+01,  5.19531250e+00,  7.65625000e+00, ...,\n",
      "         -2.93945312e-01,  3.41308594e-01, -2.89611816e-02],\n",
      "        [ 2.85156250e+01,  5.18359375e+00,  7.63281250e+00, ...,\n",
      "         -2.91748047e-01,  3.39111328e-01, -2.93579102e-02],\n",
      "        [ 2.82500000e+01,  5.19140625e+00,  7.55468750e+00, ...,\n",
      "         -2.84667969e-01,  3.35205078e-01, -2.93121338e-02]],\n",
      "\n",
      "       [[ 6.63281250e+00,  3.85546875e+00,  4.48974609e-01, ...,\n",
      "          1.28051758e-01,  1.37329102e-01,  4.72412109e-02],\n",
      "        [-7.38281250e+00,  5.91015625e+00, -9.23339844e-01, ...,\n",
      "         -1.36962891e-01,  1.09436035e-01, -5.39855957e-02],\n",
      "        [-7.48046875e+00,  8.94531250e+00, -1.46289062e+00, ...,\n",
      "         -1.19628906e-01,  1.22497559e-01, -6.73217773e-02],\n",
      "        ...,\n",
      "        [ 2.42656250e+01,  6.01171875e+00,  4.30859375e+00, ...,\n",
      "         -1.84814453e-01,  4.13085938e-01,  2.37304688e-01],\n",
      "        [ 2.53906250e+01,  5.91406250e+00,  4.92968750e+00, ...,\n",
      "         -1.82128906e-01,  4.10400391e-01,  2.12280273e-01],\n",
      "        [ 2.58437500e+01,  5.79687500e+00,  5.28125000e+00, ...,\n",
      "         -1.71997070e-01,  4.04785156e-01,  1.89697266e-01]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 9.75781250e+00,  3.89062500e+00,  1.26562500e+00, ...,\n",
      "          2.90527344e-02,  2.00073242e-01,  2.10571289e-01],\n",
      "        [-7.12109375e+00,  6.03906250e+00, -1.33300781e+00, ...,\n",
      "         -1.72119141e-01,  3.70178223e-02,  1.07604980e-01],\n",
      "        [-9.50781250e+00,  8.55468750e+00, -3.53515625e+00, ...,\n",
      "         -2.70507812e-01,  1.86645508e-01, -5.06591797e-02],\n",
      "        ...,\n",
      "        [-8.31250000e+00,  1.33828125e+01,  4.82812500e+00, ...,\n",
      "         -2.46429443e-02,  5.42602539e-02, -1.16149902e-01],\n",
      "        [-8.85156250e+00,  1.90156250e+01, -1.48828125e+00, ...,\n",
      "         -1.71997070e-01, -5.29479980e-02, -6.61010742e-02],\n",
      "        [ 5.06347656e-01,  5.82421875e+00,  1.00878906e+00, ...,\n",
      "          6.51855469e-02,  8.97216797e-02,  2.47436523e-01]],\n",
      "\n",
      "       [[ 1.30234375e+01,  4.41796875e+00,  3.31054688e+00, ...,\n",
      "         -3.38134766e-02,  1.93481445e-01,  5.13305664e-02],\n",
      "        [-6.93750000e+00,  5.63671875e+00, -1.14160156e+00, ...,\n",
      "         -1.04614258e-01,  9.56726074e-03,  1.11694336e-01],\n",
      "        [-8.67187500e+00,  6.05859375e+00,  3.09179688e+00, ...,\n",
      "         -1.57104492e-01,  5.87463379e-02, -5.78308105e-03],\n",
      "        ...,\n",
      "        [-9.46875000e+00,  9.72656250e+00, -1.57617188e+00, ...,\n",
      "         -2.63824463e-02,  8.92639160e-03,  1.65893555e-01],\n",
      "        [-5.49218750e+00,  4.18750000e+00, -2.51708984e-01, ...,\n",
      "          9.25903320e-02, -1.25610352e-01,  1.39892578e-01],\n",
      "        [-6.69921875e+00,  6.87890625e+00,  6.69921875e-01, ...,\n",
      "          2.17163086e-01,  3.16162109e-02, -5.67245483e-03]],\n",
      "\n",
      "       [[ 8.33593750e+00,  3.81054688e+00,  1.26855469e+00, ...,\n",
      "         -9.55200195e-03,  1.03759766e-01,  2.13012695e-01],\n",
      "        [-6.96093750e+00,  5.83984375e+00, -1.07519531e+00, ...,\n",
      "         -1.17553711e-01,  5.39550781e-02,  5.54809570e-02],\n",
      "        [-7.43750000e+00,  9.62500000e+00, -7.95410156e-01, ...,\n",
      "         -2.59765625e-01,  1.92871094e-01,  1.16455078e-01],\n",
      "        ...,\n",
      "        [ 3.19218750e+01,  5.72265625e+00,  7.68750000e+00, ...,\n",
      "         -4.30175781e-01,  3.92333984e-01,  3.93066406e-01],\n",
      "        [ 3.28750000e+01,  5.66015625e+00,  8.28125000e+00, ...,\n",
      "         -4.18945312e-01,  3.64501953e-01,  3.53027344e-01],\n",
      "        [ 3.33750000e+01,  5.55859375e+00,  8.64062500e+00, ...,\n",
      "         -4.05273438e-01,  3.42529297e-01,  3.22509766e-01]]],\n",
      "      dtype=float32), array([[[-0.31157553,  0.00744203, -0.0831283 , ...,  0.03570064,\n",
      "          0.22554922,  0.04765807],\n",
      "        [-0.07339045, -0.29180413,  0.37238678, ...,  0.2753536 ,\n",
      "          0.31401873, -0.13743615],\n",
      "        [ 0.16006854, -0.05592908,  0.20529681, ...,  0.12740274,\n",
      "          0.06621153,  0.05295148],\n",
      "        ...,\n",
      "        [ 0.14549032, -0.20594805,  0.2058344 , ...,  0.22525108,\n",
      "         -0.01781886, -0.00644744],\n",
      "        [ 0.14129744, -0.19753857,  0.19169779, ...,  0.22466631,\n",
      "         -0.03388707, -0.02173881],\n",
      "        [ 0.14241517, -0.19817588,  0.18950398, ...,  0.22358896,\n",
      "         -0.03447606, -0.02996875]],\n",
      "\n",
      "       [[-0.33262104,  0.00092195, -0.11388728, ..., -0.00815947,\n",
      "          0.17103805,  0.01275201],\n",
      "        [-0.1270138 , -0.27460298,  0.34313735, ...,  0.2915718 ,\n",
      "          0.299685  , -0.1898042 ],\n",
      "        [ 0.11042108, -0.08850387,  0.17479384, ...,  0.13167697,\n",
      "          0.03325394, -0.02109015],\n",
      "        ...,\n",
      "        [ 0.12137156, -0.17427099,  0.2764827 , ...,  0.23333164,\n",
      "         -0.0137268 , -0.18371549],\n",
      "        [ 0.12240996, -0.17011754,  0.2793954 , ...,  0.22722147,\n",
      "         -0.01231446, -0.18417363],\n",
      "        [ 0.13146484, -0.17850825,  0.2766779 , ...,  0.2126623 ,\n",
      "         -0.01986828, -0.1985324 ]],\n",
      "\n",
      "       [[-0.34871188,  0.0028437 , -0.11551154, ..., -0.02169869,\n",
      "          0.20041935,  0.03043509],\n",
      "        [-0.13202734, -0.28850007,  0.3522354 , ...,  0.29720956,\n",
      "          0.32268897, -0.15336445],\n",
      "        [ 0.09765215, -0.08120923,  0.2380764 , ...,  0.13513538,\n",
      "          0.02362175, -0.00901949],\n",
      "        ...,\n",
      "        [ 0.09638525, -0.22178178,  0.11675075, ...,  0.2658834 ,\n",
      "         -0.06229914, -0.05424882],\n",
      "        [ 0.0964445 , -0.2248208 ,  0.11992697, ...,  0.26688161,\n",
      "         -0.06086876, -0.05247134],\n",
      "        [ 0.09490278, -0.22735472,  0.11516059, ...,  0.2683117 ,\n",
      "         -0.06858527, -0.06015481]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.33867955,  0.0168929 , -0.10166671, ...,  0.00432531,\n",
      "          0.1940634 ,  0.03844179],\n",
      "        [-0.12880862, -0.24219385,  0.36671734, ...,  0.25670642,\n",
      "          0.3186369 , -0.16091716],\n",
      "        [ 0.122761  , -0.0474927 ,  0.21009469, ...,  0.12718119,\n",
      "          0.07177395,  0.03011149],\n",
      "        ...,\n",
      "        [ 0.11207063, -0.03145479,  0.11373927, ...,  0.05215641,\n",
      "          0.045093  , -0.19614458],\n",
      "        [ 0.09111132, -0.15461719,  0.15145783, ..., -0.18045953,\n",
      "         -0.0980384 , -0.05177643],\n",
      "        [ 0.0489742 , -0.09407672, -0.06658589, ..., -0.08515224,\n",
      "          0.00584359, -0.06491981]],\n",
      "\n",
      "       [[-0.3281505 , -0.01171648, -0.10026809, ..., -0.02524788,\n",
      "          0.12583351,  0.02917285],\n",
      "        [-0.06627358, -0.27423847,  0.35741514, ...,  0.21277289,\n",
      "          0.27931526, -0.21274497],\n",
      "        [ 0.16662027, -0.03485871,  0.18359822, ...,  0.12119277,\n",
      "         -0.01756576,  0.03092935],\n",
      "        ...,\n",
      "        [ 0.00387691,  0.00541273, -0.00553723, ...,  0.00535623,\n",
      "         -0.01138395,  0.00782355],\n",
      "        [ 0.03966382, -0.20750922,  0.04585668, ..., -0.07463224,\n",
      "         -0.22623864, -0.11500864],\n",
      "        [ 0.08978967, -0.10316087, -0.08346459, ..., -0.19467631,\n",
      "         -0.11736847,  0.07503808]],\n",
      "\n",
      "       [[-0.33505684, -0.01517221, -0.12439178, ...,  0.01868497,\n",
      "          0.17332542,  0.02533475],\n",
      "        [-0.12411654, -0.3059189 ,  0.3600254 , ...,  0.3061343 ,\n",
      "          0.33147126, -0.19034784],\n",
      "        [ 0.11225379, -0.09708969,  0.20726448, ...,  0.13825268,\n",
      "          0.04005448, -0.00778727],\n",
      "        ...,\n",
      "        [-0.09000234, -0.02965832, -0.03778071, ...,  0.21130456,\n",
      "         -0.12614368, -0.24220794],\n",
      "        [-0.04028079,  0.08955024,  0.07663742, ...,  0.03822098,\n",
      "         -0.05416997,  0.0249475 ],\n",
      "        [ 0.06235269,  0.06218569, -0.13174519, ..., -0.05776591,\n",
      "          0.01219205,  0.01012008]]], dtype=float32))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "predictions가 잘못된 형식입니다. 리스트의 리스트 형식이어야 합니다.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Trainer 클래스를 불러옵니다.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m trainer \u001b[38;5;241m=\u001b[39m load_trainer_for_train(config, generate_model, tokenizer, train_inputs_dataset, val_inputs_dataset)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# 모델 학습을 시작합니다.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# (선택) 모델 학습이 완료된 후 wandb를 종료합니다.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1937\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1934\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1937\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   1940\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   1941\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2271\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2269\u001b[0m         metrics\u001b[38;5;241m.\u001b[39mupdate(dataset_metrics)\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2271\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2274\u001b[0m \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3011\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3008\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3010\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3011\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3012\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3014\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3015\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3021\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3304\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3300\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3301\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[1;32m   3302\u001b[0m         )\n\u001b[1;32m   3303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3304\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3306\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[20], line 52\u001b[0m, in \u001b[0;36mload_trainer_for_train.<locals>.<lambda>\u001b[0;34m(pred)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMake trainer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m,)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Trainer 클래스를 정의합니다.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     48\u001b[0m     model\u001b[38;5;241m=\u001b[39mgenerate_model,\n\u001b[1;32m     49\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     50\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m     51\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mval_dataset,\n\u001b[0;32m---> 52\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m pred: \u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     53\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[MyCallback]\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMake trainer complete\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m,)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "Cell \u001b[0;32mIn[19], line 25\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(config, tokenizer, pred)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# 예기치 않은 경우: 예외 처리 또는 디버깅 메시지 출력\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(predictions)\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions가 잘못된 형식입니다. 리스트의 리스트 형식이어야 합니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# predictions를 디코딩\u001b[39;00m\n\u001b[1;32m     28\u001b[0m decoded_preds \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(predictions, clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: predictions가 잘못된 형식입니다. 리스트의 리스트 형식이어야 합니다."
     ]
    }
   ],
   "source": [
    "best_checkpoint_path = train(loaded_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFtWqowCGzEc"
   },
   "source": [
    "## 4. 모델 추론하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이곳에 내가 사용할 wandb config 설정\n",
    "print(best_checkpoint_path)\n",
    "loaded_config['inference']['ckt_path'] = best_checkpoint_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFGul3-rSscf"
   },
   "source": [
    "- test data를 사용하여 모델의 성능을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lV1Do7nlTylG"
   },
   "outputs": [],
   "source": [
    "# tokenization 과정까지 진행된 최종적으로 모델에 입력될 데이터를 출력합니다.\n",
    "def prepare_test_dataset(config,preprocessor, tokenizer):\n",
    "\n",
    "    test_file_path = os.path.join(config['general']['data_path'],'test.csv')\n",
    "\n",
    "    test_data = preprocessor.make_set_as_df(test_file_path,is_train=False)\n",
    "    test_id = test_data['fname']\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'test_data:\\n{test_data[\"dialogue\"][0]}')\n",
    "    print('-'*150)\n",
    "\n",
    "    encoder_input_test , _ = preprocessor.make_input(test_data,is_test=True)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "\n",
    "    test_tokenized_encoder_inputs = tokenizer(encoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False,)\n",
    "\n",
    "    test_encoder_inputs_dataset = DatasetForInference(test_tokenized_encoder_inputs, test_id, len(encoder_input_test))\n",
    "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
    "\n",
    "    return test_data, test_encoder_inputs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eb49bLULT3aS"
   },
   "outputs": [],
   "source": [
    "# 추론을 위한 tokenizer와 학습시킨 모델을 불러옵니다.\n",
    "def load_tokenizer_and_model_for_test(config,device):\n",
    "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
    "\n",
    "    model_name = config['general']['model_name'] \n",
    "    ckt_path = config['inference']['ckt_path']\n",
    "    print('-'*10, f'Model Name : {model_name}', '-'*10,)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    special_tokens_dict = {'additional_special_tokens': config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    generate_model = T5ForConditionalGeneration.from_pretrained(ckt_path)\n",
    "    generate_model.resize_token_embeddings(len(tokenizer))\n",
    "    generate_model.to(device)  \n",
    "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
    "\n",
    "    return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델이 생성한 요약문의 출력 결과를 보여줍니다.\n",
    "def inference(config):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print('-'*10, f'device : {device}', '-'*10,)\n",
    "    print(torch.__version__)\n",
    "\n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_test(config,device)\n",
    "\n",
    "    data_path = config['general']['data_path']\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'])\n",
    "\n",
    "    test_data, test_encoder_inputs_dataset = prepare_test_dataset(config,preprocessor, tokenizer)\n",
    "    dataloader = DataLoader(test_encoder_inputs_dataset, batch_size=config['inference']['batch_size'])\n",
    "\n",
    "    summary = []\n",
    "    text_ids = []\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(dataloader):\n",
    "            text_ids.extend(item['ID'])\n",
    "            generated_ids = generate_model.generate(input_ids=item['input_ids'].to('cuda:0'),\n",
    "                            no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],\n",
    "                            early_stopping=config['inference']['early_stopping'],\n",
    "                            max_length=config['inference']['generate_max_length'],\n",
    "                            num_beams=config['inference']['num_beams'],\n",
    "                        )\n",
    "            for ids in generated_ids:\n",
    "                result = tokenizer.decode(ids)\n",
    "                summary.append(result)\n",
    "\n",
    "    # 정확한 평가를 위하여 노이즈에 해당되는 스페셜 토큰을 제거합니다.\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    preprocessed_summary = summary.copy()\n",
    "    for token in remove_tokens:\n",
    "        preprocessed_summary = [sentence.replace(token,\" \") for sentence in preprocessed_summary]\n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"fname\": test_data['fname'],\n",
    "            \"summary\" : preprocessed_summary,\n",
    "        }\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Axzu9rsoGLgJ"
   },
   "outputs": [],
   "source": [
    "# 학습된 모델의 test를 진행합니다.\n",
    "output = inference(loaded_config)\n",
    "print(output.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_prediction(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    \n",
    "    # 앞뒤 따옴표 제거 (작은따옴표와 큰따옴표 모두 처리)\n",
    "    text = text.strip(\"'\\\"\")\n",
    "    \n",
    "    # 앞뒤 공백 제거 및 연속된 공백을 단일 공백으로 변경\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "def clean_summary_column(df, column_name='summary'):\n",
    "    df[column_name] = df[column_name].apply(clean_prediction)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_output=clean_summary_column(output)\n",
    "print(cleaned_output.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_entity_postposition(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    # #Person{n}# 뒤에 오는 조사를 결합\n",
    "    pattern = r'(#Person\\d+#)\\s+([은는이가을를와과의에로])'\n",
    "    return re.sub(pattern, r'\\1\\2', text)\n",
    "\n",
    "def apply_postprocessing_to_dataframe(df, column_name='summary'):\n",
    "    \"\"\"\n",
    "    데이터프레임의 지정된 열에 후처리를 적용합니다.\n",
    "    \n",
    "    :param df: 입력 데이터프레임\n",
    "    :param column_name: 처리할 열 이름 (기본값: 'summary')\n",
    "    :return: 후처리된 데이터프레임\n",
    "    \"\"\"\n",
    "    df[column_name] = df[column_name].apply(postprocess_entity_postposition)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_predictions = apply_postprocessing_to_dataframe(cleaned_output)\n",
    "print(processed_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = loaded_config['inference']['result_path']\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "output.to_csv(os.path.join(result_path, f\"{train_time}.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
