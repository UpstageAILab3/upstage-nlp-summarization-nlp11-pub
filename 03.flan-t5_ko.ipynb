{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Development Environment\n",
    "\n",
    "Our first step is to install the Hugging Face Libraries, including transformers and datasets. Running the following cell will install all the required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "GPU device name: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "    print(f\"GPU device name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU is not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: pytesseract in /opt/conda/lib/python3.10/site-packages (0.3.13)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.28.0)\n",
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/75/35/07c9879163b603f0e464b0f6e6e628a2340cfc7cdc5ca8e7d52d776710d4/transformers-4.44.2-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\n",
      "Requirement already satisfied: rouge-score in /opt/conda/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.17.1)\n",
      "Requirement already satisfied: py7zr in /opt/conda/lib/python3.10/site-packages (0.22.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (23.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from pytesseract) (9.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Obtaining dependency information for tokenizers<0.20,>=0.19 from https://files.pythonhosted.org/packages/40/4f/eb78de4af3b17b589f43a369cbf0c3a7173f25c3d2cd93068852c07689aa/tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# python\n",
    "!pip install pytesseract transformers datasets rouge-score nltk tensorboard py7zr --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9a7fa28fec4c8da41f1441b90a2706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "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\n",
    "T5_DialogueSum"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and prepare dialogueSum dataset from local\n",
    "- This DialogueSum dataset was originally in English but was translated into Korean by teachers using the Solar API for educational purposes. However, the translation seemed somewhat unnatural for native Korean speakers, so I used the Solar API to retranslate it into English to facilitate a more accurate summarization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the `dialogueSum` dataset, we use the `load_dataset()` method from the ðŸ¤— Datasets library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"dialoguSum_Solar_koen\"\n",
    "# huggingface hub model id\n",
    "model_id=\"paust/pko-flan-t5-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 12457\n",
      "val dataset size: 499\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset('csv', data_files={'train': \"/data/ephemeral/home/data/train_en.csv\", 'val': \"/data/ephemeral/home/data/dev_en.csv\"})\n",
    "\n",
    "print(f\"Train dataset size: {len(dataset['train'])}\")\n",
    "print(f\"val dataset size: {len(dataset['val'])}\")\n",
    "\n",
    "# Train dataset size: 12457\n",
    "# Test dataset size: 499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['fname', 'dialogue', 'summary', 'topic', 'dialogue_en', 'summary_en', 'topic_en'],\n",
       "    num_rows: 12457\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets checkout an example of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialogue: \n",
      "#Person1#: ì–´ì„œì˜¤ì„¸ìš”! ë¦¬í‹€ ì´íƒˆë¦¬ì•„ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤. ì €í¬ëŠ” ì „í˜•ì ì¸ ì´íƒˆë¦¬ì•„ ê°€ì •ì´ëžë‹ˆë‹¤!\n",
      "#Person2#: ê·¸ë ‡ë‹¤ê³  ë“¤ì—ˆìŠµë‹ˆë‹¤. ê·¸ëž˜ì„œ ë„ˆë¬´ ì¦ê±°ì›Œìš”.\n",
      "#Person1#: ì´íƒˆë¦¬ì•„ ë‚¨ìžì™€ ê²°í˜¼í•˜ì§€ ì•Šì•˜ë‹¤ë©´ ì´ë ‡ê²Œ ìžì£¼ ìž„ì‹ í•˜ì§€ ì•Šì•˜ì„ ê±°ì˜ˆìš”. ì•„ë§ˆë„ ì•„ì´ ëŒ€ì‹ ì— ë¼ì§€ë¥¼ í‚¤ìš¸ ìˆ˜ ìžˆì—ˆê² ì£ !\n",
      "#Person2#: ë„¤? ìŒ. . . ìš”ì¦˜ë„ ëŒ€ê°€ì¡±ì„ ê¾¸ë¦¬ëŠ” ì‚¬ëžŒë“¤ì´ ìžˆë‹¤ëŠ” ê²ƒì´ ì¢‹ë„¤ìš”.\n",
      "#Person1#: ê·¸ë ‡ì£ . í•˜ì§€ë§Œ í„°í”„ê°€ì´ ë‚¨íŽ¸ì´ ê¾¸ë¬¼ê±°ë¦¬ì§€ ë§ê³  ì¢€ ë” ì ê·¹ì ìœ¼ë¡œ ë„ì™€ì£¼ë©´ ë” ì¢‹ì„ ê²ƒ ê°™ì•„ìš”. í•˜í•˜. . . ì´ê±° ë“œì„¸ìš”. ì´íƒˆë¦¬ì•„ì—ì„œ ì˜¨ ê±°ì˜ˆìš”!\n",
      "---------------\n",
      "summary: \n",
      "#Person2#ê°€ ë¦¬í‹€ ì´íƒˆë¦¬ì•„ì—ì„œ ì¦ê±°ìš´ ì‹œê°„ì„ ë³´ëƒ…ë‹ˆë‹¤. ì£¼ì¸ì¸ #Person1#ì€ ì•„ì´ë“¤ì´ ë„ˆë¬´ ë§Žì•„ì„œ íž˜ë“¤ë‹¤ê³  ë¶ˆí‰í•©ë‹ˆë‹¤.\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "from random import randrange        \n",
    "\n",
    "\n",
    "sample = dataset['train'][randrange(len(dataset[\"train\"]))]\n",
    "print(f\"dialogue: \\n{sample['dialogue']}\\n---------------\")\n",
    "print(f\"summary: \\n{sample['summary']}\\n---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5TokenizerFast\n",
    "# Load tokenizer of FLAN-t5-base\n",
    "tokenizer = T5TokenizerFast.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source length: 1791\n",
      "Min source length: 70\n",
      "Max target length: 319\n",
      "Min target length: 14\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "# The maximum total input sequence length after tokenization. \n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\n",
    "tokenized_inputs = concatenate_datasets([dataset[\"train\"], dataset[\"val\"]]).map(lambda x: tokenizer(x[\"dialogue\"], truncation=True), batched=True, remove_columns=[\"dialogue\", \"summary\"])\n",
    "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "min_source_length = min([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
    "print(f\"Min source length: {min_source_length}\")\n",
    "\n",
    "\n",
    "# The maximum total sequence length for target text after tokenization. \n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\"\n",
    "tokenized_targets = concatenate_datasets([dataset[\"train\"], dataset[\"val\"]]).map(lambda x: tokenizer(x[\"summary\"], truncation=True), batched=True, remove_columns=[\"dialogue\", \"summary\"])\n",
    "max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
    "print(f\"Max target length: {max_target_length}\")\n",
    "min_target_length = min([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
    "print(f\"Min target length: {min_target_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'#CarNumber#' is not in the vocabulary.\n",
      "'#SSN#' is not in the vocabulary.\n",
      "'#PhoneNumber#' is not in the vocabulary.\n",
      "'#PassportNumber#' is not in the vocabulary.\n",
      "'#Email#' is not in the vocabulary.\n",
      "'#CardNumber#' is not in the vocabulary.\n",
      "'#Address#' is not in the vocabulary.\n",
      "'#DateOfBirth#' is not in the vocabulary.\n",
      "'#Person4#' is not in the vocabulary.\n",
      "'#Person7#' is not in the vocabulary.\n",
      "'#Person3#' is not in the vocabulary.\n",
      "'#Person2#' is not in the vocabulary.\n",
      "'#Person#' is not in the vocabulary.\n",
      "'#Person6#' is not in the vocabulary.\n",
      "'#Person5#' is not in the vocabulary.\n",
      "'#Person1#' is not in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "special_tokens = ['#CarNumber#', '#SSN#', '#PhoneNumber#', '#PassportNumber#', '#Email#', '#CardNumber#', '#Address#', '#DateOfBirth#', \\\n",
    "'#Person4#', '#Person7#', '#Person3#', '#Person2#', '#Person#', '#Person6#', '#Person5#', '#Person1#']\n",
    "for token in special_tokens:\n",
    "    if token in tokenizer.get_vocab():\n",
    "        print(f\"'{token}' is already in the vocabulary.\")\n",
    "    else:\n",
    "        print(f\"'{token}' is not in the vocabulary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 50358\n",
      "New vocab size: 50374\n"
     ]
    }
   ],
   "source": [
    "original_vocab_size = len(tokenizer)\n",
    "\n",
    "special_tokens = ['#CarNumber#', '#SSN#', '#PhoneNumber#', '#PassportNumber#', '#Email#', '#CardNumber#', '#Address#', '#DateOfBirth#', \\\n",
    "'#Person4#', '#Person7#', '#Person3#', '#Person2#', '#Person#', '#Person6#', '#Person5#', '#Person1#']\n",
    "#tokenizer.add_special_tokens({'additional_special_tokens': special_tokens})\n",
    "tokenizer.add_tokens(special_tokens)\n",
    "new_vocab_size = len(tokenizer)\n",
    "\n",
    "print(f\"Original vocab size: {original_vocab_size}\")\n",
    "print(f\"New vocab size: {new_vocab_size}\")\n",
    "\n",
    "# Original vocab size: 50358\n",
    "# New vocab size: 50374"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizer í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE:\n",
      "#Person1#: ì•ˆë…•í•˜ì„¸ìš”, ìŠ¤ë¯¸ìŠ¤ì”¨. ì €ëŠ” í˜¸í‚¨ìŠ¤ ì˜ì‚¬ìž…ë‹ˆë‹¤. ì˜¤ëŠ˜ ì™œ ì˜¤ì…¨ë‚˜ìš”?\n",
      "#Person2#: ê±´ê°•ê²€ì§„ì„ ë°›ëŠ” ê²ƒì´ ì¢‹ì„ ê²ƒ ê°™ì•„ì„œìš”.\n",
      "#Person1#: ê·¸ë ‡êµ°ìš”, ë‹¹ì‹ ì€ 5ë…„ ë™ì•ˆ ê±´ê°•ê²€ì§„ì„ ë°›ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë§¤ë…„ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤.\n",
      "#Person2#: ì•Œê³  ìžˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì•„ë¬´ ë¬¸ì œê°€ ì—†ë‹¤ë©´ ì™œ ì˜ì‚¬ë¥¼ ë§Œë‚˜ëŸ¬ ê°€ì•¼ í•˜ë‚˜ìš”?\n",
      "#Person1#: ì‹¬ê°í•œ ì§ˆë³‘ì„ í”¼í•˜ëŠ” ê°€ìž¥ ì¢‹ì€ ë°©ë²•ì€ ì´ë¥¼ ì¡°ê¸°ì— ë°œê²¬í•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ê·¸ëŸ¬ë‹ˆ ë‹¹ì‹ ì˜ ê±´ê°•ì„ ìœ„í•´ ìµœì†Œí•œ ë§¤ë…„ í•œ ë²ˆì€ ì˜¤ì„¸ìš”.\n",
      "#Person2#: ì•Œê² ìŠµë‹ˆë‹¤.\n",
      "#Person1#: ì—¬ê¸° ë³´ì„¸ìš”. ë‹¹ì‹ ì˜ ëˆˆê³¼ ê·€ëŠ” ê´œì°®ì•„ ë³´ìž…ë‹ˆë‹¤. ê¹Šê²Œ ìˆ¨ì„ ë“¤ì´ì‰¬ì„¸ìš”. ìŠ¤ë¯¸ìŠ¤ì”¨, ë‹´ë°° í”¼ìš°ì‹œë‚˜ìš”?\n",
      "#Person2#: ë„¤.\n",
      "#Person1#: ë‹¹ì‹ ë„ ì•Œë‹¤ì‹œí”¼, ë‹´ë°°ëŠ” íì•”ê³¼ ì‹¬ìž¥ë³‘ì˜ ì£¼ìš” ì›ì¸ìž…ë‹ˆë‹¤. ì •ë§ë¡œ ëŠìœ¼ì…”ì•¼ í•©ë‹ˆë‹¤. \n",
      "#Person2#: ìˆ˜ë°± ë²ˆ ì‹œë„í–ˆì§€ë§Œ, ìŠµê´€ì„ ë²„ë¦¬ëŠ” ê²ƒì´ ì–´ë µìŠµë‹ˆë‹¤.\n",
      "#Person1#: ìš°ë¦¬ëŠ” ë„ì›€ì´ ë  ìˆ˜ ìžˆëŠ” ìˆ˜ì—…ê³¼ ì•½ë¬¼ë“¤ì„ ì œê³µí•˜ê³  ìžˆìŠµë‹ˆë‹¤. ë‚˜ê°€ê¸° ì „ì— ë” ë§Žì€ ì •ë³´ë¥¼ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "#Person2#: ì•Œê² ìŠµë‹ˆë‹¤, ê°ì‚¬í•©ë‹ˆë‹¤, ì˜ì‚¬ì„ ìƒë‹˜.\n",
      "\n",
      "ENCODED SENTENCE:\n",
      "[50373, 27, 222, 1381, 963, 13, 222, 14563, 796, 15, 222, 425, 274, 222, 528, 21693, 222, 2183, 535, 15, 222, 805, 222, 997, 222, 29297, 296, 32, 200, 50369, 27, 222, 1323, 6831, 291, 222, 1760, 222, 398, 262, 222, 2150, 222, 398, 222, 2585, 296, 15, 200, 50373, 27, 222, 5367, 296, 13, 222, 1837, 311, 222, 22, 482, 222, 1063, 222, 1323, 6831, 291, 222, 3629, 222, 6136, 15, 222, 4376, 222, 5467, 222, 550, 15, 200, 50369, 27, 222, 1500, 222, 738, 15, 222, 890, 222, 1129, 222, 871, 278, 222, 7203, 222, 997, 222, 2183, 333, 222, 14123, 222, 2240, 222, 42536, 32, 200, 50373, 27, 222, 6747, 222, 5153, 291, 222, 15508, 222, 985, 222, 810, 222, 933, 311, 222, 16469, 222, 434, 3945, 222, 2384, 429, 222, 398, 535, 15, 222, 5380, 222, 1837, 302, 222, 1323, 291, 222, 863, 222, 6252, 222, 4376, 222, 305, 222, 490, 311, 222, 4669, 15, 200, 50369, 27, 222, 7587, 15, 200, 50373, 27, 222, 1005, 222, 1473, 15, 222, 1837, 302, 222, 803, 381, 222, 886, 274, 222, 4193, 222, 3912, 15, 222, 9494, 222, 1664, 291, 222, 3708, 26309, 15, 222, 14563, 796, 13, 222, 4265, 222, 23572, 2956, 296, 32, 200, 50369, 27, 222, 449, 15, 200, 50373, 27, 222, 1837, 301, 222, 33914, 13, 222, 4265, 274, 222, 1393, 1105, 381, 222, 4245, 761, 302, 222, 2293, 222, 2779, 535, 15, 222, 861, 293, 222, 2567, 17010, 222, 550, 15, 222, 200, 50369, 27, 222, 9376, 222, 490, 222, 3156, 1832, 13, 222, 2370, 291, 222, 6016, 222, 398, 262, 222, 8918, 15, 200, 50373, 27, 222, 699, 274, 222, 1436, 262, 222, 764, 222, 334, 222, 491, 222, 1796, 381, 222, 6936, 5672, 222, 1239, 443, 222, 738, 15, 222, 9272, 222, 353, 279, 222, 451, 222, 882, 222, 889, 333, 222, 2793, 15, 200, 50369, 27, 222, 7587, 13, 222, 835, 550, 13, 222, 2183, 1746, 549, 15, 1]\n",
      "\n",
      "DECODED SENTENCE:\n",
      "#Person1#: ì•ˆë…•í•˜ì„¸ìš”, ìŠ¤ë¯¸ìŠ¤ì”¨. ì €ëŠ” í˜¸í‚¨ìŠ¤ ì˜ì‚¬ìž…ë‹ˆë‹¤. ì˜¤ëŠ˜ ì™œ ì˜¤ì…¨ë‚˜ìš”?\n",
      "#Person2#: ê±´ê°•ê²€ì§„ì„ ë°›ëŠ” ê²ƒì´ ì¢‹ì„ ê²ƒ ê°™ì•„ì„œìš”.\n",
      "#Person1#: ê·¸ë ‡êµ°ìš”, ë‹¹ì‹ ì€ 5ë…„ ë™ì•ˆ ê±´ê°•ê²€ì§„ì„ ë°›ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë§¤ë…„ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤.\n",
      "#Person2#: ì•Œê³  ìžˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì•„ë¬´ ë¬¸ì œê°€ ì—†ë‹¤ë©´ ì™œ ì˜ì‚¬ë¥¼ ë§Œë‚˜ëŸ¬ ê°€ì•¼ í•˜ë‚˜ìš”?\n",
      "#Person1#: ì‹¬ê°í•œ ì§ˆë³‘ì„ í”¼í•˜ëŠ” ê°€ìž¥ ì¢‹ì€ ë°©ë²•ì€ ì´ë¥¼ ì¡°ê¸°ì— ë°œê²¬í•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤. ê·¸ëŸ¬ë‹ˆ ë‹¹ì‹ ì˜ ê±´ê°•ì„ ìœ„í•´ ìµœì†Œí•œ ë§¤ë…„ í•œ ë²ˆì€ ì˜¤ì„¸ìš”.\n",
      "#Person2#: ì•Œê² ìŠµë‹ˆë‹¤.\n",
      "#Person1#: ì—¬ê¸° ë³´ì„¸ìš”. ë‹¹ì‹ ì˜ ëˆˆê³¼ ê·€ëŠ” ê´œì°®ì•„ ë³´ìž…ë‹ˆë‹¤. ê¹Šê²Œ ìˆ¨ì„ ë“¤ì´ì‰¬ì„¸ìš”. ìŠ¤ë¯¸ìŠ¤ì”¨, ë‹´ë°° í”¼ìš°ì‹œë‚˜ìš”?\n",
      "#Person2#: ë„¤.\n",
      "#Person1#: ë‹¹ì‹ ë„ ì•Œë‹¤ì‹œí”¼, ë‹´ë°°ëŠ” íì•”ê³¼ ì‹¬ìž¥ë³‘ì˜ ì£¼ìš” ì›ì¸ìž…ë‹ˆë‹¤. ì •ë§ë¡œ ëŠìœ¼ì…”ì•¼ í•©ë‹ˆë‹¤. \n",
      "#Person2#: ìˆ˜ë°± ë²ˆ ì‹œë„í–ˆì§€ë§Œ, ìŠµê´€ì„ ë²„ë¦¬ëŠ” ê²ƒì´ ì–´ë µìŠµë‹ˆë‹¤.\n",
      "#Person1#: ìš°ë¦¬ëŠ” ë„ì›€ì´ ë  ìˆ˜ ìžˆëŠ” ìˆ˜ì—…ê³¼ ì•½ë¬¼ë“¤ì„ ì œê³µí•˜ê³  ìžˆìŠµë‹ˆë‹¤. ë‚˜ê°€ê¸° ì „ì— ë” ë§Žì€ ì •ë³´ë¥¼ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "#Person2#: ì•Œê² ìŠµë‹ˆë‹¤, ê°ì‚¬í•©ë‹ˆë‹¤, ì˜ì‚¬ì„ ìƒë‹˜.\n"
     ]
    }
   ],
   "source": [
    "# ìž‘ë™ ìž˜ ë˜ëŠ”ì§€ í™•ì¸\n",
    "# Define a test sentence\n",
    "sentence = dataset[\"train\"]['dialogue'][0]\n",
    "\n",
    "\n",
    "# Encode the sentence using the tokenizer, returning PyTorch tensors\n",
    "sentence_encoded = tokenizer(sentence, \n",
    "                             truncation=True, \n",
    "                             add_special_tokens=True)\n",
    "\n",
    "# Decode the encoded sentence, skipping special tokens\n",
    "sentence_decoded = tokenizer.decode(\n",
    "        sentence_encoded[\"input_ids\"], \n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "# Print SENTENCE\n",
    "print('SENTENCE:')\n",
    "print(sentence)\n",
    "\n",
    "# Print the encoded sentence's representation\n",
    "print('\\nENCODED SENTENCE:')\n",
    "print(sentence_encoded[\"input_ids\"])\n",
    "\n",
    "# Print the decoded sentence\n",
    "print('\\nDECODED SENTENCE:')\n",
    "print(sentence_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing Using Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Zero Shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(50358, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(50358, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(50358, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50358, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab size: 50374\n",
      "New vocab size: 195808\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get the original vocabulary size\n",
    "original_vocab_size = len(tokenizer)\n",
    "print(f\"Original vocab size: {original_vocab_size}\")\n",
    "\n",
    "# Define a function to extract unique words from text\n",
    "def extract_unique_words(dataset_column):\n",
    "    unique_words = set()\n",
    "    for sentence in dataset_column:\n",
    "        words = sentence.split()  # Simple split, adjust with tokenizer if needed\n",
    "        unique_words.update(words)\n",
    "    return unique_words\n",
    "\n",
    "# Step 1: Extract unique words from the dataset\n",
    "unique_words_train_dialogue = extract_unique_words(dataset['train']['dialogue'])\n",
    "unique_words_train_summary = extract_unique_words(dataset['train']['summary'])\n",
    "unique_words_val_dialogue = extract_unique_words(dataset['val']['dialogue'])\n",
    "unique_words_val_summary = extract_unique_words(dataset['val']['summary'])\n",
    "\n",
    "# Step 2: Extract unique words from the test set\n",
    "test = pd.read_csv('/data/ephemeral/home/data/test.csv')\n",
    "unique_words_test_dialogue = extract_unique_words(test['dialogue'])\n",
    "\n",
    "# Combine all unique words\n",
    "all_unique_words = unique_words_train_dialogue | unique_words_train_summary | unique_words_val_dialogue | unique_words_val_summary | unique_words_test_dialogue\n",
    "\n",
    "# Step 3: Add these unique words to the tokenizer vocabulary\n",
    "tokenizer.add_tokens(list(set(all_unique_words)))\n",
    "\n",
    "# Step 4: Check the new vocabulary size\n",
    "new_vocab_size = len(tokenizer)\n",
    "print(f\"New vocab size: {new_vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Zero Shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ENCODED SENTENCE:\n",
      "tensor([[ 54883,    222,  80742,    222, 132110,    222,  87673,   1496,     27,\n",
      "            200,  84037,    222, 154137,    222, 157557,    222, 181610,    222,\n",
      "          79309,    222,  77117,    222, 185842,    222,  96891,    222, 178248,\n",
      "            200,  94525,    222, 105686,    222, 159632,    222, 124699,    222,\n",
      "          89268,    222,  72668,    222,  80201,    200,  84037,    222, 148923,\n",
      "            222, 159244,    222,  55032,    222,  98756,    222, 105686,    222,\n",
      "          95426,    222, 181071,    222, 182897,    222,  76739,    222, 113915,\n",
      "            200,  94525,    222,  67100,    222,  61758,    222,  80559,    222,\n",
      "         188558,    222, 176692,    222, 150619,    222,  96891,    222, 169610,\n",
      "            222,  73772,    222, 172848,    222,  81850,    200,  84037,    222,\n",
      "          90448,    222,  52227,    222, 111605,    222,  90272,    222,  86731,\n",
      "            222,  59618,    222,  86698,    222, 144898,    222, 132333,    222,\n",
      "          77292,    222, 105703,    222,  85681,    222,  80319,    222, 133806,\n",
      "            222, 188494,    222, 182897,    222, 130391,    222, 124099,    222,\n",
      "         195292,    200,  94525,    222, 127189,    200,  84037,    222, 144029,\n",
      "            222, 194736,    222,  85681,    222, 166489,    222, 155782,    222,\n",
      "         195541,    222,  70245,    222, 185718,    222, 133873,    222, 120971,\n",
      "            222,  79493,    222, 117421,    222, 111589,    200,  94525,    222,\n",
      "         136337,    200,  84037,    222, 101445,    222, 159256,    222, 112956,\n",
      "            222, 142733,    222, 128727,    222,  64938,    222,  71561,    222,\n",
      "         150002,    222, 130202,    222, 113915,    222,    200,  94525,    222,\n",
      "         170603,    222,  60026,    222, 178540,    222, 181979,    222,  81260,\n",
      "            222, 124699,    222,  97698,    200,  84037,    222,  58452,    222,\n",
      "         111276,    222, 133693,    222, 184477,    222,  67098,    222,  65780,\n",
      "            222,  90736,    222,  68583,    222,  61758,    222, 180061,    222,\n",
      "         137499,    222,  97189,    222, 189671,    222,  88895,    222, 160149,\n",
      "            200,  94525,    222, 143881,    222, 179629,    222,  67103,    200,\n",
      "              1]])\n",
      "\n",
      "DECODED SENTENCE:\n",
      "Thank you so much for your help in the process of developing a new technology.\n",
      "\n",
      "GOLDEN:\n",
      "ìŠ¤ë¯¸ìŠ¤ì”¨ê°€ ê±´ê°•ê²€ì§„ì„ ë°›ê³  ìžˆê³ , í˜¸í‚¨ìŠ¤ ì˜ì‚¬ëŠ” ë§¤ë…„ ê±´ê°•ê²€ì§„ì„ ë°›ëŠ” ê²ƒì„ ê¶Œìž¥í•©ë‹ˆë‹¤. í˜¸í‚¨ìŠ¤ ì˜ì‚¬ëŠ” ìŠ¤ë¯¸ìŠ¤ì”¨ê°€ ë‹´ë°°ë¥¼ ëŠëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìžˆëŠ” ìˆ˜ì—…ê³¼ ì•½ë¬¼ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•  ê²ƒìž…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# zero shot\n",
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "# load model from the hub\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_id)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "\n",
    "# Define a test sentence\n",
    "sentence = dataset[\"train\"]['dialogue'][0]\n",
    "golden = dataset[\"train\"]['summary'][0]\n",
    "\n",
    "instruction = f\"\"\"ë‹¤ìŒ ëŒ€í™”ë¥¼ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì¤˜:\\n{sentence}\n",
    "\"\"\"\n",
    "#instruction = [\"Please summarize the conversation by clearly stating what each speaker did or said. : \" +sentence]\n",
    "# instruction = [\"In this '#Person1#: Hello, Mr. Smith. I'm Dr. Hawkins.' dialogue, the speaker is #Person1#. \\\n",
    "#     Summarize the conversation with a focus on the speakers, ensuring that each speaker's name or identifier, such as #Person1#, is accurately used as the subject in the summary. : \" + sentence]\n",
    "# Encode the sentence using the tokenizer, returning PyTorch tensors\n",
    "sentence_encoded = tokenizer(instruction, \n",
    "                             max_length=max_source_length, \n",
    "                             padding=\"longest\", \n",
    "                             truncation=True, \n",
    "                             add_special_tokens=True,\n",
    "                             return_tensors=\"pt\")  # Ensure tensors are returned for model input\n",
    "\n",
    "# Generate the summary using the model\n",
    "summary_ids = model.generate(\n",
    "    sentence_encoded[\"input_ids\"], \n",
    "    max_length=max_target_length, \n",
    "    min_length=40, \n",
    "    num_beams=5,  # Optional: control the generation strategy\n",
    "    early_stopping=True,  # Optional: stop early when all beams are finished\n",
    "    no_repeat_ngram_size=2\n",
    ")\n",
    "\n",
    "# Decode the encoded sentence, skipping special tokens\n",
    "sentence_decoded = tokenizer.decode(\n",
    "    summary_ids[0],  # Select the first (and usually only) sequence generated\n",
    "    skip_special_tokens=True  # Skip special tokens in the final output\n",
    "    )\n",
    "\n",
    "# Print the encoded sentence's representation\n",
    "print('\\nENCODED SENTENCE:')\n",
    "print(sentence_encoded[\"input_ids\"])\n",
    "\n",
    "# Print the decoded sentence\n",
    "print('\\nDECODED SENTENCE:')\n",
    "print(sentence_decoded)\n",
    "\n",
    "# Print SENTENCE\n",
    "print('\\nGOLDEN:')\n",
    "print(golden)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying One Shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(example_indices_full, example_index_to_summarize):\n",
    "    prompt = ''\n",
    "    for index in example_indices_full:\n",
    "        dialogue = dataset['train']['dialogue'][index]\n",
    "        summary = dataset['train']['summary'][index]\n",
    "\n",
    "        # The stop sequence '{summary}\\n\\n\\n' is important for FLAN-T5. Other models may have their own preferred stop sequence.\n",
    "        prompt += f\"\"\"ëŒ€í™”:{dialogue}\\nëŒ€í™”ë‚´ìš©ìš”ì•½:{summary}\"\"\"\n",
    "\n",
    "    dialogue = dataset['train']['dialogue'][example_index_to_summarize]\n",
    "\n",
    "    prompt += f\"\"\"ëŒ€í™”:{dialogue}\\nëŒ€í™”ë‚´ìš©ìš”ì•½:\"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëŒ€í™”:#Person1#: ì•ˆë…•í•˜ì„¸ìš”, íŒŒì»¤ ë¶€ì¸, ì–´ë–»ê²Œ ì§€ë‚´ì…¨ë‚˜ìš”?\n",
      "#Person2#: ì•ˆë…•í•˜ì„¸ìš”, í”¼í„°ìŠ¤ ë°•ì‚¬ë‹˜. ìž˜ ì§€ëƒˆìŠµë‹ˆë‹¤, ê°ì‚¬í•©ë‹ˆë‹¤. ë¦¬í‚¤ì™€ í•¨ê»˜ ë°±ì‹  ì ‘ì¢…ì„ ìœ„í•´ ì™”ìŠµë‹ˆë‹¤.\n",
      "#Person1#: ì¢‹ìŠµë‹ˆë‹¤. ë°±ì‹  ì ‘ì¢… ê¸°ë¡ì„ ë³´ë‹ˆ, ë¦¬í‚¤ëŠ” ì´ë¯¸ ì†Œì•„ë§ˆë¹„, ë””í”„í…Œë¦¬ì•„, Bí˜• ê°„ì—¼ ë°±ì‹ ì„ ë§žì•˜êµ°ìš”. ê·¸ëŠ” 14ê°œì›”ì´ë¯€ë¡œ, ì´ì œ Aí˜• ê°„ì—¼, ìˆ˜ë‘, í™ì—­ ë°±ì‹ ì„ ë§žì•„ì•¼ í•©ë‹ˆë‹¤.\n",
      "#Person2#: í’ì§„ê³¼ ë³¼ê±°ë¦¬ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n",
      "#Person1#: ì§€ê¸ˆì€ ì´ ë°±ì‹ ë“¤ë§Œ ì ‘ì¢…í•  ìˆ˜ ìžˆê³ , ëª‡ ì£¼ í›„ì— ë‚˜ë¨¸ì§€ë¥¼ ì ‘ì¢…í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "#Person2#: ì¢‹ìŠµë‹ˆë‹¤. ë°•ì‚¬ë‹˜, ì €ë„ ë””í”„í…Œë¦¬ì•„ ì˜ˆë°©ì ‘ì¢…ì´ í•„ìš”í•  ê²ƒ ê°™ì•„ìš”. ë§ˆì§€ë§‰ìœ¼ë¡œ ë§žì€ ê²Œ ì•„ë§ˆë„ 15ë…„ ì „ì´ì—ˆë˜ ê²ƒ ê°™ì•„ìš”!\n",
      "#Person1#: ì €í¬ê°€ ê¸°ë¡ì„ í™•ì¸í•˜ê³  ê°„í˜¸ì‚¬ì—ê²Œ ë¶€ìŠ¤í„°ë¥¼ ì ‘ì¢…í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ì´ì œ, ë¦¬í‚¤ì˜ íŒ”ì„ ê½‰ ìž¡ì•„ì£¼ì„¸ìš”, ì¡°ê¸ˆ ì°Œë¦¿í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "ëŒ€í™”ë‚´ìš©ìš”ì•½:íŒŒì»¤ ë¶€ì¸ì´ ë¦¬í‚¤ë¥¼ ë°ë¦¬ê³  ë°±ì‹  ì ‘ì¢…ì„ í•˜ëŸ¬ ê°”ë‹¤. í”¼í„°ìŠ¤ ë°•ì‚¬ëŠ” ê¸°ë¡ì„ í™•ì¸í•œ í›„ ë¦¬í‚¤ì—ê²Œ ë°±ì‹ ì„ ì ‘ì¢…í–ˆë‹¤.ëŒ€í™”:#Person1#: ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "#Person2#: MP-3 í”Œë ˆì´ì–´ë¥¼ ì°¾ê³  ìžˆì–´ìš”. ì–´ë–¤ ë¸Œëžœë“œê°€ ê°€ìž¥ í’ˆì§ˆì´ ì¢‹ë‚˜ìš”?\n",
      "#Person1#: íŒŒì´ì˜¤ë‹ˆì–´ë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.\n",
      "#Person2#: ì–´ë–¤ ëª¨ë¸ì´ ê°€ìž¥ ìž˜ íŒ”ë¦¬ë‚˜ìš”?\n",
      "#Person1#: ì´ ëª¨ë¸ì´ ì—¬ì„±ë“¤ì—ê²Œ ë§¤ìš° ì¸ê¸°ê°€ ìžˆìŠµë‹ˆë‹¤.\n",
      "#Person2#: ê·¸ê²ƒì„ ë³¼ ìˆ˜ ìžˆì„ê¹Œìš”?\n",
      "#Person1#: ë¬¼ë¡ ìž…ë‹ˆë‹¤, ì´ê²ƒì€ ë‹¤ê¸°ëŠ¥ìž…ë‹ˆë‹¤. ìŒì•…ì„ ìž¬ìƒí•˜ëŠ” ê²ƒ ì™¸ì—ë„ ë¬¸ì„œë¥¼ ì €ìž¥í•˜ê³  ë…¹ìŒí•˜ëŠ” ë°ë„ ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "#Person2#: ì´ ëª¨ë¸ì„ í°ìƒ‰ìœ¼ë¡œ ê°€ì§€ê³  ê³„ì‹ ê°€ìš”?\n",
      "#Person1#: ì•„ë‹ˆìš”, í•˜ì§€ë§Œ ë…¸ëž€ìƒ‰ì€ ìžˆìŠµë‹ˆë‹¤.\n",
      "#Person2#: ê·¸ëŸ¼ ë…¸ëž€ìƒ‰ìœ¼ë¡œ í• ê²Œìš”.\n",
      "#Person1#: ìž ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”. ê°€ì ¸ë‹¤ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "#Person2#: ì•Œê² ì–´ìš”.\n",
      "ëŒ€í™”ë‚´ìš©ìš”ì•½:\n"
     ]
    }
   ],
   "source": [
    "example_indices_full = [1]\n",
    "example_index_to_summarize = 101\n",
    "\n",
    "one_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
    "\n",
    "print(one_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE HUMAN SUMMARY:\n",
      "#Person2#ëŠ” MP-3 í”Œë ˆì´ì–´ë¥¼ ì°¾ê³  ìžˆìŠµë‹ˆë‹¤. #Person1#ëŠ” íŒŒì´ì˜¤ë‹ˆì–´ë¥¼ ì¶”ì²œí•˜ê³  #Person2#ëŠ” ë…¸ëž€ìƒ‰ì„ ì„ íƒí•©ë‹ˆë‹¤.\n",
      "\n",
      "MODEL GENERATION - ONE SHOT:\n",
      "20ëŒ€ì—¬ì„±: #@ì‹œìŠ¤í…œ#ì‚¬ì§„#\n",
      "30ëŒ€ë‚¨ì„±:..??!!?\n",
      "40ëŒ€ê¸°í˜¼:,,?,\n",
      "50ëŒ€ë¯¸í˜¼:-_--,-/-á…³á…³-;;,//;::;\n",
      "60ëŒ€ìž„ë¶€:/_/:__á…³\n",
      "70ëŒ€ìž„ì‚°ë¶€ë„ ê´œì°®ìœ¼ë ¤ë‚˜? á„á„\n",
      "200ëª…ì¤‘ í•œëª…ì€ ê´œì°®ì€ë° ë‚˜ë¨¸ì§€ëŠ” ì•„ì˜ˆ ì•ˆë³´ì—¬ì„œ ì•„ì‰½ë”ë¼ á…²á…² í‘í‘ á…®á…®\n",
      "190ëª… ì¤‘ì— 160ëª…ì´ ê³¼ì²´ì¤‘ì´ë¼ ê·¸ëŸ°ì§€ ëª¸ë¬´ê²Œê°€ ì—„ì²­ ë¬´ê±°ì› ì–´ìš” ^^ á„’\n",
      "150ëª…ì˜ ìž„ì‚°ë¶€ëŠ” ë‹¤ì´ì–´íŠ¸ ì—´ì‹¬ížˆ í•˜ê³  ìžˆëŒ€ìš”. í—ˆí—ˆí—ˆ.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model understanding more context of the conversation with one shot inference\n",
    "\n",
    "summary = dataset['train']['summary'][example_index_to_summarize]\n",
    "\n",
    "inputs = tokenizer(one_shot_prompt, #truncation=True, \n",
    "                             add_special_tokens=True,\n",
    "                             return_tensors=\"pt\")\n",
    "output = tokenizer.decode(\n",
    "    model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=max_target_length,\n",
    "        min_length=40, \n",
    "        num_beams=5,  # Optional: control the generation strategy\n",
    "        early_stopping=True,  # Optional: stop early when all beams are finished\n",
    "        no_repeat_ngram_size=2\n",
    "        )[0],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "#print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "#print(dash_line)\n",
    "print(f'MODEL GENERATION - ONE SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying few Shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m example_indices_full \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m51\u001b[39m]\n\u001b[1;32m      2\u001b[0m example_index_to_summarize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m101\u001b[39m\n\u001b[0;32m----> 4\u001b[0m few_shot_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mmake_prompt\u001b[49m(example_indices_full, example_index_to_summarize)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(few_shot_prompt)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_prompt' is not defined"
     ]
    }
   ],
   "source": [
    "example_indices_full = [11, 21, 51]\n",
    "example_index_to_summarize = 101\n",
    "\n",
    "few_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
    "\n",
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE HUMAN SUMMARY:\n",
      "#Person2# is looking for an MP-3 player. #Person1# recommends a pioneer and #Person2# chooses yellow.\n",
      "\n",
      "MODEL GENERATION - FEW SHOT:\n",
      "rien is looking for an MP-3 player. He wants to buy it in yellow.\n"
     ]
    }
   ],
   "source": [
    "summary = dataset['train']['summary_en'][example_index_to_summarize]\n",
    "\n",
    "inputs = tokenizer(few_shot_prompt, return_tensors='pt', add_special_tokens=True)\n",
    "output = tokenizer.decode(\n",
    "    model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=50,\n",
    "    )[0],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "#print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "#print(dash_line)\n",
    "print(f'MODEL GENERATION - FEW SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ê²°ë¡ : TOKENIZER ìˆ˜ì •ë³´ë‹¤ ONE SHOT, FEW SHOT INFERENCEê°€ ë‚«ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5ForConditionalGeneration(\n",
      "  (shared): Embedding(50358, 1024)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(50358, 1024)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 16)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-23): 23 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(50358, 1024)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 16)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-23): 23 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=50358, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_instruct = \"\"\"Dialogue:\n",
    "\n",
    "#Person1#: We should check in at the Air China counter half an hour before takeoff, Joy.\n",
    "#Person2#: Yeah, I know. The boarding time on the ticket is 17:05, and it's 16:15 now. I think we have enough time.\n",
    "#Person1#: Do we need to show our IDs when we check in?\n",
    "#Person2#: Yeah, that's a must.\n",
    "#Person1#: What about our luggage?\n",
    "#Person2#: We can check in our luggage and carry our small bags in our hands. And we need to open each of them for inspection.\n",
    "#Person1#: Do you think they will search every passenger?\n",
    "#Person2#: I think so. We definitely don't want to have a hijacking incident on the plane today, do we?\n",
    "\n",
    "What was going on?\n",
    "#Person1# asks #Person2# what to do when checking in at the Air China counter.\n",
    "\n",
    "Dialogue:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë‹¨ì–´ ìˆ˜ ê³„ì‚°\n",
    "word_count = len(one_shot_instruct.split())\n",
    "\n",
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(one_shot_instruct, return_tensors='pt')['input_ids'].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a69eb2ce3fb4688960d25bc3db7be8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/499 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(sample, padding=\"max_length\"):\n",
    "    # one_shot_instructë¥¼ í† í°í™”í•˜ì—¬ í† í° ìˆ˜ë¥¼ ê³„ì‚°\n",
    "    instruction_tokens = tokenizer(one_shot_instruct, return_tensors='pt')['input_ids'].shape[-1]\n",
    "    \n",
    "    # ëŒ€í™” ë‚´ìš©ì„ í”„ë¡¬í”„íŠ¸ì™€ ê²°í•©í•˜ì—¬ ìž…ë ¥ ìƒì„±\n",
    "    inputs = [one_shot_instruct + item + \" What was going on?\" for item in sample[\"dialogue_en\"]]\n",
    "\n",
    "    # max_lengthì— í”„ë¡¬í”„íŠ¸ì˜ í† í° ìˆ˜ë¥¼ ê³ ë ¤í•œ ê¸¸ì´ë¥¼ ì„¤ì •\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length + instruction_tokens, padding=padding, truncation=True, add_special_tokens=True)\n",
    "\n",
    "    # íƒ€ê²Ÿ(summary_en)ë„ í† í°í™”\n",
    "    labels = tokenizer(text_target=sample[\"summary_en\"], max_length=max_target_length, padding=padding, truncation=True)\n",
    "\n",
    "    # íŒ¨ë”© í† í°ì„ -100ìœ¼ë¡œ êµì²´í•˜ì—¬ ì†ì‹¤ ê³„ì‚°ì— ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•Šë„ë¡ ì²˜ë¦¬\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# ë°ì´í„°ì…‹ì— ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ì ìš©\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=['fname', 'dialogue', 'summary', 'topic', 'dialogue_en', 'summary_en', 'topic_en'])\n",
    "\n",
    "# ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ì˜ í‚¤ ì¶œë ¥\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fine-tune and evaluate FLAN-T5\n",
    "\n",
    "After we have processed our dataset, we can start training our model. Therefore we first need to load our [FLAN-T5](https://huggingface.co/models?search=flan-t5) from the Hugging Face Hub. In the example we are using a instance with a NVIDIA V100 meaning that we will fine-tune the `base` version of the model. \n",
    "_I plan to do a follow-up post on how to fine-tune the `xxl` version of the model using Deepspeed._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„œìš¸íŠ¹ë³„ì‹œ\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5TokenizerFast\n",
    "\n",
    "tokenizer = T5TokenizerFast.from_pretrained('paust/pko-flan-t5-large')\n",
    "model = T5ForConditionalGeneration.from_pretrained('paust/pko-flan-t5-large')\n",
    "\n",
    "prompt = \"\"\"ì„œìš¸íŠ¹ë³„ì‹œ(ì„œìš¸ç‰¹åˆ¥å¸‚, ì˜ì–´: Seoul Metropolitan Government)ëŠ” ëŒ€í•œë¯¼êµ­ ìˆ˜ë„ì´ìž ìµœëŒ€ ë„ì‹œì´ë‹¤. ì„ ì‚¬ì‹œëŒ€ë¶€í„° ì‚¬ëžŒì´ ê±°ì£¼í•˜ì˜€ìœ¼ë‚˜ ë³¸ ì—­ì‚¬ëŠ” ë°±ì œ ì²« ìˆ˜ë„ ìœ„ë¡€ì„±ì„ ì‹œì´ˆë¡œ í•œë‹¤. ì‚¼êµ­ì‹œëŒ€ì—ëŠ” ì „ëžµì  ìš”ì¶©ì§€ë¡œì„œ ê³ êµ¬ë ¤, ë°±ì œ, ì‹ ë¼ê°€ ë²ˆê°ˆì•„ ì°¨ì§€í•˜ì˜€ìœ¼ë©°, ê³ ë ¤ ì‹œëŒ€ì—ëŠ” ì™•ì‹¤ì˜ ë³„ê¶ì´ ì„¸ì›Œì§„ ë‚¨ê²½(å—äº¬)ìœ¼ë¡œ ì´ë¦„í•˜ì˜€ë‹¤.\n",
    "í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ìž…ë‹ˆê¹Œ?\"\"\"\n",
    "input_ids = tokenizer(prompt, add_special_tokens=True, return_tensors='pt').input_ids\n",
    "output_ids = model.generate(input_ids=input_ids, max_new_tokens=32, num_beams=12)\n",
    "text = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0]\n",
    "print(text)  # ì„œìš¸íŠ¹ë³„ì‹œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8685ae2efc46559b60811ed22bb0a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12457 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels[\"input_ids\"][0]: [56123, 222, 105686, 222, 122393, 222, 151113, 222, 79309, 222, 156065, 222, 182897, 222, 105686, 222, 159632, 222, 95433, 222, 168566, 222, 79309, 222, 156065, 222, 56123, 222, 58316, 222, 178311, 222, 129594, 222, 111276, 222, 133693, 222, 184477, 222, 67098, 222, 65780, 222, 56908, 222, 65105, 222, 88895, 222, 149030, 222, 77292, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels[\"input_ids\"][0]: [73979, 222, 171882, 222, 91616, 222, 82061, 222, 96254, 222, 88039, 222, 184324, 222, 191120, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels[\"input_ids\"][0]: [155331, 222, 126895, 222, 112541, 222, 86524, 222, 57112, 222, 170188, 222, 64601, 222, 194855, 222, 53429, 222, 183641, 222, 113915, 222, 186520, 222, 165949, 222, 79856, 222, 148671, 222, 110513, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels[\"input_ids\"][0]: [155331, 222, 161989, 222, 60288, 222, 170259, 222, 156225, 222, 116697, 222, 65105, 222, 88895, 222, 149281, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels[\"input_ids\"][0]: [155331, 222, 185032, 222, 111235, 222, 118138, 222, 159913, 222, 123701, 222, 57112, 222, 170188, 222, 133343, 222, 113915, 222, 63354, 222, 178892, 222, 170543, 222, 176024, 222, 68655, 222, 192797, 222, 188901, 222, 162521, 222, 113975, 222, 147220, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels[\"input_ids\"][0]: [155331, 222, 114532, 222, 182903, 222, 132932, 222, 179881, 222, 194940, 222, 182713, 222, 142831, 222, 159210, 222, 171882, 222, 192716, 222, 142831, 222, 139924, 222, 132722, 222, 159900, 222, 96762, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels[\"input_ids\"][0]: [184182, 222, 98588, 222, 108400, 222, 164896, 222, 155331, 222, 92436, 222, 157670, 222, 109452, 222, 116539, 222, 97243, 222, 111344, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels[\"input_ids\"][0]: [171882, 222, 178892, 222, 114702, 222, 139378, 222, 79348, 222, 96854, 222, 142152, 222, 145655, 222, 127084, 222, 85041, 222, 90272, 222, 135909, 222, 143975, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels[\"input_ids\"][0]: [155331, 222, 106781, 222, 94094, 222, 131774, 222, 85895, 222, 129175, 222, 76693, 222, 129878, 222, 115286, 222, 69345, 222, 145572, 222, 86812, 222, 73979, 222, 171882, 222, 99095, 222, 82434, 222, 161788, 222, 189629, 222, 132306, 222, 108730, 222, 184324, 222, 100373, 222, 155331, 222, 54883, 222, 119681, 222, 171857, 222, 133806, 222, 124996, 222, 181309, 222, 113915, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels[\"input_ids\"][0]: [155331, 222, 114810, 222, 105678, 222, 140968, 222, 104013, 222, 133930, 222, 123701, 222, 89860, 222, 96060, 222, 155331, 222, 125220, 222, 115286, 222, 169612, 222, 109660, 222, 171990, 222, 80559, 222, 97083, 222, 76166, 222, 81087, 222, 113181, 222, 185307, 222, 60182, 222, 193506, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels[\"input_ids\"][0]: [58283, 222, 178892, 222, 189120, 222, 187670, 222, 133566, 222, 67098, 222, 170543, 222, 99278, 222, 79563, 222, 195542, 222, 129951, 222, 66611, 222, 106152, 222, 173309, 222, 87042, 222, 155331, 222, 106711, 222, 89860, 222, 99284, 222, 125736, 222, 146541, 222, 115570, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels[\"input_ids\"][0]: [155331, 222, 192203, 222, 142262, 222, 50369, 222, 178891, 222, 90882, 222, 108029, 222, 116620, 222, 192203, 222, 88525, 222, 161788, 222, 62554, 222, 81821, 222, 113076, 222, 184324, 222, 122022, 222, 112224, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels[\"input_ids\"][0]: [106781, 222, 133189, 222, 111560, 222, 53, 222, 16, 222, 119492, 222, 169920, 222, 105652, 222, 174857, 222, 77504, 222, 192282, 222, 63749, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c3d4f8f66545f29ca05b39d5d7daab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/499 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels[\"input_ids\"][0]: [171882, 222, 149708, 222, 108763, 222, 166194, 222, 156065, 222, 178892, 222, 111980, 222, 184324, 222, 115269, 222, 88515, 222, 61633, 222, 165737, 222, 109031, 222, 140744, 222, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Keys of tokenized dataset: ['dialogue_en', 'summary_en', 'topic_en', 'input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(sample, padding=\"max_length\"):\n",
    "    \n",
    "    # ëŒ€í™” ë‚´ìš©ì„ í”„ë¡¬í”„íŠ¸ì™€ ê²°í•©í•˜ì—¬ ìž…ë ¥ ìƒì„±\n",
    "    inputs = [\"ëŒ€í™”ë¥¼ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì¤˜.\" for item in sample[\"dialogue\"]]\n",
    "\n",
    "    # max_lengthì— í”„ë¡¬í”„íŠ¸ì˜ í† í° ìˆ˜ë¥¼ ê³ ë ¤í•œ ê¸¸ì´ë¥¼ ì„¤ì •\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length + 20, padding=padding, truncation=True, add_special_tokens=True)\n",
    "\n",
    "    # íƒ€ê²Ÿ(summary_en)ë„ í† í°í™”\n",
    "    labels = tokenizer(text_target=sample[\"summary\"], \n",
    "                        max_length=max_target_length, \n",
    "                        padding=padding, \n",
    "                        truncation=True)\n",
    "    \n",
    "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore padding in the loss.\n",
    "    if padding == \"max_length\":\n",
    "        \n",
    "        if isinstance(labels[\"input_ids\"][0], list):  # Check if it is a list of lists\n",
    "            print(f'labels[\"input_ids\"][0]: {labels[\"input_ids\"][0]}')\n",
    "            labels[\"input_ids\"] = [\n",
    "                [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "            ]\n",
    "        else:  # Handle single instance case\n",
    "            print(f'labels[\"input_ids\"]: {labels[\"input_ids\"]}')\n",
    "            labels[\"input_ids\"] = [(l if l != tokenizer.pad_token_id else -100) for l in labels[\"input_ids\"]]\n",
    "\n",
    "\n",
    "    # model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    # return model_inputs\n",
    "    \n",
    "    # with tokenizer.as_target_tokenizer():\n",
    "    #     labels = tokenizer(sample[\"summary\"], max_length=max_target_length, padding=padding, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "# ë°ì´í„°ì…‹ì— ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ì ìš©\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=['fname', 'dialogue', 'summary', 'topic'])\n",
    "\n",
    "# ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ì˜ í‚¤ ì¶œë ¥\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /data/ephemeral/home/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Metric\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "# helper function to postprocess text\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    \n",
    "    # ì •ìˆ˜ ë°°ì—´ë¡œ ë³€í™˜í•˜ê³ , ë²”ìœ„ë¥¼ tokenizerì˜ vocab í¬ê¸°ë¡œ ì œí•œ\n",
    "    preds = np.array(preds, dtype=np.int64)\n",
    "    preds = np.clip(preds, 0, tokenizer.vocab_size - 1)\n",
    "    print(preds)\n",
    "  \n",
    "    # í† í° IDë¥¼ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    print(decoded_preds)\n",
    "    # ë¼ë²¨ì—ì„œ -100ì„ íŒ¨ë”© í† í° IDë¡œ ëŒ€ì²´\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # ë©”íŠ¸ë¦­ ê³„ì‚° í›„ ê²°ê³¼ ë°˜í™˜\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "    \n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoModelForCausalLM, DataCollatorForSeq2Seq\n",
    "from transformers import T5ForConditionalGeneration,T5TokenizerFast\n",
    "\n",
    "# load model from the hub\n",
    "# model = T5ForConditionalGeneration.from_pretrained(model_id)\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# load model from the hub\n",
    "#model = T5TokenizerFast.from_pretrained(model_id)\n",
    "\n",
    "# we want to ignore tokenizer pad token in the loss\n",
    "label_pad_token_id = -100\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=label_pad_token_id,\n",
    "    pad_to_multiple_of=8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3856150448.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    wandb login\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "wandb login\n",
    "# 37ef351873d76557e00679959886f35cb3bbc35c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.81 MiB is free. Process 3316941 has 23.66 GiB memory in use. Of the allocated memory 23.31 GiB is allocated by PyTorch, and 50.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Training ì‹œìž‘\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2279\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2279\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2282\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2283\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2284\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2285\u001b[0m ):\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3318\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3318\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3320\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3323\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3324\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3363\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3362\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3363\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3364\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3365\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/operations.py:820\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/operations.py:808\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1702\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[38;5;66;03m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1701\u001b[0m     \u001b[38;5;66;03m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[0;32m-> 1702\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1703\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[1;32m   1712\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1713\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1714\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1715\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1716\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1012\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to initialize the model with valid token embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1012\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m batch_size, seq_length \u001b[38;5;241m=\u001b[39m input_shape\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# required mask seq length can be calculated via length of past\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 20.81 MiB is free. Process 3316941 has 23.66 GiB memory in use. Of the allocated memory 23.31 GiB is allocated by PyTorch, and 50.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from huggingface_hub import HfFolder\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, EarlyStoppingCallback\n",
    "\n",
    "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ë° ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Hugging Face repository id\n",
    "repository_id = f\"{model_id.split('/')[1]}-{dataset_id}\"\n",
    "\n",
    "# Define training args with additional parameters\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=repository_id,\n",
    "    num_train_epochs=20,  # ì´ 20 ì—í­ ë™ì•ˆ í•™ìŠµ\n",
    "    learning_rate=1e-5,  # í•™ìŠµë¥ \n",
    "    per_device_train_batch_size=1,  # í›ˆë ¨ ì¤‘ í•œ ìž¥ì¹˜ë‹¹ ë°°ì¹˜ í¬ê¸°\n",
    "    per_device_eval_batch_size=1,  # í‰ê°€ ì¤‘ í•œ ìž¥ì¹˜ë‹¹ ë°°ì¹˜ í¬ê¸°\n",
    "    warmup_ratio=0.1,  # ì›Œë°ì—… ë¹„ìœ¨\n",
    "    weight_decay=0.01,  # ê°€ì¤‘ì¹˜ ê°ì‡ \n",
    "    lr_scheduler_type='cosine',  # ì½”ì‚¬ì¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì‚¬ìš©\n",
    "    optim='adamw_torch',  # ì˜µí‹°ë§ˆì´ì €: AdamW ì‚¬ìš©\n",
    "    gradient_accumulation_steps=16,  # ê¸°ìš¸ê¸° ëˆ„ì  ë‹¨ê³„\n",
    "    evaluation_strategy='epoch',  # ì—í­ ë‹¨ìœ„ë¡œ í‰ê°€\n",
    "    save_strategy='epoch',  # ì—í­ ë‹¨ìœ„ë¡œ ì €ìž¥\n",
    "    save_total_limit=5,  # ì´ 5ê°œì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ìž¥\n",
    "    fp16=True,  # mixed precision í•™ìŠµ í™œì„±í™” # Trueë¡œ í•˜ë©´ overflow\n",
    "    load_best_model_at_end=True,  # ê°€ìž¥ ì¢‹ì€ ëª¨ë¸ì„ ë§ˆì§€ë§‰ì— ë¡œë“œ\n",
    "    seed=42,  # ìž¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ê°’\n",
    "    logging_dir=\"./logs\",  # ë¡œê·¸ ë””ë ‰í† ë¦¬\n",
    "    logging_strategy=\"epoch\",  # ì—í­ë§ˆë‹¤ ë¡œê¹…\n",
    "    predict_with_generate=True,  # ìƒì„± ëª¨ë“œë¥¼ ì‚¬ìš©í•  ë•Œ í‰ê°€ ì„¤ì •\n",
    "    generation_max_length=max_target_length,  # ìµœëŒ€ ìƒì„± ê¸¸ì´\n",
    "    do_train=True,  # í•™ìŠµ ì—¬ë¶€\n",
    "    do_eval=True,  # í‰ê°€ ì—¬ë¶€\n",
    ")\n",
    "\n",
    "# Create Trainer instance with early stopping callback\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"val\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(\n",
    "            early_stopping_patience=3,  # 3ë²ˆì˜ ì—í­ ë™ì•ˆ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ ì¤‘ë‹¨\n",
    "            early_stopping_threshold=0.001  # ì„±ëŠ¥ì´ 0.001ë§Œí¼ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ ì¤‘ë‹¨\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# GPU ë©”ëª¨ë¦¬ ìºì‹œë¥¼ ì§€ì›ë‹ˆë‹¤.\n",
    "torch.cuda.empty_cache()\n",
    "# Training ì‹œìž‘\n",
    "trainer.train()\n",
    "# 20 epoch: 13ì‹œê°„ ì˜ˆìƒ\n",
    "# 1 epoch: 0.69ì‹œê°„ ì˜ˆìƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 819\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='103' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [103/103 01:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.3715944290161133,\n",
       " 'eval_rouge1': 47.2358,\n",
       " 'eval_rouge2': 23.5135,\n",
       " 'eval_rougeL': 39.6266,\n",
       " 'eval_rougeLsum': 43.3458,\n",
       " 'eval_gen_len': 17.39072039072039,\n",
       " 'eval_runtime': 108.99,\n",
       " 'eval_samples_per_second': 7.514,\n",
       " 'eval_steps_per_second': 0.945,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best score we achieved is an `rouge1` score of `47.23`. \n",
    "\n",
    "Lets save our results and tokenizer to the Hugging Face Hub and create a model card. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our tokenizer and create model card\n",
    "tokenizer.save_pretrained(repository_id)\n",
    "trainer.create_model_card()\n",
    "# Push the results to the hub\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Inference\n",
    "\n",
    "Now we have a trained model, we can use it to run inference. We will use the `pipeline` API from transformers and a `test` example from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialogue: \n",
      "Abby: Have you talked to Miro?\n",
      "Dylan: No, not really, I've never had an opportunity\n",
      "Brandon: me neither, but he seems a nice guy\n",
      "Brenda: you met him yesterday at the party?\n",
      "Abby: yes, he's so interesting\n",
      "Abby: told me the story of his father coming from Albania to the US in the early 1990s\n",
      "Dylan: really, I had no idea he is Albanian\n",
      "Abby: he is, he speaks only Albanian with his parents\n",
      "Dylan: fascinating, where does he come from in Albania?\n",
      "Abby: from the seacoast\n",
      "Abby: Duress I believe, he told me they are not from Tirana\n",
      "Dylan: what else did he tell you?\n",
      "Abby: That they left kind of illegally\n",
      "Abby: it was a big mess and extreme poverty everywhere\n",
      "Abby: then suddenly the border was open and they just left \n",
      "Abby: people were boarding available ships, whatever, just to get out of there\n",
      "Abby: he showed me some pictures, like <file_photo>\n",
      "Dylan: insane\n",
      "Abby: yes, and his father was among the people\n",
      "Dylan: scary but interesting\n",
      "Abby: very!\n",
      "---------------\n",
      "flan-t5-base summary:\n",
      "Abby met Miro yesterday at the party. Miro's father came from Albania to the US in the early 1990s. He speaks Albanian with his parents. The border was open and people were boarding ships to get out of there.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from random import randrange        \n",
    "\n",
    "# load model and tokenizer from huggingface hub with pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"philschmid/flan-t5-base-samsum\", device=0)\n",
    "\n",
    "# select a random test sample\n",
    "sample = dataset['test'][randrange(len(dataset[\"test\"]))]\n",
    "print(f\"dialogue: \\n{sample['dialogue']}\\n---------------\")\n",
    "\n",
    "# summarize dialogue\n",
    "res = summarizer(sample[\"dialogue\"])\n",
    "\n",
    "print(f\"flan-t5-base summary:\\n{res[0]['summary_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
