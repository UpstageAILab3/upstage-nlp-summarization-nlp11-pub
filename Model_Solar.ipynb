{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/meta-llama/llama-recipes/blob/v0.0.3/recipes/quickstart/finetuning/quickstart_peft_finetuning.ipynb 를 복사해서 수정함.\n",
    "\n",
    "pip install llama-recipes 실행 시, 0.0.3 버전이 설치 되기 때문에,\n",
    "quickstart_peft_finetuning.ipynb 파일도 0.0.3 버전을 사용해야 문제 없이 실행이 됨!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "This software may be used and distributed according to the terms of the Llama 2 Community License Agreement.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/meta-llama/llama-recipes/blob/main/recipes/finetuning/quickstart_peft_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEFT Finetuning Quick Start Notebook\n",
    "\n",
    "This notebook shows how to train a Meta Llama 3 model on a single GPU (e.g. A10 with 24GB) using int8 quantization and LoRA finetuning.\n",
    "\n",
    "**_Note:_** To run this notebook on a machine with less than 24GB VRAM (e.g. T4 with 16GB) the context length of the training dataset needs to be adapted.\n",
    "We do this based on the available VRAM during execution.\n",
    "If you run into OOM issues try to further lower the value of train_config.context_length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Install pre-requirements and convert checkpoint\n",
    "\n",
    "We need to have llama-recipes and its dependencies installed for this notebook. Additionally, we need to log in with the huggingface_cli and make sure that the account is able to to access the Meta Llama weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if running from Colab T4\n",
    "# ! pip install llama-recipes ipywidgets\n",
    "\n",
    "# import huggingface_hub\n",
    "# huggingface_hub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"model_name\": \"upstage/SOLAR-10.7B-v1.0\", # 불러올 모델의 이름을 사용자 환경에 맞게 지정할 수 있습니다.\n",
    "        \"output_dir\": \"./solar_finetuning\" # 모델의 최종 출력 값을 저장할 경로를 설정합니다.\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"max_new_tokens\": 175,\n",
    "        #\"min_new_tokens\": 30,\n",
    "        # 특정 단어들이 분해되어 tokenization이 수행되지 않도록 special_tokens을 지정해줍니다.\n",
    "        #\"special_tokens\": ['#Person#', '#Person1#', '#Person2#', '#Person3#', '#Person4#', '#Person5#', '#Person6#', '#Person7#', '#Address#', '#SSN#', '#PassportNumber#', '#CardNumber#', '#CarNumber#', '#Email#', '#DateOfBirth#', '#PhoneNumber#']\n",
    "    },\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the model\n",
    "\n",
    "Setup training configuration and load the model and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515578f8c02d40b4a9524b14c4d0d251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from llama_recipes.configs import train_config as TRAIN_CONFIG\n",
    "\n",
    "train_config = TRAIN_CONFIG()\n",
    "train_config.model_name = config_data[\"general\"][\"model_name\"]\n",
    "train_config.num_epochs = 1\n",
    "train_config.run_validation = False\n",
    "train_config.gradient_accumulation_steps = 4\n",
    "train_config.batch_size_training = 1\n",
    "train_config.lr = 3e-4\n",
    "train_config.use_fast_kernels = True\n",
    "train_config.use_fp16 = True\n",
    "train_config.context_length = 1024 if torch.cuda.get_device_properties(0).total_memory < 16e9 else 2048 # T4 16GB or A10 24GB\n",
    "train_config.batching_strategy = \"packing\"\n",
    "train_config.output_dir = config_data[\"general\"][\"output_dir\"]\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,  # Add\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "            train_config.model_name,\n",
    "            device_map=\"auto\",\n",
    "            quantization_config=config,\n",
    "            use_cache=False,\n",
    "            attn_implementation=\"sdpa\" if train_config.use_fast_kernels else None,\n",
    "            torch_dtype=torch.bfloat16,     # float16 ==> bfloat16\n",
    "        )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(train_config.model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Check base model\n",
    "\n",
    "Run the base model on an example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize this dialog:\n",
      "#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
      "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
      "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
      "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
      "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
      "#Person2#: 알겠습니다.\n",
      "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
      "#Person2#: 네.\n",
      "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
      "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
      "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
      "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
      "---\n",
      "Summary:\n",
      "Person1 is a doctor and Person2 is a patient. Person2 is having a health checkup. Person2 smokes and the doctor advises him to quit smoking.\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"\n",
    "Summarize this dialog:\n",
    "#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
    "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
    "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
    "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
    "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
    "#Person2#: 알겠습니다.\n",
    "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
    "#Person2#: 네.\n",
    "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
    "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
    "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
    "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
    "---\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    generated = model.generate(**model_input, \n",
    "                               # min_new_tokens = config_data['tokenizer']['min_new_tokens'], \n",
    "                               max_new_tokens = config_data['tokenizer']['max_new_tokens'])\n",
    "    \n",
    "    print(tokenizer.decode(generated[0], skip_special_tokens=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the base model only repeats the conversation.\n",
    "\n",
    "### Step 3: Load the preprocessed dataset\n",
    "\n",
    "We load and preprocess the samsum dataset which consists of curated pairs of dialogs and their summarization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "class DatasetForLlamaTrain(Dataset):\n",
    "    def __init__(self, train_csv_fullpath):\n",
    "        df = pd.read_csv(train_csv_fullpath)\n",
    "        \n",
    "        prompt = (\n",
    "            f\"Summarize this dialog:\\n{{dialog}}\\n---\\nSummary:\\n\"\n",
    "        )\n",
    "\n",
    "        def apply_prompt_template(s):\n",
    "            return prompt.format(dialog=s)\n",
    "\n",
    "        df['dialogue'] = df['dialogue'].map(apply_prompt_template)\n",
    "\n",
    "        self.preprocessed_list = []\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            processed_row = {}\n",
    "            \n",
    "            prompt = tokenizer.encode(tokenizer.bos_token + df.iloc[i]['dialogue'], add_special_tokens=False)\n",
    "            summary = tokenizer.encode(df.iloc[i]['summary'] +  tokenizer.eos_token, add_special_tokens=False)\n",
    "            \n",
    "            processed_row = {\n",
    "                \"input_ids\": prompt + summary,\n",
    "                \"attention_mask\" : [1] * (len(prompt) + len(summary)),\n",
    "                \"labels\": [-100] * len(prompt) + summary,\n",
    "            }\n",
    "            \n",
    "            self.preprocessed_list.append(processed_row)\n",
    "        \n",
    "        self.len = len(self.preprocessed_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.preprocessed_list[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/llama_recipes/model_checkpointing/checkpoint_handler.py:17: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead\n",
      "  from torch.distributed._shard.checkpoint import (\n",
      "Preprocessing dataset: 100%|██████████| 12956/12956 [00:00<00:00, 31854.99it/s]\n"
     ]
    }
   ],
   "source": [
    "#from llama_recipes.configs.datasets import samsum_dataset\n",
    "from llama_recipes.data.concatenator import ConcatDataset\n",
    "from llama_recipes.utils.config_utils import get_dataloader_kwargs\n",
    "#from llama_recipes.utils.dataset_utils import get_preprocessed_dataset\n",
    "\n",
    "train_dataset = DatasetForLlamaTrain('../../data/train_dev.csv')    # train + dev dataset\n",
    "\n",
    "train_dl_kwargs = get_dataloader_kwargs(train_config, train_dataset, tokenizer, \"train\")\n",
    "\n",
    "if train_config.batching_strategy == \"packing\":\n",
    "        train_dataset = ConcatDataset(train_dataset, chunk_size=train_config.context_length)\n",
    "\n",
    "# Create DataLoaders for the training and validation dataset\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    num_workers=train_config.num_workers_dataloader,\n",
    "    pin_memory=True,\n",
    "    **train_dl_kwargs,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Prepare model for PEFT\n",
    "\n",
    "Let's prepare the model for Parameter Efficient Fine Tuning (PEFT):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, prepare_model_for_kbit_training, LoraConfig\n",
    "from dataclasses import asdict\n",
    "from llama_recipes.configs import lora_config as LORA_CONFIG\n",
    "\n",
    "lora_config = LORA_CONFIG()\n",
    "lora_config.r = 8\n",
    "lora_config.lora_alpha = 32\n",
    "lora_dropout: float=0.01\n",
    "\n",
    "peft_config = LoraConfig(**asdict(lora_config))\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Fine tune the model\n",
    "\n",
    "Here, we fine tune the model for a single epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/llama_recipes/utils/train_utils.py:92: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/memory.py:343: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "Training Epoch: 1:   0%|\u001b[34m          \u001b[0m| 0/842 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/opt/conda/lib/python3.10/site-packages/llama_recipes/utils/train_utils.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "Training Epoch: 1/1, step 3368/3369 completed (loss: 0.13318221271038055): : 843it [2:59:59, 12.81s/it]                       2.81s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max CUDA memory allocated was 9 GB\n",
      "Max CUDA memory reserved was 10 GB\n",
      "Peak active CUDA memory was 9 GB\n",
      "CUDA Malloc retries : 0\n",
      "CPU Total Peak Memory consumed during the train (max): 3 GB\n",
      "Epoch 1: train_perplexity=nan, train_epoch_loss=nan, epoch time 10800.556940671057s\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from llama_recipes.utils.train_utils import train\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=train_config.lr,\n",
    "            weight_decay=train_config.weight_decay,\n",
    "        )\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=train_config.gamma)\n",
    "\n",
    "# Start the training process\n",
    "results = train(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    None,\n",
    "    tokenizer,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    train_config.gradient_accumulation_steps,\n",
    "    train_config,\n",
    "    None,\n",
    "    None,\n",
    "    None,\n",
    "    wandb_run=None,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6:\n",
    "Save model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(train_config.output_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7:\n",
    "Try the fine tuned model on the same example again to see the learning progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize this dialog:\n",
      "#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
      "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
      "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
      "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
      "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
      "#Person2#: 알겠습니다.\n",
      "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
      "#Person2#: 네.\n",
      "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
      "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
      "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
      "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
      "---\n",
      "Summary:\n",
      " 스미스씨는 건강검진을 받기 위해 의사에게 찾아갑니다. 의사는 스미스씨에게 건강검진을 매년 받는 것이 좋다고 말합니다. 의사는 스미스씨에게 담배를 끊으라고 제안하고 그에게 수업과 약물을 제공할 것이라고 말합니다.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, \n",
    "                                          # min_new_tokens = config_data['tokenizer']['min_new_tokens'], \n",
    "                                          max_new_tokens = config_data['tokenizer']['max_new_tokens'])[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 아래를 실행하기 전에 \n",
    "1. 메모리 확보를 위해 커널을 재시작 할 것!\n",
    "2. 제일 위쪽에 config_data 정의하는 코드 블록 실행할것!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    #np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c6a1a89b834231aff095027cb9e8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://huggingface.co/blog/peft 이 글에서 학습한걸 읽는 코드를 참고해서 작성함.\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from llama_recipes.configs import train_config as TRAIN_CONFIG\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "peft_model_id = config_data['general']['output_dir']\n",
    "peftConfig = PeftConfig.from_pretrained(peft_model_id)\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,  # Add\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "            peftConfig.base_model_name_or_path,\n",
    "            device_map=\"auto\",\n",
    "            quantization_config=config,\n",
    "            use_cache=False,\n",
    "            torch_dtype=torch.bfloat16,     # float16 ==> bfloat16\n",
    "        )\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "model = model.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(peftConfig.base_model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize this dialog:\n",
      "#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
      "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
      "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
      "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
      "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
      "#Person2#: 알겠습니다.\n",
      "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
      "#Person2#: 네.\n",
      "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
      "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
      "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
      "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
      "---\n",
      "Summary:\n",
      " 스미스씨는 건강검진을 받기 위해 의사에게 찾아갑니다. 의사는 스미스씨에게 건강검진을 매년 받는 것이 좋다고 말합니다. 의사는 스미스씨에게 담배를 끊으라고 제안하고 그에게 수업과 약물을 제공할 것이라고 말합니다.\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"\n",
    "Summarize this dialog:\n",
    "#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
    "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
    "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
    "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
    "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
    "#Person2#: 알겠습니다.\n",
    "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
    "#Person2#: 네.\n",
    "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
    "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
    "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
    "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
    "---\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    max_new_tokens = int(len(model_input['input_ids'][0]) * 0.3)\n",
    "    generated = model.generate(**model_input, \n",
    "                               # min_new_tokens=config_data['tokenizer']['min_new_tokens'], \n",
    "                               max_new_tokens = max_new_tokens)\n",
    "    \n",
    "    print(tokenizer.decode(generated[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "class DatasetForLlamaTest(Dataset):\n",
    "    def __init__(self, train_csv_fullpath):\n",
    "        df = pd.read_csv(train_csv_fullpath)\n",
    "        \n",
    "        prompt = (\n",
    "            f\"Summarize this dialog:\\n{{dialog}}\\n---\\nSummary:\\n\"\n",
    "        )\n",
    "\n",
    "        def apply_prompt_template(s):\n",
    "            return prompt.format(dialog=s)\n",
    "\n",
    "        df['dialogue'] = df['dialogue'].map(apply_prompt_template)\n",
    "\n",
    "        self.fname_list = []\n",
    "        self.preprocessed_list = []\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            #\n",
    "            self.fname_list.append(df.iloc[i]['fname'])\n",
    "            \n",
    "            # tokenizer() 와 tokenizer.encode() 는 다르다!\n",
    "            # tokenizer() 를 사용해야 딕셔너리(input_ids, attention_mask) 형태로 리턴됨.\n",
    "            prompt = tokenizer(df.iloc[i]['dialogue'], return_tensors=\"pt\").to(\"cuda\")\n",
    "            self.preprocessed_list.append(prompt)\n",
    "        \n",
    "        self.len = len(self.preprocessed_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.fname_list[idx], self.preprocessed_list[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetForLlamaTest('../../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/499 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  0%|          | 1/499 [00:50<6:58:39, 50.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  0%|          | 2/499 [01:26<5:47:47, 41.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 3/499 [01:57<5:04:15, 36.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 4/499 [02:09<3:42:28, 26.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 5/499 [02:34<3:38:18, 26.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 6/499 [03:52<6:02:18, 44.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|▏         | 7/499 [04:14<5:01:25, 36.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 8/499 [04:37<4:24:32, 32.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 9/499 [04:57<3:52:31, 28.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 10/499 [05:05<3:00:19, 22.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 11/499 [05:22<2:48:15, 20.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 12/499 [05:38<2:35:32, 19.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 13/499 [06:11<3:08:04, 23.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 14/499 [06:18<2:29:36, 18.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 15/499 [06:39<2:35:49, 19.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 16/499 [06:59<2:37:06, 19.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 17/499 [07:09<2:13:12, 16.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▎         | 18/499 [07:17<1:51:38, 13.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 19/499 [07:23<1:33:50, 11.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 20/499 [07:27<1:13:15,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 21/499 [07:52<1:51:39, 14.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 22/499 [08:19<2:21:38, 17.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▍         | 23/499 [08:31<2:08:02, 16.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▍         | 24/499 [08:37<1:44:57, 13.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 25/499 [08:47<1:36:55, 12.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 26/499 [09:48<3:30:14, 26.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 27/499 [10:08<3:13:56, 24.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 28/499 [10:42<3:35:25, 27.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 29/499 [11:19<3:58:11, 30.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 30/499 [11:25<2:59:48, 23.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 31/499 [11:45<2:53:26, 22.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▋         | 32/499 [11:54<2:23:06, 18.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 33/499 [12:14<2:26:01, 18.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 34/499 [12:31<2:21:25, 18.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 35/499 [12:54<2:30:56, 19.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 36/499 [13:14<2:33:05, 19.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 37/499 [14:29<4:39:25, 36.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 38/499 [14:34<3:27:38, 27.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 39/499 [15:02<3:28:54, 27.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 40/499 [15:29<3:27:00, 27.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 41/499 [15:41<2:53:13, 22.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 42/499 [16:21<3:32:04, 27.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  9%|▊         | 43/499 [16:36<3:02:45, 24.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  9%|▉         | 44/499 [16:57<2:55:35, 23.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  9%|▉         | 45/499 [17:20<2:54:45, 23.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  9%|▉         | 46/499 [17:47<3:03:16, 24.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  9%|▉         | 47/499 [18:03<2:43:09, 21.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 10%|▉         | 48/499 [18:40<3:16:53, 26.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 10%|▉         | 49/499 [18:50<2:41:49, 21.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 10%|█         | 50/499 [19:05<2:25:05, 19.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 10%|█         | 51/499 [19:17<2:08:09, 17.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 10%|█         | 52/499 [19:30<1:59:39, 16.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 11%|█         | 53/499 [19:42<1:50:20, 14.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 11%|█         | 54/499 [19:47<1:28:40, 11.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 11%|█         | 55/499 [20:00<1:29:49, 12.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 11%|█         | 56/499 [20:08<1:20:06, 10.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 11%|█▏        | 57/499 [20:27<1:38:43, 13.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 12%|█▏        | 58/499 [20:59<2:19:47, 19.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 12%|█▏        | 59/499 [21:12<2:05:30, 17.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 12%|█▏        | 60/499 [21:56<3:04:04, 25.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 12%|█▏        | 61/499 [22:10<2:39:02, 21.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 12%|█▏        | 62/499 [22:41<2:59:01, 24.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 13%|█▎        | 63/499 [23:00<2:47:31, 23.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 13%|█▎        | 64/499 [23:13<2:24:51, 19.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 13%|█▎        | 65/499 [23:17<1:48:46, 15.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 13%|█▎        | 66/499 [23:22<1:26:50, 12.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 13%|█▎        | 67/499 [23:33<1:25:46, 11.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 14%|█▎        | 68/499 [24:07<2:12:33, 18.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 14%|█▍        | 69/499 [24:17<1:53:18, 15.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 14%|█▍        | 70/499 [24:29<1:44:33, 14.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 14%|█▍        | 71/499 [24:42<1:41:20, 14.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 14%|█▍        | 72/499 [25:32<2:57:03, 24.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 15%|█▍        | 73/499 [26:08<3:20:21, 28.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 15%|█▍        | 74/499 [26:34<3:16:54, 27.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 15%|█▌        | 75/499 [26:47<2:43:30, 23.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 15%|█▌        | 76/499 [27:02<2:25:53, 20.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 15%|█▌        | 77/499 [27:21<2:21:49, 20.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 16%|█▌        | 78/499 [27:31<1:59:50, 17.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 16%|█▌        | 79/499 [28:02<2:29:35, 21.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 16%|█▌        | 80/499 [28:27<2:36:27, 22.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 16%|█▌        | 81/499 [28:39<2:14:11, 19.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 16%|█▋        | 82/499 [28:47<1:50:34, 15.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 17%|█▋        | 83/499 [29:15<2:15:35, 19.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 17%|█▋        | 84/499 [29:40<2:26:18, 21.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 17%|█▋        | 85/499 [29:55<2:14:28, 19.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 17%|█▋        | 86/499 [30:07<1:57:22, 17.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 17%|█▋        | 87/499 [30:23<1:55:27, 16.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 18%|█▊        | 88/499 [31:51<4:21:09, 38.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 18%|█▊        | 89/499 [32:31<4:25:31, 38.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 18%|█▊        | 90/499 [32:48<3:38:50, 32.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 18%|█▊        | 91/499 [32:55<2:48:20, 24.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 18%|█▊        | 92/499 [33:02<2:12:01, 19.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 19%|█▊        | 93/499 [33:14<1:56:40, 17.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 19%|█▉        | 94/499 [33:42<2:16:59, 20.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 19%|█▉        | 95/499 [34:00<2:11:23, 19.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 19%|█▉        | 96/499 [34:54<3:22:13, 30.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 19%|█▉        | 97/499 [35:06<2:44:40, 24.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|█▉        | 98/499 [35:15<2:12:14, 19.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|█▉        | 99/499 [35:24<1:51:43, 16.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|██        | 100/499 [35:49<2:07:20, 19.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|██        | 101/499 [36:25<2:40:53, 24.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|██        | 102/499 [36:31<2:04:10, 18.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 21%|██        | 103/499 [36:39<1:43:04, 15.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 21%|██        | 104/499 [36:48<1:28:17, 13.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 21%|██        | 105/499 [37:24<2:13:45, 20.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 21%|██        | 106/499 [37:46<2:16:49, 20.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 21%|██▏       | 107/499 [38:09<2:19:18, 21.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 22%|██▏       | 108/499 [38:36<2:30:56, 23.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 22%|██▏       | 109/499 [38:47<2:06:44, 19.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 22%|██▏       | 110/499 [38:57<1:48:20, 16.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 22%|██▏       | 111/499 [39:16<1:51:09, 17.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 22%|██▏       | 112/499 [40:09<3:00:36, 28.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 23%|██▎       | 113/499 [40:19<2:26:05, 22.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 23%|██▎       | 114/499 [40:35<2:12:15, 20.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 23%|██▎       | 115/499 [40:42<1:45:00, 16.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 23%|██▎       | 116/499 [41:04<1:56:07, 18.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 23%|██▎       | 117/499 [41:20<1:51:08, 17.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 24%|██▎       | 118/499 [41:41<1:59:04, 18.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 24%|██▍       | 119/499 [43:38<5:05:13, 48.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 24%|██▍       | 120/499 [43:49<3:54:00, 37.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 24%|██▍       | 121/499 [44:03<3:09:17, 30.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 24%|██▍       | 122/499 [44:42<3:26:03, 32.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 25%|██▍       | 123/499 [44:54<2:45:57, 26.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 25%|██▍       | 124/499 [45:00<2:06:47, 20.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 25%|██▌       | 125/499 [45:09<1:45:02, 16.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 25%|██▌       | 126/499 [45:30<1:52:36, 18.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 25%|██▌       | 127/499 [46:12<2:37:50, 25.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 26%|██▌       | 128/499 [46:24<2:11:12, 21.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 26%|██▌       | 129/499 [46:34<1:50:07, 17.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 26%|██▌       | 130/499 [46:41<1:30:18, 14.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 26%|██▋       | 131/499 [47:04<1:46:07, 17.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 26%|██▋       | 132/499 [48:21<3:34:38, 35.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 27%|██▋       | 133/499 [49:24<4:25:30, 43.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 27%|██▋       | 134/499 [49:34<3:23:28, 33.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 27%|██▋       | 135/499 [50:06<3:19:05, 32.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 27%|██▋       | 136/499 [50:29<3:02:28, 30.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 27%|██▋       | 137/499 [51:12<3:23:32, 33.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 28%|██▊       | 138/499 [51:19<2:34:56, 25.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 28%|██▊       | 139/499 [51:24<1:57:15, 19.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 28%|██▊       | 140/499 [51:29<1:30:43, 15.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 28%|██▊       | 141/499 [52:11<2:18:53, 23.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 28%|██▊       | 142/499 [52:30<2:11:47, 22.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 29%|██▊       | 143/499 [53:25<3:09:59, 32.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 29%|██▉       | 144/499 [53:41<2:40:37, 27.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 29%|██▉       | 145/499 [53:54<2:15:30, 22.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 29%|██▉       | 146/499 [54:15<2:10:54, 22.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 29%|██▉       | 147/499 [54:43<2:20:49, 24.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 30%|██▉       | 148/499 [54:53<1:54:48, 19.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 30%|██▉       | 149/499 [55:09<1:49:24, 18.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 30%|███       | 150/499 [55:28<1:48:11, 18.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 30%|███       | 151/499 [55:42<1:40:31, 17.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 30%|███       | 152/499 [55:46<1:17:53, 13.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 31%|███       | 153/499 [56:05<1:27:05, 15.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 31%|███       | 154/499 [56:21<1:27:46, 15.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 31%|███       | 155/499 [56:27<1:11:28, 12.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 31%|███▏      | 156/499 [57:18<2:18:15, 24.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 31%|███▏      | 157/499 [57:45<2:21:47, 24.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 32%|███▏      | 158/499 [58:49<3:27:47, 36.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 32%|███▏      | 159/499 [59:00<2:44:26, 29.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 32%|███▏      | 160/499 [59:07<2:07:05, 22.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 32%|███▏      | 161/499 [59:34<2:13:06, 23.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 32%|███▏      | 162/499 [1:00:11<2:35:22, 27.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 33%|███▎      | 163/499 [1:00:21<2:05:30, 22.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 33%|███▎      | 164/499 [1:00:43<2:03:59, 22.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 33%|███▎      | 165/499 [1:00:48<1:35:34, 17.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 33%|███▎      | 166/499 [1:01:03<1:31:04, 16.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 33%|███▎      | 167/499 [1:01:22<1:35:44, 17.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 34%|███▎      | 168/499 [1:01:55<2:01:21, 22.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 34%|███▍      | 169/499 [1:02:04<1:38:50, 17.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 34%|███▍      | 170/499 [1:02:57<2:37:04, 28.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 34%|███▍      | 171/499 [1:03:12<2:13:18, 24.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 34%|███▍      | 172/499 [1:03:23<1:51:51, 20.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 35%|███▍      | 173/499 [1:04:10<2:34:32, 28.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 35%|███▍      | 174/499 [1:04:22<2:07:11, 23.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 35%|███▌      | 175/499 [1:04:33<1:47:30, 19.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 35%|███▌      | 176/499 [1:05:16<2:24:17, 26.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 35%|███▌      | 177/499 [1:05:20<1:46:59, 19.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 36%|███▌      | 178/499 [1:05:29<1:27:54, 16.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 36%|███▌      | 179/499 [1:05:37<1:15:05, 14.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 36%|███▌      | 180/499 [1:06:12<1:48:28, 20.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 36%|███▋      | 181/499 [1:06:30<1:44:18, 19.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 36%|███▋      | 182/499 [1:06:52<1:46:29, 20.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 37%|███▋      | 183/499 [1:07:00<1:27:53, 16.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 37%|███▋      | 184/499 [1:07:54<2:26:55, 27.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 37%|███▋      | 185/499 [1:08:41<2:55:08, 33.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 37%|███▋      | 186/499 [1:08:44<2:06:51, 24.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 37%|███▋      | 187/499 [1:09:06<2:03:05, 23.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 38%|███▊      | 188/499 [1:09:24<1:53:46, 21.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 38%|███▊      | 189/499 [1:10:28<2:58:12, 34.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 38%|███▊      | 190/499 [1:10:37<2:18:49, 26.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 38%|███▊      | 191/499 [1:10:42<1:44:39, 20.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 38%|███▊      | 192/499 [1:10:55<1:33:36, 18.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 39%|███▊      | 193/499 [1:11:27<1:54:18, 22.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 39%|███▉      | 194/499 [1:11:35<1:31:52, 18.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 39%|███▉      | 195/499 [1:11:53<1:30:46, 17.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 39%|███▉      | 196/499 [1:12:07<1:24:17, 16.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 39%|███▉      | 197/499 [1:12:24<1:24:34, 16.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|███▉      | 198/499 [1:12:46<1:32:55, 18.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|███▉      | 199/499 [1:13:17<1:50:04, 22.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|████      | 200/499 [1:13:40<1:51:31, 22.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|████      | 201/499 [1:14:50<3:02:56, 36.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|████      | 202/499 [1:15:14<2:42:46, 32.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 41%|████      | 203/499 [1:15:21<2:03:50, 25.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 41%|████      | 204/499 [1:16:22<2:57:10, 36.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 41%|████      | 205/499 [1:16:31<2:15:54, 27.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 41%|████▏     | 206/499 [1:17:03<2:22:21, 29.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 41%|████▏     | 207/499 [1:17:19<2:02:04, 25.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 42%|████▏     | 208/499 [1:17:26<1:36:09, 19.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 42%|████▏     | 209/499 [1:17:50<1:40:45, 20.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 42%|████▏     | 210/499 [1:18:04<1:30:58, 18.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 42%|████▏     | 211/499 [1:18:20<1:26:58, 18.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 42%|████▏     | 212/499 [1:18:30<1:14:33, 15.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 43%|████▎     | 213/499 [1:18:36<59:58, 12.58s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 43%|████▎     | 214/499 [1:19:10<1:30:47, 19.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 43%|████▎     | 215/499 [1:19:46<1:55:10, 24.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 43%|████▎     | 216/499 [1:19:55<1:32:02, 19.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 43%|████▎     | 217/499 [1:20:05<1:18:06, 16.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 44%|████▎     | 218/499 [1:20:21<1:17:33, 16.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 44%|████▍     | 219/499 [1:20:43<1:24:43, 18.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 44%|████▍     | 220/499 [1:21:01<1:24:38, 18.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 44%|████▍     | 221/499 [1:21:28<1:36:43, 20.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 44%|████▍     | 222/499 [1:21:56<1:45:23, 22.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 45%|████▍     | 223/499 [1:22:14<1:38:41, 21.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 45%|████▍     | 224/499 [1:22:24<1:22:34, 18.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 45%|████▌     | 225/499 [1:22:35<1:12:25, 15.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 45%|████▌     | 226/499 [1:22:49<1:10:14, 15.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 45%|████▌     | 227/499 [1:22:59<1:02:19, 13.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 46%|████▌     | 228/499 [1:23:14<1:03:41, 14.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 46%|████▌     | 229/499 [1:23:54<1:38:59, 22.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 46%|████▌     | 230/499 [1:24:02<1:19:19, 17.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 46%|████▋     | 231/499 [1:24:08<1:03:43, 14.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 46%|████▋     | 232/499 [1:24:56<1:47:33, 24.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 47%|████▋     | 233/499 [1:25:14<1:39:41, 22.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 47%|████▋     | 234/499 [1:25:21<1:18:14, 17.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 47%|████▋     | 235/499 [1:25:50<1:33:45, 21.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 47%|████▋     | 236/499 [1:26:15<1:37:58, 22.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 47%|████▋     | 237/499 [1:27:11<2:21:09, 32.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 48%|████▊     | 238/499 [1:27:23<1:54:22, 26.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 48%|████▊     | 239/499 [1:27:54<1:59:25, 27.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 48%|████▊     | 240/499 [1:28:09<1:43:25, 23.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 48%|████▊     | 241/499 [1:29:25<2:49:42, 39.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 48%|████▊     | 242/499 [1:29:34<2:10:42, 30.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 49%|████▊     | 243/499 [1:29:59<2:02:21, 28.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 49%|████▉     | 244/499 [1:30:25<1:59:08, 28.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 49%|████▉     | 245/499 [1:30:39<1:40:23, 23.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 49%|████▉     | 246/499 [1:30:55<1:30:05, 21.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 49%|████▉     | 247/499 [1:31:57<2:20:37, 33.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 50%|████▉     | 248/499 [1:32:12<1:57:44, 28.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 50%|████▉     | 249/499 [1:33:17<2:42:25, 38.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 50%|█████     | 250/499 [1:33:35<2:16:27, 32.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 50%|█████     | 251/499 [1:33:47<1:49:24, 26.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 51%|█████     | 252/499 [1:33:54<1:24:57, 20.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 51%|█████     | 253/499 [1:34:40<1:56:02, 28.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 51%|█████     | 254/499 [1:35:38<2:31:45, 37.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 51%|█████     | 255/499 [1:35:47<1:56:49, 28.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 51%|█████▏    | 256/499 [1:36:15<1:55:09, 28.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 52%|█████▏    | 257/499 [1:36:51<2:04:08, 30.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 52%|█████▏    | 258/499 [1:37:02<1:40:08, 24.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 52%|█████▏    | 259/499 [1:37:07<1:15:36, 18.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 52%|█████▏    | 260/499 [1:37:28<1:17:29, 19.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 52%|█████▏    | 261/499 [1:37:54<1:24:51, 21.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 53%|█████▎    | 262/499 [1:38:05<1:12:24, 18.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 53%|█████▎    | 263/499 [1:38:53<1:47:45, 27.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 53%|█████▎    | 264/499 [1:39:25<1:52:02, 28.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 53%|█████▎    | 265/499 [1:39:47<1:43:36, 26.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 53%|█████▎    | 266/499 [1:39:56<1:22:56, 21.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 54%|█████▎    | 267/499 [1:40:26<1:33:28, 24.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 54%|█████▎    | 268/499 [1:40:37<1:17:29, 20.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 54%|█████▍    | 269/499 [1:41:08<1:29:53, 23.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 54%|█████▍    | 270/499 [1:41:18<1:14:07, 19.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 54%|█████▍    | 271/499 [1:41:44<1:21:22, 21.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 55%|█████▍    | 272/499 [1:42:04<1:19:22, 20.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 55%|█████▍    | 273/499 [1:42:22<1:15:10, 19.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 55%|█████▍    | 274/499 [1:42:31<1:02:07, 16.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 55%|█████▌    | 275/499 [1:42:39<52:24, 14.04s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 55%|█████▌    | 276/499 [1:42:45<43:03, 11.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 56%|█████▌    | 277/499 [1:43:10<57:37, 15.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 56%|█████▌    | 278/499 [1:43:49<1:23:30, 22.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 56%|█████▌    | 279/499 [1:43:56<1:06:07, 18.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 56%|█████▌    | 280/499 [1:44:38<1:31:40, 25.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 56%|█████▋    | 281/499 [1:44:45<1:11:27, 19.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 57%|█████▋    | 282/499 [1:44:56<1:01:49, 17.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 57%|█████▋    | 283/499 [1:45:02<50:12, 13.95s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 57%|█████▋    | 284/499 [1:45:18<51:53, 14.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 57%|█████▋    | 285/499 [1:45:38<57:09, 16.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 57%|█████▋    | 286/499 [1:45:47<50:05, 14.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 58%|█████▊    | 287/499 [1:46:00<48:05, 13.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 58%|█████▊    | 288/499 [1:46:23<58:01, 16.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 58%|█████▊    | 289/499 [1:46:36<53:44, 15.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 58%|█████▊    | 290/499 [1:47:09<1:12:45, 20.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 58%|█████▊    | 291/499 [1:47:29<1:10:35, 20.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 59%|█████▊    | 292/499 [1:47:32<52:41, 15.27s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 59%|█████▊    | 293/499 [1:48:06<1:11:17, 20.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 59%|█████▉    | 294/499 [1:49:18<2:03:33, 36.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 59%|█████▉    | 295/499 [1:50:25<2:35:03, 45.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 59%|█████▉    | 296/499 [1:50:54<2:17:21, 40.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 60%|█████▉    | 297/499 [1:51:27<2:09:08, 38.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 60%|█████▉    | 298/499 [1:51:56<1:58:23, 35.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 60%|█████▉    | 299/499 [1:52:22<1:48:29, 32.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 60%|██████    | 300/499 [1:52:43<1:36:52, 29.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 60%|██████    | 301/499 [1:52:52<1:16:17, 23.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 61%|██████    | 302/499 [1:53:00<1:00:57, 18.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 61%|██████    | 303/499 [1:53:19<1:01:01, 18.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 61%|██████    | 304/499 [1:53:41<1:03:48, 19.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 61%|██████    | 305/499 [1:53:47<50:57, 15.76s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 61%|██████▏   | 306/499 [1:54:02<49:38, 15.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 62%|██████▏   | 307/499 [1:54:17<48:52, 15.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 62%|██████▏   | 308/499 [1:54:29<45:17, 14.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 62%|██████▏   | 309/499 [1:54:34<36:02, 11.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 62%|██████▏   | 310/499 [1:55:42<1:29:21, 28.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 62%|██████▏   | 311/499 [1:56:16<1:34:14, 30.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 63%|██████▎   | 312/499 [1:56:42<1:29:55, 28.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 63%|██████▎   | 313/499 [1:56:47<1:07:25, 21.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 63%|██████▎   | 314/499 [1:56:50<50:11, 16.28s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 63%|██████▎   | 315/499 [1:57:01<44:37, 14.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 63%|██████▎   | 316/499 [1:57:20<48:47, 16.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 64%|██████▎   | 317/499 [1:57:26<38:49, 12.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 64%|██████▎   | 318/499 [1:57:50<48:45, 16.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 64%|██████▍   | 319/499 [1:58:26<1:06:39, 22.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 64%|██████▍   | 320/499 [1:58:34<53:46, 18.02s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 64%|██████▍   | 321/499 [1:58:52<53:39, 18.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 65%|██████▍   | 322/499 [1:59:11<53:53, 18.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 65%|██████▍   | 323/499 [1:59:18<43:44, 14.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 65%|██████▍   | 324/499 [1:59:51<59:12, 20.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 65%|██████▌   | 325/499 [2:00:08<56:00, 19.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 65%|██████▌   | 326/499 [2:00:24<52:23, 18.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 66%|██████▌   | 327/499 [2:00:30<42:18, 14.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 66%|██████▌   | 328/499 [2:01:15<1:08:02, 23.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 66%|██████▌   | 329/499 [2:01:58<1:23:53, 29.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 66%|██████▌   | 330/499 [2:02:38<1:31:57, 32.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 66%|██████▋   | 331/499 [2:03:07<1:27:59, 31.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 67%|██████▋   | 332/499 [2:03:23<1:14:57, 26.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 67%|██████▋   | 333/499 [2:03:40<1:05:59, 23.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 67%|██████▋   | 334/499 [2:03:47<51:44, 18.82s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 67%|██████▋   | 335/499 [2:04:05<50:28, 18.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 67%|██████▋   | 336/499 [2:04:19<47:08, 17.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 68%|██████▊   | 337/499 [2:04:38<48:16, 17.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 68%|██████▊   | 338/499 [2:04:51<43:37, 16.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 68%|██████▊   | 339/499 [2:04:58<35:56, 13.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 68%|██████▊   | 340/499 [2:05:21<43:17, 16.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 68%|██████▊   | 341/499 [2:05:26<34:06, 12.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 69%|██████▊   | 342/499 [2:06:00<50:16, 19.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 69%|██████▊   | 343/499 [2:06:08<41:31, 15.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 69%|██████▉   | 344/499 [2:06:45<57:00, 22.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 69%|██████▉   | 345/499 [2:08:06<1:42:13, 39.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 69%|██████▉   | 346/499 [2:09:02<1:53:57, 44.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 70%|██████▉   | 347/499 [2:10:12<2:12:16, 52.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 70%|██████▉   | 348/499 [2:10:46<1:57:54, 46.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 70%|██████▉   | 349/499 [2:11:06<1:37:18, 38.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 70%|███████   | 350/499 [2:11:10<1:10:39, 28.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 70%|███████   | 351/499 [2:11:33<1:06:12, 26.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 71%|███████   | 352/499 [2:11:41<51:28, 21.01s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 71%|███████   | 353/499 [2:12:04<52:48, 21.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 71%|███████   | 354/499 [2:12:18<46:29, 19.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 71%|███████   | 355/499 [2:12:50<55:19, 23.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 71%|███████▏  | 356/499 [2:12:58<44:16, 18.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 72%|███████▏  | 357/499 [2:13:03<34:37, 14.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 72%|███████▏  | 358/499 [2:13:08<27:08, 11.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 72%|███████▏  | 359/499 [2:13:35<38:06, 16.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 72%|███████▏  | 360/499 [2:13:47<35:07, 15.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 72%|███████▏  | 361/499 [2:14:04<35:34, 15.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 73%|███████▎  | 362/499 [2:14:08<27:33, 12.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 73%|███████▎  | 363/499 [2:14:42<42:06, 18.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 73%|███████▎  | 364/499 [2:15:05<45:00, 20.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 73%|███████▎  | 365/499 [2:15:13<36:40, 16.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 73%|███████▎  | 366/499 [2:15:20<30:26, 13.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 74%|███████▎  | 367/499 [2:15:43<36:11, 16.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 74%|███████▎  | 368/499 [2:16:10<42:30, 19.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 74%|███████▍  | 369/499 [2:16:26<40:17, 18.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 74%|███████▍  | 370/499 [2:16:53<44:57, 20.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 74%|███████▍  | 371/499 [2:17:00<35:59, 16.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 75%|███████▍  | 372/499 [2:17:12<32:50, 15.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 75%|███████▍  | 373/499 [2:17:38<38:40, 18.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 75%|███████▍  | 374/499 [2:17:49<33:44, 16.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 75%|███████▌  | 375/499 [2:18:16<40:12, 19.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 75%|███████▌  | 376/499 [2:19:00<55:29, 27.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 76%|███████▌  | 377/499 [2:19:18<49:27, 24.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 76%|███████▌  | 378/499 [2:19:35<44:25, 22.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 76%|███████▌  | 379/499 [2:19:56<43:20, 21.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 76%|███████▌  | 380/499 [2:22:20<1:56:06, 58.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 76%|███████▋  | 381/499 [2:22:44<1:34:11, 47.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 77%|███████▋  | 382/499 [2:23:50<1:43:58, 53.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 77%|███████▋  | 383/499 [2:25:36<2:13:48, 69.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 77%|███████▋  | 384/499 [2:26:30<2:03:49, 64.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 77%|███████▋  | 385/499 [2:27:03<1:44:41, 55.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 77%|███████▋  | 386/499 [2:27:07<1:15:20, 40.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 78%|███████▊  | 387/499 [2:27:25<1:02:18, 33.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 78%|███████▊  | 388/499 [2:27:44<53:39, 29.00s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 78%|███████▊  | 389/499 [2:28:00<45:55, 25.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 78%|███████▊  | 390/499 [2:28:11<38:03, 20.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 78%|███████▊  | 391/499 [2:28:32<37:41, 20.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 79%|███████▊  | 392/499 [2:29:03<42:48, 24.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 79%|███████▉  | 393/499 [2:29:25<41:13, 23.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 79%|███████▉  | 394/499 [2:29:56<44:35, 25.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 79%|███████▉  | 395/499 [2:30:14<40:14, 23.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 79%|███████▉  | 396/499 [2:30:36<39:37, 23.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 80%|███████▉  | 397/499 [2:31:07<43:15, 25.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 80%|███████▉  | 398/499 [2:31:39<45:51, 27.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 80%|███████▉  | 399/499 [2:31:57<41:05, 24.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 80%|████████  | 400/499 [2:32:11<35:08, 21.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 80%|████████  | 401/499 [2:32:40<38:35, 23.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 81%|████████  | 402/499 [2:32:56<34:21, 21.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 81%|████████  | 403/499 [2:33:10<30:31, 19.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 81%|████████  | 404/499 [2:33:16<23:59, 15.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 81%|████████  | 405/499 [2:33:33<24:35, 15.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 81%|████████▏ | 406/499 [2:33:38<19:46, 12.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 82%|████████▏ | 407/499 [2:33:58<22:32, 14.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 82%|████████▏ | 408/499 [2:34:34<32:18, 21.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 82%|████████▏ | 409/499 [2:34:54<31:14, 20.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 82%|████████▏ | 410/499 [2:35:06<26:58, 18.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 82%|████████▏ | 411/499 [2:35:55<40:21, 27.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 83%|████████▎ | 412/499 [2:36:04<31:32, 21.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 83%|████████▎ | 413/499 [2:37:13<51:28, 35.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 83%|████████▎ | 414/499 [2:37:35<45:12, 31.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 83%|████████▎ | 415/499 [2:38:29<53:40, 38.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 83%|████████▎ | 416/499 [2:38:48<45:12, 32.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 84%|████████▎ | 417/499 [2:39:01<36:24, 26.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 84%|████████▍ | 418/499 [2:39:12<29:41, 22.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 84%|████████▍ | 419/499 [2:39:17<22:34, 16.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 84%|████████▍ | 420/499 [2:39:59<32:20, 24.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 84%|████████▍ | 421/499 [2:40:29<33:58, 26.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 85%|████████▍ | 422/499 [2:41:00<35:25, 27.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 85%|████████▍ | 423/499 [2:41:15<30:06, 23.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 85%|████████▍ | 424/499 [2:41:25<24:45, 19.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 85%|████████▌ | 425/499 [2:41:35<20:34, 16.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 85%|████████▌ | 426/499 [2:41:58<22:37, 18.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 86%|████████▌ | 427/499 [2:42:24<25:03, 20.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 86%|████████▌ | 428/499 [2:42:45<24:32, 20.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 86%|████████▌ | 429/499 [2:42:57<21:12, 18.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 86%|████████▌ | 430/499 [2:43:06<17:44, 15.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 86%|████████▋ | 431/499 [2:43:12<14:18, 12.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 87%|████████▋ | 432/499 [2:43:33<16:57, 15.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 87%|████████▋ | 433/499 [2:43:46<16:04, 14.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 87%|████████▋ | 434/499 [2:44:11<19:11, 17.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 87%|████████▋ | 435/499 [2:47:08<1:09:44, 65.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 87%|████████▋ | 436/499 [2:47:36<56:51, 54.15s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 88%|████████▊ | 437/499 [2:47:50<43:29, 42.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 88%|████████▊ | 438/499 [2:48:04<34:24, 33.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 88%|████████▊ | 439/499 [2:48:33<32:25, 32.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 88%|████████▊ | 440/499 [2:49:16<34:53, 35.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 88%|████████▊ | 441/499 [2:49:55<35:15, 36.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 89%|████████▊ | 442/499 [2:50:15<30:05, 31.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 89%|████████▉ | 443/499 [2:50:27<23:57, 25.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 89%|████████▉ | 444/499 [2:51:08<27:45, 30.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 89%|████████▉ | 445/499 [2:51:47<29:33, 32.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 89%|████████▉ | 446/499 [2:52:14<27:23, 31.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 90%|████████▉ | 447/499 [2:52:33<23:55, 27.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 90%|████████▉ | 448/499 [2:53:01<23:24, 27.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 90%|████████▉ | 449/499 [2:53:06<17:30, 21.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 90%|█████████ | 450/499 [2:53:55<23:52, 29.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 90%|█████████ | 451/499 [2:54:10<19:59, 24.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 91%|█████████ | 452/499 [2:54:23<16:48, 21.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 91%|█████████ | 453/499 [2:54:30<13:04, 17.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 91%|█████████ | 454/499 [2:54:45<12:25, 16.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 91%|█████████ | 455/499 [2:54:51<09:47, 13.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 91%|█████████▏| 456/499 [2:55:04<09:29, 13.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 92%|█████████▏| 457/499 [2:55:34<12:40, 18.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 92%|█████████▏| 458/499 [2:55:51<12:11, 17.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 92%|█████████▏| 459/499 [2:55:54<08:57, 13.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 92%|█████████▏| 460/499 [2:56:32<13:30, 20.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 92%|█████████▏| 461/499 [2:56:41<10:56, 17.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 93%|█████████▎| 462/499 [2:56:55<10:01, 16.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 93%|█████████▎| 463/499 [2:57:08<09:13, 15.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 93%|█████████▎| 464/499 [2:57:15<07:29, 12.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 93%|█████████▎| 465/499 [2:57:53<11:27, 20.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 93%|█████████▎| 466/499 [2:58:03<09:27, 17.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 94%|█████████▎| 467/499 [2:58:14<08:14, 15.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 94%|█████████▍| 468/499 [2:59:14<14:54, 28.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 94%|█████████▍| 469/499 [3:00:12<18:46, 37.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 94%|█████████▍| 470/499 [3:00:20<13:54, 28.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 94%|█████████▍| 471/499 [3:01:31<19:13, 41.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 95%|█████████▍| 472/499 [3:01:55<16:17, 36.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 95%|█████████▍| 473/499 [3:02:04<12:09, 28.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 95%|█████████▍| 474/499 [3:02:52<14:05, 33.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 95%|█████████▌| 475/499 [3:03:28<13:50, 34.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 95%|█████████▌| 476/499 [3:03:53<12:11, 31.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 96%|█████████▌| 477/499 [3:04:14<10:29, 28.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 96%|█████████▌| 478/499 [3:05:05<12:20, 35.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 96%|█████████▌| 479/499 [3:05:17<09:26, 28.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 96%|█████████▌| 480/499 [3:05:46<08:58, 28.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 96%|█████████▋| 481/499 [3:06:45<11:16, 37.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 97%|█████████▋| 482/499 [3:07:07<09:21, 33.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 97%|█████████▋| 483/499 [3:07:25<07:36, 28.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 97%|█████████▋| 484/499 [3:08:15<08:44, 34.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 97%|█████████▋| 485/499 [3:08:20<06:01, 25.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 97%|█████████▋| 486/499 [3:08:35<04:55, 22.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 98%|█████████▊| 487/499 [3:09:03<04:51, 24.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 98%|█████████▊| 488/499 [3:09:21<04:06, 22.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 98%|█████████▊| 489/499 [3:09:57<04:25, 26.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 98%|█████████▊| 490/499 [3:10:16<03:36, 24.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 98%|█████████▊| 491/499 [3:11:12<04:28, 33.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 99%|█████████▊| 492/499 [3:11:21<03:03, 26.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 99%|█████████▉| 493/499 [3:11:36<02:17, 22.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 99%|█████████▉| 494/499 [3:11:44<01:31, 18.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 99%|█████████▉| 495/499 [3:11:58<01:08, 17.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 99%|█████████▉| 496/499 [3:12:29<01:03, 21.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "100%|█████████▉| 497/499 [3:13:19<00:59, 29.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "100%|█████████▉| 498/499 [3:13:48<00:29, 29.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "100%|██████████| 499/499 [3:14:11<00:00, 23.35s/it]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "fname_list = []\n",
    "summary_list = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for fname, model_input in tqdm(train_dataset):\n",
    "        max_new_tokens = int(len(model_input['input_ids'][0]) * 0.3)\n",
    "        \n",
    "        generated = model.generate(**model_input, \n",
    "                                   # min_new_tokens=config_data['tokenizer']['min_new_tokens'], \n",
    "                                   max_new_tokens = max_new_tokens)\n",
    "\n",
    "        decoded_str = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "        \n",
    "        summary = decoded_str.split('Summary:\\n')[1]\n",
    "        \n",
    "        # \\n 제거\n",
    "        summary = re.sub('\\n', '', summary)\n",
    "        \n",
    "        fname_list.append(fname)\n",
    "        summary_list.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트링의 시작과 끝에 있는 모든 공백 문자를 제거\n",
    "for i, s in enumerate(summary_list):\n",
    "    summary_list[i] = s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_0', 'test_1', 'test_2', 'test_3', 'test_4', 'test_5', 'test_6', 'test_7', 'test_8', 'test_9', 'test_10', 'test_11', 'test_12', 'test_13', 'test_14', 'test_15', 'test_16', 'test_17', 'test_18', 'test_19', 'test_20', 'test_21', 'test_22', 'test_23', 'test_24', 'test_25', 'test_26', 'test_27', 'test_28', 'test_29', 'test_30', 'test_31', 'test_32', 'test_33', 'test_34', 'test_35', 'test_36', 'test_37', 'test_38', 'test_39', 'test_40', 'test_41', 'test_42', 'test_43', 'test_44', 'test_45', 'test_46', 'test_47', 'test_48', 'test_49', 'test_50', 'test_51', 'test_52', 'test_53', 'test_54', 'test_55', 'test_56', 'test_57', 'test_58', 'test_59', 'test_60', 'test_61', 'test_62', 'test_63', 'test_64', 'test_65', 'test_66', 'test_67', 'test_68', 'test_69', 'test_70', 'test_71', 'test_72', 'test_73', 'test_74', 'test_75', 'test_76', 'test_77', 'test_78', 'test_79', 'test_80', 'test_81', 'test_82', 'test_83', 'test_84', 'test_85', 'test_86', 'test_87', 'test_88', 'test_89', 'test_90', 'test_91', 'test_92', 'test_93', 'test_94', 'test_95', 'test_96', 'test_97', 'test_98', 'test_99', 'test_100', 'test_101', 'test_102', 'test_103', 'test_104', 'test_105', 'test_106', 'test_107', 'test_108', 'test_109', 'test_110', 'test_111', 'test_112', 'test_113', 'test_114', 'test_115', 'test_116', 'test_117', 'test_118', 'test_119', 'test_120', 'test_121', 'test_122', 'test_123', 'test_124', 'test_125', 'test_126', 'test_127', 'test_128', 'test_129', 'test_130', 'test_131', 'test_132', 'test_133', 'test_134', 'test_135', 'test_136', 'test_137', 'test_138', 'test_139', 'test_140', 'test_141', 'test_142', 'test_143', 'test_144', 'test_145', 'test_146', 'test_147', 'test_148', 'test_149', 'test_150', 'test_151', 'test_152', 'test_153', 'test_154', 'test_155', 'test_156', 'test_157', 'test_158', 'test_159', 'test_160', 'test_161', 'test_162', 'test_163', 'test_164', 'test_165', 'test_166', 'test_167', 'test_168', 'test_169', 'test_170', 'test_171', 'test_172', 'test_173', 'test_174', 'test_175', 'test_176', 'test_177', 'test_178', 'test_179', 'test_180', 'test_181', 'test_182', 'test_183', 'test_184', 'test_185', 'test_186', 'test_187', 'test_188', 'test_189', 'test_190', 'test_191', 'test_192', 'test_193', 'test_194', 'test_195', 'test_196', 'test_197', 'test_198', 'test_199', 'test_200', 'test_201', 'test_202', 'test_203', 'test_204', 'test_205', 'test_206', 'test_207', 'test_208', 'test_209', 'test_210', 'test_211', 'test_212', 'test_213', 'test_214', 'test_215', 'test_216', 'test_217', 'test_218', 'test_219', 'test_220', 'test_221', 'test_222', 'test_223', 'test_224', 'test_225', 'test_226', 'test_227', 'test_228', 'test_229', 'test_230', 'test_231', 'test_232', 'test_233', 'test_234', 'test_235', 'test_236', 'test_237', 'test_238', 'test_239', 'test_240', 'test_241', 'test_242', 'test_243', 'test_244', 'test_245', 'test_246', 'test_247', 'test_248', 'test_249', 'test_250', 'test_251', 'test_252', 'test_253', 'test_254', 'test_255', 'test_256', 'test_257', 'test_258', 'test_259', 'test_260', 'test_261', 'test_262', 'test_263', 'test_264', 'test_265', 'test_266', 'test_267', 'test_268', 'test_269', 'test_270', 'test_271', 'test_272', 'test_273', 'test_274', 'test_275', 'test_276', 'test_277', 'test_278', 'test_279', 'test_280', 'test_281', 'test_282', 'test_283', 'test_284', 'test_285', 'test_286', 'test_287', 'test_288', 'test_289', 'test_290', 'test_291', 'test_292', 'test_293', 'test_294', 'test_295', 'test_296', 'test_297', 'test_298', 'test_299', 'test_300', 'test_301', 'test_302', 'test_303', 'test_304', 'test_305', 'test_306', 'test_307', 'test_308', 'test_309', 'test_310', 'test_311', 'test_312', 'test_313', 'test_314', 'test_315', 'test_316', 'test_317', 'test_318', 'test_319', 'test_320', 'test_321', 'test_322', 'test_323', 'test_324', 'test_325', 'test_326', 'test_327', 'test_328', 'test_329', 'test_330', 'test_331', 'test_332', 'test_333', 'test_334', 'test_335', 'test_336', 'test_337', 'test_338', 'test_339', 'test_340', 'test_341', 'test_342', 'test_343', 'test_344', 'test_345', 'test_346', 'test_347', 'test_348', 'test_349', 'test_350', 'test_351', 'test_352', 'test_353', 'test_354', 'test_355', 'test_356', 'test_357', 'test_358', 'test_359', 'test_360', 'test_361', 'test_362', 'test_363', 'test_364', 'test_365', 'test_366', 'test_367', 'test_368', 'test_369', 'test_370', 'test_371', 'test_372', 'test_373', 'test_374', 'test_375', 'test_376', 'test_377', 'test_378', 'test_379', 'test_380', 'test_381', 'test_382', 'test_383', 'test_384', 'test_385', 'test_386', 'test_387', 'test_388', 'test_389', 'test_390', 'test_391', 'test_392', 'test_393', 'test_394', 'test_395', 'test_396', 'test_397', 'test_398', 'test_399', 'test_400', 'test_401', 'test_402', 'test_403', 'test_404', 'test_405', 'test_406', 'test_407', 'test_408', 'test_409', 'test_410', 'test_411', 'test_412', 'test_413', 'test_414', 'test_415', 'test_416', 'test_417', 'test_418', 'test_419', 'test_420', 'test_421', 'test_422', 'test_423', 'test_424', 'test_425', 'test_426', 'test_427', 'test_428', 'test_429', 'test_430', 'test_431', 'test_432', 'test_433', 'test_434', 'test_435', 'test_436', 'test_437', 'test_438', 'test_439', 'test_440', 'test_441', 'test_442', 'test_443', 'test_444', 'test_445', 'test_446', 'test_447', 'test_448', 'test_449', 'test_450', 'test_451', 'test_452', 'test_453', 'test_454', 'test_455', 'test_456', 'test_457', 'test_458', 'test_459', 'test_460', 'test_461', 'test_462', 'test_463', 'test_464', 'test_465', 'test_467', 'test_468', 'test_469', 'test_470', 'test_471', 'test_472', 'test_473', 'test_474', 'test_475', 'test_476', 'test_477', 'test_478', 'test_479', 'test_480', 'test_481', 'test_482', 'test_483', 'test_484', 'test_485', 'test_486', 'test_487', 'test_488', 'test_489', 'test_490', 'test_491', 'test_492', 'test_493', 'test_494', 'test_495', 'test_496', 'test_497', 'test_498', 'test_499']\n",
      "['#Person1#은 더슨 씨에게 내부 메모를 받아쓰도록 요청하고, 모든 통신이 이메일 통신과 공식 메모로 제한되며, 즉시 메시지를 계속 사용하는 어떤 직원이라도 먼저 경고를 받고 직무 정지에 처해질 것이라고 말합니다.', '#Person2#는 교통 체증에 걸렸다. #Person1#는 #Person2#에게 대중교통을 이용하거나 자전거를 타는 것을 제안한다. #Person2#는 자유를 잃는 것을 걱정하지만, 운동을 하는 것이 좋다고 생각한다.', '#Person1#은 케이트에게 마샤와 히어로가 이혼하려고 하며 이혼이 새해 초에 확정될 것이라고 말한다. 케이트는 이혼이 놀란다고 생각하며 이혼이 언제 확정되는지 묻는다.', '#Person1#은 브라이언의 생일 파티에 참석하고 춤을 추고 술을 마시며 즐겼다.', '#Person1#과 #Person2#는 올림픽 스타디움을 방문하고 있습니다. #Person2#는 스타디움의 완공 시기, 좌석 수, 그리고 외국인 방문객을 위한 영어로 번역된 표지판에 대해 #Person1#에게 알려줍니다.', '#Person1#은 회사에서 일하는 것이 도움이 되지 않다고 생각하고 사업 계획서를 작성하고 투자자를 모집하여 자신의 회사를 창업하기로 결정했다. #Person2#는 #Person1#에게 잘 작성된 사업 계획서가 어떻게 보여야 하는지 알려줍니다. #Person1#은 그냥 예전 일을 계속하는 것이 더 좋다고 생각합니다.', '#Person2#는 많이 긁고 있고 떨어지지 않는 것 같다. #Person1#는 그것이 수두라고 생각하지만 #Person2#는 그것이 두드러기나 알레르기일 수도 있다고 생각한다.', '#Person2#는 체크아웃 시 청구서에 세탁 서비스 비용이 추가되어 있다는 것을 발견합니다. #Person1#는 실수가 있었다고 사과하고 청구서를 수정합니다.', '#Person1#은 스티븐에게 아내가 그와 비서의 불륜을 발견했다고 말한다. 스티븐은 그녀가 이혼을 재고하도록 설득해 볼 것이다.', '#Person1#과 #Person2#는 에이브러햄 링컨에 대해 이야기합니다.', '#Person1#과 #Person2#는 허베이로 여행을 가려고 하지만, 그곳에서 심각한 모래폭풍이 일어나고 있다는 것을 알게 됩니다.', '#Person2#는 프란시스의 생일 파티에 참석하고 리모컨 자동차를 선물로 준다. 프란시스는 그것을 좋아하고 감사하다.', '토니는 부정행위를 하다 걸렸다. 그는 아버지가 그를 죽일 것이라고 생각하고 공부하지 않고 부정행위를 하고 걸렸다는 사실이 끔찍하다고 생각한다. 스티븐은 그가 그것을 배우고 충분하다고 생각한다.', '#Person1#은 아홉시 반 기차를 타야 하지만 톰은 아직 시간이 많다고 생각한다.', '#Person1#은 삶을 어떻게 조정해야 할지 모르고 있습니다. #Person2#는 #Person1#에게 잠, 음주, 운동, 그리고 미래에 대한 걱정에 대한 조언을 제공합니다.', '#Person1#은 #Person2#에게 루오지아의 결혼 파티에 초대하고 그녀의 행복한 결혼을 축하하는 카드를 가져갈 것이라고 말합니다.', '#Person1#과 #Person2#는 잔인하지만 재미있는 친구들에 대해 이야기하고 있습니다.', '#Person1#은 마이크에게 그의 누나에 대해 묻고 그녀가 마이크와 비슷하다고 생각한다.', '#Person1#은 머리가 아프고 어지러워서 #Person2#에게 전화를 걸었습니다.', '#Person2#는 새로운 휴대폰을 원합니다.', '프랭크는 우체국에서 일하게 되었다. 그는 그 일이 힘든 것이라고 생각하지만, 그 일이 가족들에게 훌륭한 건강보험 혜택을 제공하기 때문에 그것을 선택했다.', '#Person2#는 컴퓨터 프로그램 작성, 비서 기술, 의사 면허, 운전 면허, 사무 기술 교육, 그리고 사무용 기기 조작에 대한 특별한 교육을 받았습니다.', '#Person1#은 스테이크가 너무 익혀 있다고 생각하고 바꾸고 싶어합니다. #Person2#는 동의합니다.', '#Person1#은 톰에게 톰의 소설이 노벨상을 받았다고 알려줍니다.', '#Person2#는 #Person1#에게 #Person2#의 전공, 학위, 그리고 이전 직장에서 담당한 업무에 대해 이야기합니다.', '#Person1#과 #Person2#는 술에 대해 이야기하고 있습니다. #Person2#는 술을 많이 마시고 내성을 키워야 한다고 생각합니다. #Person1#는 맥주를 좋아하지만 두통이 생기기 때문에 맥주를 많이 마실 수 없습니다. #Person2#는 #Person1#에게 내성을 키우라고 제안하고 같이 나가서 술을 마시자고 제안합니다.', '#Person1#은 메이에게 피크닉 준비를 도와달라고 요청하고, 메이는 다니엘에게 도움을 청하지 않고 혼자서 할 것이라고 말한다.', '제임스와 뮤리엘은 새로운 계정에 대해 이야기하고 휴가 동안 무엇을 했는지 공유합니다. 그들은 스키를 타는 것을 좋아하지만 그들의 아내들은 그렇지 않습니다.', '#Person1#은 돈을 인출하려 하지만 기계가 그렇게 하지 않고 세계 야생동물 기금에 10000 달러를 이체하려 합니다. #Person1#은 돈을 줘 달라고 요청하지만 기계는 문을 봉쇄합니다.', '#Person2#는 #Person1#에게 자신이 외향적인 사람이라고 말하고 소통에서 가장 중요한 것', '폴리 씨는 끔찍한 일에서 벗어나고 싶어합니다. #Person1#은 폴리 씨에게 탄산 음료를 사는 것을 제안하지만, 폴리 씨는 지갑에 돈', '프란시스와 모니카는 금요일 오후에 재무 보고서를 작업하기로 합의했습니다.', '#Person2#는 면접 수업에서 중요한 것들에 대해 이야기하고 있습니다. #Person1#는 친절함과 솔직함이 중요하다고 생각합니다.', '#Person1#은 컷에서 마이크의 연기가 맞지 않다고 생각하고 그에게 다른 방식으로 시도해 보라고 제안한다.', '#Person1#은 토드 부인을 방문하기 위해 가게에 왔다. 토드 부인은 새로 이사 온 #Person1#이 먼저 전화를 걸어야 했다고 생각하지만, 그들은 가게에서 필요한 것이 없다.', '빌은 일하는 시간이 길어서 피곤해 보입니다. 그는 동생이 미국에 있다고 말하고 시계를 설정하는 방법을 #Person1#에게 알려줍니다.', '사이먼은 핵무기 확산 막기 위한 시위에 참여하고 싶지만 클레오는 시위에 참여하고 싶지 않습니다. 사이먼은 클레오에게 시위가 평화로울 것이라고 설명하지만 클레오는 시위에 참여하고 싶지 않습니다. 클레오는 사이먼에게 정치학 수업에 참석하는 학생들에게 가보라고 제안합니다.', '#Person1#과 #Person2#는 누군가를 신뢰하는 것이 어렵다고 생각합니다.', '마크는 매기의 노트를 빌리고 싶지만 매기는 수업 시작 후 30분 후에 졸리기 때문에 거절한다. 그들은 공부 파트너가 되기로 합의한다.', '#Person2#는 고급 지질학 과목에 등록하고 싶어합니다. 터너 교수는 #Person2#가 학점을 쉽게 받기 위해 등록하는 것이 아니라고 생각하고 그에게 등록을 허락합니다.', '#Person1#은 펜던트가 부러졌다고 #Person2#에게 말합니다. #Person2#는 새 것으로 바꿔주기로 합니다.', '#Person1#과 #Person2#는 옷 선물에 대해 논의하고 있습니다. #Person2#는 경기를 보고 싶지만 #Person1#은 옷 선물에 대해 논의하고 싶어합니다. #Person2#는 #Person1#이 살즈베리 씰즈를 욕하고 있다고 생각합니다.', '#Person1#은 #Person2#에게 직업 선택을 도와주고 있다. #Person2#는 미디어 쪽에서 일하는 것을 선호하고 인터랙티브 미디어로 결정한다.', '#Person1#과 #Person2#는 지루한 연설을 듣고 있다. #Person1#은 #Person2#에게 몇 가지 재미있는 것들을 제안하고 연설을 집중하라고 말한다.', '사라는 이사하고 싶지만 그럴 수 없습니다. #Person1#은 더 저렴한 집을 찾는 방법을 제안하고 그 예시를 알려줍니다.', '#Person1#은 마크 리치를 소개하고 그의 직업, 팀, 일, 그리고 영국에 오는 사람들에게 제안하는 것에 대해 묻습니다.', '루시와 린팡은 다음 수업이 뭐지 묻고 그들의 가장 좋아하는 과목에 대해 이야기한다.', '제임스는 토마스 부인의 집안일을 돕고 있습니다. 토마스 부인은 제임스에게 오스카를 산책시키고 집안일을 돌보는 것을 돕는 것에 대해 감사합니다. 제임스는 자전거를 사고 싶어하고 다음 주말에 할아버지 댁에 갈 예정입니다.', '#Person1#과 #Person2#는 봄이 온 것 같지만 밤에는 여전히 매우 춥다고 생각합니다.', '#Person1#은 마이크에게 그의 연기가 맞지 않다고 말하고 다른 방법을 시도해 보라고 제안한다.', '#Person1#은 프렌드십 호텔로 가는 택시를 타고 15위안을 지불하고 20위안을 납부합니다.', '#Person1#은 과자를 사서 돈이 없어 버스를 타지 못했습니다. #Person2#는 #Person1#에게 환승을 요청하라고 제안했습니다.', '#Person2#는 #Person1#에게 회사의 위치, 회사의 주요 회사, 그리고 회사의 식당에 대해 알려줍니다.', '#Person1#은 #Person2#에게 루루와 빅이 헤어졌다고 말한다.', '샐리는 데이브에게 짐이 아직 돌아오지 않았다고 말한다. 데이브는 나중에 다시 전화할 것이다.', '#Person2#는 #Person1#에게 시청으로 가는 방법을 알려줍니다.', '#Person1#은 여권을 분실했습니다. #Person2#는 여권을 찾는 데 도움을 주고 새 여권을 발급받는 방법을 알려줍니다.', '레아는 나다니엘에게 전화를 걸어 콜린스 선생님이 다시 전화할 수 없다고 말합니다. 그녀는 나다니엘에게 폰다 씨와 통화할 수 있는 시간을 제안합니다.', '#Person1#과 #Person2#는 사라가 딕과 같은 남자에게 마음을 두었다는 것에 대해 놀란 표현을 합니다.', '#Person1#과 #Person2#는 파티에 참석하고 있습니다. 그들은 여자들에 대해 이야기하고 그들이 좋아하는 여자들에 대해 이야기합니다. #Person1#은 #Person2#에게 여자들에게 말하는 것을 제안하지만, #Person2#는 그렇게 하기 어렵다고 생각합니다.', '잭은 정치학 수업이 좋았다고 생각하지만, 작년에 비즈니스 커뮤니케이션 수업이 더 좋았다고 생각한다.', '#Person1#과 #Person2#는 베이징의 날씨에 대해 이야기하고 있습니다. 그들은 베이징의 봄, 여름, 겨울, 그리고 저녁에 대해 이야기합니다.', '#Person1#과 #Person2#는 오늘 밤에 영화를 보기로 했습니다. 그들은 몇 가지 제안을 논의하고 결국 전쟁 영화를 보기로 결정했습니다.', '아담이 #Person1#에게 학교 구경을 시켜주고 있습니다. #Person1#은 학교에 입학하고 싶어합니다.', '#Person1#은 #Person2#에게 자신이 임신했다고 말한다.', '#Person1#과 #Person2#는 존이 그녀에게 반한 것 같다고 생각합니다.', '#Person1#은 #Person2#에게 소프트웨어와 하드웨어 업그레이드를 고려하도록 제안합니다.', '#Person1#과 #Person2#는 서로 자기 소개를 하고 있습니다. #Person1#은 콜롬비아 혈통이 있고 스페인어를 할 수 있습니다. #Person2#는 멕시코 사람이고 중국에서 온 업무 여행 중입니다.', '#Person1#은 체중이 증가했다. #Person2#는 #Person1#에게 식단 조절과 운동을 제안한다.', '제임스는 예약을 하고 왔습니다. #Person1#은 그에게 홀을 제안하지만 제임스는 거절합니다.', '#Person2#는 #Person1#에게 공장의 면적, 설립 시기, 직원 수, 그리고 생산 공장에 대해 알려줍니다.', '레베카는 #Person1#에게 그녀의 첫 직장이 요크 헤럴드였다고 말합니다. 그녀는 그 직장을 즐겼고 그것이 그녀의 실력을 향상시키는 데 도움이 되었다고 생각합니다. 그녀는 런던으로 이사하고 주간 런던에서 일하기 시작했습니다.', '#Person1#과 #Person2#는 그룹 발표를 위해 포스터를 만들기 위한 물건을 사기 위해 문구점에 갈 예정입니다. 그들은 쇼핑 목록을 만들고 필요한 물건을 찾는 방법을 논의합니다.', '메리는 인력시장에서 일자리를 찾는 것이 피곤하다고 생각하고, #Person1#은 인터넷에서 구직하는 것을 제안한다. 메리는 그것이 안전하다고 생각하고 시도해 볼 것이다.', '#Person2#는 쇼핑 예산을 세우고 있습니다. #Person1#는 #Person2#의 예산 계획을 칭찬합니다.', '제인은 수잔을 방문하기 위해 병원에 가고 있다. 헨리는 제인에게 어떤 버스를 타야 하는지 알려줍니다.', '#Person1#은 내년 판매 예측에 대해 #Person2#와 이야기하고 싶어합니다. 그들은 다음 화요일 오후 2시 30분에 만나기로 합니다.', '#Person2#는 #Person1#에게 뉴욕에 가는 첫 번째 여행에 대한 추천을 해줍니다.', '#Person2#는 #Person1#에게 회사의 정보와 직업 선호도에 대해 알려줍니다. #Person1#는 #Person2#에게 월급, 복리후생 혜택, 보험 및 건강보험에 대해 알려줍니다.', '#Person1#은 계약서를 서명하러 왔지만 #Person2#는 아직 준비되지 않았다고 말합니다. #Person1#은 수정을 요청하고 #Person2#는 오늘 저녁에 계약서를 작성하고 서명을 위해 복사본을 만들 것입니다.', '#Person1#은 차량 사고를 경험하고 있습니다. #Person2#는 구급차와 경찰을 불러주기로 합니다.', '#Person2#는 #Person1#에게 학교 클리닉으로 가는 길을 알려줍니다.', '#Person2#는 방이 너무 시끄러워서 바꾸고 싶어합니다. #Person1#는 오늘 여분의 방이 없지만 내일 여러분이 선택할 수 있는 방이 있을 것이라고 말합니다.', '#Person1#은 #Person2#를 베이징 호텔로 데려가고 있습니다. #Person1#은 #Person2#를 오늘 저녁 연회에 초대하고 관광을 제안합니다.', '#Person1#은 길을 잃었습니다. #Person2#는 #Person1#에게 자신의 위치를 알려주고 리우 이창으로 가는 방법을 알려줍니다.', '#Person2#의 컴퓨터가 잘 작동하지 않고 있다. #Person1#은 수리공에게 전화하는 것을 제안한다.', '#Person2#는 어머니 생일 선물로 시계를 사고 싶어하고, #Person1#의 도움으로 금 시계를 선택합니다.', '피셔 씨와 로스 씨는 피셔 씨의 뉴질랜드 지사 개설 발표 준비에 대해 이야기하고 있습니다. 그들은 발표의 시간, 방, 간식, 장비, 그리고 예상 인원에 대해 논의하고 있습니다.', '#Person2#는 #Person1#에게 러시아와 캐나다의 주요 차이점에 대해 이야기합니다. #Person2#는 러시아 사람들이 빠르게 움직이는 것 같다고 생각하지만, 캐나다인들은 더 차분하다고 생각합니다.', '#Person2#는 카리브해로 휴가를 가려고 하지만, #Person1#는 작년에 폭풍이 많이 일어난 것을 기억하고 있습니다.', '#Person1#은 소풍에 가져갈 과일을 물어봅니다. #Person2#는 바나나와 포도를 제안합니다.', '#Person1#은 #Person2#에게 소형차 렌트 비용을 묻고 운전 면허증을 보여줍니다.', '#Person1#과 #Person2#는 다른 사람들이 미소를 짓는 것에 대해 다른 의견을 가지고 있습니다.', '#Person1#과 #Person2#는 지난해의 판매 정보를 논의하고 있습니다. 그들은 월리스의 기여와 새로운 마케팅 전략 때문에 성공했다고 생각합니다.', '#Person2#는 택시에서 가방을 잃어버렸다. #Person1#는 #Person2#에게 돈을 빌려주고 집에 데려다 줄 것이다.', '린과 스티븐은 베이징에서 식사를 하고 있습니다. 린은 스티븐에게 다음에 베이징에 오면 그녀를 대접하라고 말합니다. 그들은 팁에 대해 이야기합니다. 린은 미터기에 나온 금액만 지불하면 돼고, 일반적으로 호텔 짐꾼에게는 가방 하나당 10위안을 팁으로 주지', '빌은 오늘 룸메이트에 대해 알아보았고, 그 룸메이트는 브레인 로커라고 불린다.', '톰 윌슨이 호텔 청구서를 신용카드로 지불하고 있습니다.', '수잔이 캐롤에게 전화를 받아 파티에 대한 정보를 알려줍니다.', '#Person1#은 #Person2#를 알고 있다고 생각하지만, #Person2#는 그렇지 않다. #Person1#은 몇 가지 추측을 하지만 결국 그들은 이전에 대화한 적이 없다는 것을 알게 된다.', '#Person1#과 #Person2#는 트럼프에 대한 다른 의견을 가지고 있습니다. #Person1#은 트럼프가 다시 선출되는 것을 상상할 수 없고 바이든에게 투표할 것입니다. #Person2#는 트럼프에 믿음이 있고 그가 다시 선출되면 행복할 것입니다.', '#Person2#는 #Person1#에게 ATM 사용법을 알려줍니다.', '수잔 밀러는 존에게 그 메모의 복사본을 제 비서에게 달라고 요청하지만, 존은 그것을 찾지 못한다.', '#Person1#은 릴리를 소풍에 초대하고 릴리에게 무엇을 가져갈지 알려줍니다.', '#Person1#은 #Person2#에게 중국 테이블 에티켓에 대해 묻고, #Person2#는 젓가락 사용에 대해 묻습니다. #Person1#은 젓가락을 어리석게 놓는 #Person2#에게 경고합니다.', '프랭크와 메리는 여가 시간에 영화를 보는 것을 좋아하고 자주 영화관에 가지만, 메리는 보통 무비 살롱에서 영화를 빌린다.', '#Person1#과 #Person2#는 녹색당, 압력 단체, 정치 이슈에 대한 사람들의 이해, 그리고 미디어의 정치 이슈 보도에 대해 이야기합니다.', '#Person1#은 윌슨 씨에게 상품에서 실수를 한 것에 대해 사과하고 책임을 지겠다고 말합니다. 그들은 조사 후 해결될 것으로 예상되는 첫 번째 문제와 우리의 샘플에 미치지 못하는 모든 상품을 교', '#Person2#는 #Person1#에게 강도를 보았고 경찰서로 가서 추가 질문을 받을 수 있다고 말합니다.', '#Person2#는 #Person1#에게 아빠와 엄마가 데이트를 하러 나갈 것이라고 말한다.', '#Person1#은 새해 결심으로 다이어트를 시작하고 캐롤에게 그런 얘기를 전에 들었다고 말한다. 캐롤은 #Person1#을 믿지 않는다.', '카렌 후앙은 비교문학 287 수업에 등록하고 싶지만 수업이 가득 찼습니다. #Person1#은 카렌에게 대기 명단에 올리고 특별 코드를 사용하여 수업에 들어가는 방법을 알려줍니다.', '#Person1#과 #Person2#는 비를 피하기 위해 우산을 같이 쓰고 가든 호텔로 가고 있습니다.', '잭은 데이지에게 새 차를 보여주고 그것이 빠르고 멋지다고 말한다. 그들은 파운드 그늘을 찾아봐.', '#Person2#는 #Person1#에게 불이 밤 10시쯤에 발생했다고 말한다.', '#Person2#는 905위안의 계산을 위해 현금으로 지불하려 하지만, #Person1#은 가게 규정에 따라 그것이 안 된다고 말합니다. #Person2#는 신용카드로 지불하고 영수증을 받습니다.', '#Person2#는 #Person1#에게 차를 세차하고 싶다고 말합니다. #Person1#은 일반 세차 패키지를 추천하고 #Person2#는 그것을 선택합니다.', '해리는 휴가 여행을 가기 위해 아내와 함께 이집트로 가고 싶어하지만, 아내는 여행 전에 몇 가지 사항을 해결하기 위해 걱정하고 있습니다.', '#Person1#은 웨이트를 사용하는 방법을 알고 싶어합니다. 존슨은 #Person1#에게 기계를 사용하기 전에 준비하고 트레이닝 카드를 사용하는 방법을 알려줍니다. 그들은 기계를 사용하고 적합한 시작 무게를 결정하기 위해 각 기계를 보고 있습니다. 그들은 나머지 기계들을 함께 보고 자신의 한계를 알아내는 것이 중요하다고 생각합니다.', '#Person1#과 #Person2#는 일자리를 잃었다. 그들은 전기기사 프로그램에 지원하기로 결정했다.', '#Person1#은 #Person2#에게 강아지들에게 밥을 주고 목욕을 시키고 동물병원 예약을 잊지 않도록 요청합니다.', '#Person1#은 집주인에게 돈을 빚지고 있고 에이든에게 돈을 빌리려고 합니다. 에이든은 돈이 부족하지만 20달러를 빌려줍니다. 그들은 오늘 밤에 저녁 식사를 함께 할 예정입니다.', '#Person2#는 자선 단체에서 일한 경험이 그녀의 사고 방식에 영향을 미쳤다고 생각합니다.', '#Person1#은 #Person2#에게 결정을 내리기 위해 한 주의 시간이 필요하다고 말합니다.', '#Person2#는 #Person1#에게 무탄과 함께 베이징 오리구이를 추천합니다.', '안젤라는 댄에게 전화를 걸어 다음 주에 있는 결혼식에 메건을 초대하도록 댄에게 메시지를 남기고 싶어한다.', '#Person1#과 #Person2#는 디저트 시간에 다양한 디저트를 시도해보고 있습니다. 그들은 그리스 요구르트, 이탈리아 티라미수, 바나나 튀김을 시도해보고 있습니다. 그들은 바나나 튀김을 가져가기로 결정했습니다.', '스미스 씨는 #Person1#에게 그의 학력, 연령, 그리고 은행에서의 연봉에 대해 이야기합니다.', '#Person1#은 #Person2#의 도움으로 바비 인형을 구매하고 현금으로 지불합니다.', '#Person2#는 조던 스포츠 신발을 사고 싶지만 #Person1#은 더 싼 가격에 세일 중입니다', '#Person1#은 과학 박물관으로 가고 싶지만 길을 잃어버렸습니다. #Person2#는 #Person1#에게 티켓 기계를 어떻게 사용해야 하는지 알려줍니다.', '사이먼은 은퇴 후에 가족과 더 많은 시간을 보낸다. 그는 단계적 은퇴 프로그램에 참여하고 있다. 이 프로그램은 회사가 임시 직원을 고용하는 대신 은퇴한 직원들이 접근할 수 있는 웹사이트에 채용 공고를 올리는 것이다. 사이먼은 이 프로그램이 유연성을 얻는 회사에 이익이 된다고 생각한다.', '#Person1#은 로키에게 여자를 찾는 방법에 대해 조언하고 그의 성별 역할 관점에 대해 비판한다. 로키는 집에 있는 여자를 선호하고, #Person1#은 외향적이고 사람들의 차이를 비판하지 않는 여자를 좋아한다. 그들은 그들의 견해가 바꿀 수 없다고 생각한다.', '#Person1#과 #Person2#는 어제 밤의 폭풍에 대해 이야기하고 있습니다.', '#Person1#은 #Person2#와 함께 TV를 보는 것을 좋아하지만, #Person2#는 그것이 지루하다고 생각하고 밖에 나가는 것을 선호한다. #Person1#은 함께 할 수 있는 것을 제안하고, #Person2#는 음악을 제안한다.', '벤은 수업 준비에 떨려 있다. #Person1#은 그에게 편하게 생각하고 새로운 학교 생활에 적응하라고 격려한다. 그들은 학교 시간표에 대해 이야기한다.', '애덤은 오늘 훨씬 나아진 무릎 상태를 #Person1#에게 알리고, 그들은 미시간과의 경기에 대해 이야기한다. #Person1#은 그들이 힘든 경기를 하게 될 것이라고 생각하고, 애덤은 전체 훈련에 참여하러 돌아올 것이다.', '#Person1#은 #Person2#에게 프린터 고장 때문에 복사본을 출력해달라고 요청합니다.', '#Person1#은 커튼을 걸고 싶어하고 #Person2#는 도와주기로 합의했다.', '잭은 #Person1#에게 다음 주말이 가장 적합하다고 말합니다.', '#Person1#은 #Person2#에게 화를 낸 것에 대해 사과하고, #Person2#는 큰 산불을 끄기 위해 낮과 밤을 가리지 않고 일했다고 말한다. #Person1#은 임신했다고 말하지만, #Person2#는 그것이 자기 아기가 아니라고 생각한다.', '#Person2#는 #Person2#의 딸이 대학을 결정하지 못하고 있어서 걱정하고 있습니다. #Person1#는 #Person2#에게 그녀가 스스로 결정을 내릴 수 있다고 말합니다.', '#Person1#은 큰 실수를 저지르고 직장을 잃을 것이라고 생각하고 있다. #Person2#는 #Person1#에게 현실적으로 어떤 일이 일어날지 생각하고 다른 직장을 찾을 때까지 #Person2#와 함께 살 수 있다고 제안한다.', '#Person2#는 #Person1#에게 친구가 방문하고 강연을 할 예정이라고 말한다. #Person1#는 그 강연을 듣고 싶어한다.', '#Person2#는 아픈 것 같아서 존의 집에 갈 수 없다. #Person1#는 #Person2#를 위해 스프를 만들어 줄 것이다.', '파버 씨가 요크 호텔에 전화하여 더블 룸을 예약하고 싶어합니다. #Person1#은 그에게 하루에 $130이며 조식이 포함되어 있다고 알려줍니다.', '#Person1#은 웨스트 더비에 있는 연립 주택을 찾고 싶어합니다. #Person2#는 사우스 더비에 있는 존 고드프리의 전화번호를 #Person1#에게 알려줍니다.', '#Person1#과 #Person2#는 누가 잘못했는지에 대해 논쟁하고 있습니다.', '달린은 댄에게 전화를 걸어 주문이 지연되었다고 말하고 스티브에게 불평하기 위해 그의 전화번호를 요청한다.', '#Person1#과 #Person2#는 뉴욕 타임즈, 워싱턴 포스트, 그리고 로스앤젤레스 타임즈의 창립 시기에 대해 이야기하고 있습니다.', '#Person2#의 컴퓨터에 바이러스가 침투했다고 생각하지만, #Person1#은 실제로는 이메일 용량을 초과했다고 말한다.', '#Person1#은 #Person2#에게 주말 즐거웠다고 말합니다.', '#Person1#은 먹고 싶지만 무엇을 먹고 싶은지 모르고 있습니다. #Person2#는 판다 익스프레스에서 중국 음식을 사는 것을 제안합니다.', '메리는 톰에게 판매 직원 자리를 다른 사람에게 제공하기로 결정했다고 알리고, 톰은 그들의 결정을 재고하도록 부탁합니다.', '#Person1#은 누군가에게 전화를 걸었지만 그 사람은 전화를 받지 않았습니다.', '#Person1#은 #Person2#에게 음악 선생님이 되고 싶은 이유, 학위, 좋아하는 음악 종류, 클래식 음악에 대한 알아봄, 그리고 추천에 대해 묻습니다.', '#Person2#는 미국인 여자를 만났고 그녀에게 반했다. #Person1#는 #Person2#에게 그녀에게 전화하고 저녁 식사에 초대하는 것을 제안한다.', '#Person1#과 #Person2#는 미렐라가 어제 회사에 어떤 식으로 하고 왔는지 봤다. 그녀는 사무실에서 집처럼 편하게 지내고 있다. #Person1#은 그녀가 캐주얼한 재킷과 바지를 입는 것이 이상하다고 생각하지만, #Person2#는 그녀가 좀 더 캐주얼한 재킷과 바지를 입을 수 있다고 생각한다.', '#Person2#는 자신만의 법률 사무소를 세우려 하고 있습니다. #Person1#는 #Person2#에게 도움을 제안합니다.', '피터는 케이트에게 어젯밤에 온라인에서 밤새도록 머무렸다고 말한다.', '#Person1#과 #Person2#는 배와 보트가 기차, 비행기, 자동차에 자리를 내주고 있다고 생각합니다. 그들은 사람들이 배로 여행하고 싶어하지 않는 이유는 배의 속도가 너무 느리기 때문이라고 생각합니다.', '패니는 악몼을 꿨고 그 후 엄마가 그녀를 깨웠다. 패니는 미시간 대학교에 들어가는 것에 대해 걱정하고 있다. 앤디는 다른 학교가 패니를 받아줄 것이라고 생각한다.', '#Person1#과 어니는 밴드를 시작하고 바닐라 아이스의 노래를 연주하기로 결정했다.', '#Person1#과 #Person2#는 뉴올리언스에서 여행을 즐기고 있습니다. 그들은 재즈 클럽, 강변 보트 투어, 그리고 극장에 가는 것을 고려하고 있습니다.', '#Person1#은 #Person2#의 도움으로 신용카드로 옷을 구매했습니다.', '#Person1#은 블레이크 씨에게 전화를 걸어 포스터 씨에게 훈련 매뉴얼을 보내달라고 요청합니다. 블레이크 씨는', '#Person2#는 롱아일랜드로의 여행 계획을 #Person1#에게 알려줍니다. 그들은 호텔에서 묵고 관광을 할 예정입니다.', '#Person1#은 파멜라를 돌봐 달라고 #Person2#에게 부탁하고, #Person2#는 동의합니다. #Person1#은 #Person2#에게 감사하다고 말하고, #Person2#는 그것이 그녀의 일이라고 생각합니다.', '#Person2#는 #Person1#에게 77번 거리로 가는 버스 노선을 알려줍니다.', '#Person1#과 #Person2#는 이슬람에 대한 프로그램을 보고 있다. #Person2#는 무슬림들이 하지를 가는 이유와 사고 가능성에 대해 #Person1#에게 설명한다. 그들은 다른 신앙의 순례에 대해 이야기하고 루르드에 대해 논의한다.', '#Person1#은 길을 잃었습니다. #Person2#는 #Person1#에게 센트럴 백화점과 국립은행으로 가는 길을 알려줍니다.', '#Person1#과 #Person2#는 런던에 갈 수 있는 방법에 대해 논의하고 있습니다.', '톰과 캐서린은 점심 식사에 대해 이야기하고 있습니다. 톰은 점심 식사가 최악이었다고 생각하고 패스트푸드가 라이프 스타일이라고 생각합니다. 캐서린은 그런 곳을 피하는 미국인이 많다고 말합니다.', '#Person1#은 #Person2#에게 레모네이드, 바비큐 윙, 베이비 백 립을 주문하도록 도와줍니다.', '#Person2#는 #Person1#에게 더블 치즈버거, 용수철감자, 그리고 펩시콜라를 주문했습니다.', '#Person1#은 #Person2#가 아침 식사를 만드는 것을 보고 그것이 뭔지 알아 뭔지 모르고 그것이 뭔지 알아 뭔지 모르고 그것이 뭔지 알아 뭔지 모르고 그것이 뭔지 알아 뭔지 모르고 그것이 뭔지 알아 뭔지 모르고 그것이 뭔지 알아 뭔지', '#Person1#과 #Person2#는 그랜드 호텔로 가고 있습니다.', '#Person1#은 #Person2#의 사진을 찍어 아이들에게 미국 경찰이 어떻게 생겼는지 보여주고 싶어', '#Person1#은 #Person2#에게 내일 모든 방이 예약 완료되었다고 말합니다. #Person1#은 #Person2#에게 다른 호텔을 추천', '#Person2#는 미국에 공부하기 위해 비자를 신청했습니다. #Person2#는 비자 신청서가 복잡하다고 생각하며, 비자 거절의 이유는 양식을 제대로 작성하지 않거나 필요한 서류를 모두 내지 않는 것이라고 생각합니다.', '앤은 밤새도록 웃고 이야기했던 시간을 즐겼지만, 그녀는 너무 피곤해서 다시 널 보고 싶지 않다.', '메리는 온라인 쇼핑을 즐기며, 그것이 편리하고 저렴하다고 생각합니다. 그녀는 #Person1#에게 온라인 은행 계좌를 개설하는 방법을 알려줍니다.', '#Person2#는 #Person1#에게 미국식 회계에 익숙하지 않다고 말하고 회계 과정의 기본 개념을 소개합니다.', '제인은 피터에게 7월 중에 시안에 갈 것이라고 말하고 피터에게 함께 가고 싶은지 묻는다. 피터는 관심이 있고 비용이 얼마나 들지 묻는다. 그들은 북부 지방에 사는 부모님이 있는 사람들이 돈이 많으면 휴가를 어디로 갈 것인지에 대해 이야기한다.', '#Person2#는 #Person1#의 도움으로 딸을 위해 로맨스 영화를 대여하고 있습니다. #Person1#는 #Person2#에게 딸을 위해 영화를 대여하는 데 필요한 딸림 카드를 발급하고 대여료, 반납 시한, 연체료에 대해 알려줍니다.', '#Person1#은 미스터 리의 소포를 받습니다.', '#Person2#는 #Person1#에게 비행기 운항이 중단되어 공항 호텔에서 밤을 보내야 한다고 알립니다. #Person1#는 불을 켜놓지 않으면 잠을 자지 못한다고 말합니다.', '#Person1#은 #Person2#에게 지난주에 도움을 준 것에 대해 보답하고 싶어합니다. #Person2#는 그렇게 하지 않고 싶어하지만, 결국 그들은 식당에 가기', '#Person2#는 성적 때문에 걱정하고 있고 그 때문에 잠이 오지 않고 있다. #Person1#는 #Person2#에게 요가 수업을 듣거나 이완 요법을 배우는 것을 제안하지만, #Person2#는 공부에 매진해 있다. #Person1#는 음악을 듣는 것을 추천하고 경음악이나 클래식 음악을 듣는 것을 제안한다.', '#Person1#은 주방을 새로 만들고 싶어하지만 #Person2#는 그것이 유행을 따라하는 것이라고 생각합니다.', '스털링과 월터는 우드 교수님에 대해 이야기하고 있다.', '#Person1#은 검사 결과를 받고 싶지만 #Person2#는 확인하기 위해 한 번 더 검사를 하고 싶어합니다.', '마틴은 엘리자 선생님에게 다가오는 시험 준비가 잘 되고 있다고 말합니다. 마틴은 용돈이 없어서 아르바이트를 하고 있습니다. 마틴은 학생 복지 클럽이 도움이 되었다고 생각합니다.', '#Person1#은 #Person2#에게 소포를 한국으로 보내는 방법을 물어봅니다.', '린다는 휴대폰을 잃어버렸다. #Person1#은 빵집에 전화하고 여동생에게 전화하는 것을 제안한다.', '#Person1#은 영국인이고 #Person2#는 미국인입니다. 그들은 도시에 여행 중이며 음료를 한 잔 더 가져다 달라고 합니다.', '#Person1#은 여름방학에 쉬고 싶어하지만, #Person2#는 경영학 수업을 듣고 삼촌 회사에서 일하면서 경험을 쌓을 것이다.', '#Person2#는 개와 나뭇가지에 부딪혔다. #Person1#는 이것이 영화 한 편 같다고 생각하지만, #Person2#는 이것이 웃을 일이 아니라고 생각한다.', '#Person2#는 6년 동안 한 회사에 있었습니다. #Person2#는 지금 더 오래 일하고 많은 돈을 벌고 있습니다. #Person2#는 승진 준비가 되었고 매니지먼트 교육 과정을 두 번 수료했습니다.', '#Person1#은 당좌예금 계좌를 개설하고 싶어합니다. #Person2#는 #Person1#에게 이자를 얻지 못하고 돈을 어떻게 인출할 수 있는지 알려줍니다.', '#Person1#은 중국 요리를 먹고 싶어하고 #Person2#에게 추천을 요청합니다. #Person2#는 많은 유명한 중국 요리가 있다고 말하고 몇 가지를 소개합니다. #Person1#은 광동 요리를 먹고 싶어하지만 너무 멀다고 생각합니다. #Person2#는 베이징 요리를 추천하고 전취덕 식당을 소개합니다.', '#Person1#과 #Person2#는 배송 시간에 대해 이야기하고 있습니다. #Person1#은 배송 시간을 늘리지 않겠다고 말하고, #Person2#는 그것이 걱정스러워합니다. 그들은 결국 동의합니다.', '#Person1#은 #Person2#에게 독서등을 깨뜨렸다고 알리고 비용을 지불하겠다고 말합니다.', '#Person1#은 2006년 회계 연도 마케팅 계획에 대한 발표를 하고 있습니다. #Person2#는 그들이 더 젊은 소비자 집단에 호소하고 이미지를 재구성하려고 했다고 말합니다. #Person1#은 그들이 해외 시장에서 배송을 두 배로 늘리는 목표도 설정했다고 말합니다. #Person1#은 그들이 두 번째와 세 번째 부분을 설명하고 그래프를 보여줍', '#Person2#는 유럽 여행 계획을 #Person1#에게 알려줍니다.', '지미 폭스는 중형 차량을 예약하지만 #Person2#는 모두 예약되었다고 말합니다. 폭스는 컴팩트를 원하고 보험을 드리기로 합니다. #Person2#는 할인을 제안합니다.', '#Person1#은 엄마에게 카드 게임을 하도록 요청하지만, 엄마는 #Person1#에게 숙제를 다 했는지 확인하고 5분만 허락한다.', '앤은 존스 씨에게 회의 시간표를 알려줍니다.', '#Person1#과 #Person2#는 지리 수업을 준비하고 있다. 그들은 지리적 특성만 보여주는 세계 지도를 보고 있다. 그들은 바다, 산, 강, 그리고 기후에 대해 놀란다.', '#Person2#는 방에서 담배 냄새가 심해서 방을 바꾸고 싶어합니다. #Person1#는 바로 금연 방을 준비해 줄 것입니다.', '빌은 젖은 페인트에 손대지 않겠다고 약속하지만, 그는 그것을 잊고 공지를 붙이러 걸어가고 있습니다.', '벤은 엘라의 전화번호를 얻고 그녀에게 전화를 걸 것이다.', '짐은 빌에게 딕의 건강 상태를 물어봅니다.', '#Person2#는 최저임금으로 일하고 있고 야근에 대한 보상을 받지 못하고 있다. #Person1#는 #Person2#가 그만두면 안 된다고 생각하지만, #Person2#는 다른 일자리를 찾지 못할까봐 두려워한다.', '리사는 #Person1#에게 마크가 두 달 동안 다른 사람을 만나고 있다는 것을 알게 되었다고 말한다. 리사는 마크에게 진실을 말하거나 그녀와의 관계를 끝내지 않으면 이혼하겠다고 말했다.', '#Person2#는 #Person1#에게 의사가 #Person2#에게 적색 육류를 줄이고 식단을 정리하라고 조언했다고 말합니다.', '#Person1#은 떠나고 싶어하지만 #Person2#는 #Person1#이 그와 함께 있기를 원한다.', '#Person2#는 #Person1#에게 도서관 이용 방법을 알려줍니다. #Person1#는 영어 회화에 관한 두 권의 책을 대출하려고 합니다.', '#Person1#과 #Person2#는 좋은 날씨에 봄날씨를 즐기고 있습니다. 그들은 비가 올지 논의하고 이번 주말에 해변으로 가는 것을 제안합니다.', '#Person1#은 #Person2#에게 박물관에서 사진을 찍는 것이 금지되었다고 말합니다. #Person2#는 카메라를 압수하고 슬라이드나 그림 엽서를 구매하는 것을 제', '#Person2#는 대출 정책에 대한 정보를 얻고 싶어합니다. #Person1#는 대출 정책의 일반적인 조건을 소개하고 #Person2#의 신용 점수에 대해 묻습니다.', '#Person1#은 모니카의 발표에 대해 축하하고 그녀가 준비하는 데 몇몇 통계를 찾기 쉽지 않았다고 말한다. 모니카는 지난 주에 경제 전문가에게 상담했다고 말한다.', '#Person1#은 톰에게 러닝을 제안하지만 톰은 아침에 달리는 것을 선호한다. 그들은 내일 함께 달리기로 합의한다.', '#Person2#는 #Person1#에게 일본 레스토랑의 영업 시간과 제공 음식에 대해 알려줍니다.', '#Person1#은 심슨 씨에게 점심 식사를 제안하고 그들은 목요일에 12시 30분에 만나기로 합의했습니다.', '#Person1#은 데이트를 위해 레스토랑을 선택하는 데 도움을 청하고, #Person2#는 그녀의 추천을 제공합니다.', '#Person1#은 #Person2#에게 식사 비용을 지불하고 팁을 제공하지만, #Person2#는 팁을 받지 않습니다.', '#Person1#과 #Person2#는 각자의 나라에서 인기 있는 스포츠에 대해 이야기합니다.', '#Person2#는 헬싱키로 가는 비행기를 예약하고 싶어합니다. #Person1#는 가장 저렴한 비행기를 추천하고 출발 시간과 도착 시간을 알려줍니다. #Person2#는 채식주의자 식사를 요청합니다.', '#Person1#은 #Person2#에게 내일 플로리다로 가서 할머니를 방문하고 디즈니 월드에 갈 것이라고', '#Person2#는 호주에 가고 싶어하며, 특히 대장벽 산호초를 보고 싶어합니다.', '로라는 둘 다 건강과 외모를 위해 운동을 하고 있다. #Person1#은 걷는 것을 좋아하지만 헬스장에는 가지 않는다. 로라는 #Person1#에게 언젠가 헬스장에 같이 가자고 제안하지만, #Person1#은 그런 것에 대해 꽤 게으른 편이다.', '#Person2#는 시카고에서 태어났지만 윌메트에서 자랐다. #Person2#는 링컨 고등학교를 졸업하고 뮌헨에 살았다.', '#Person1#은 새로운 정장을 샀고 #Person2#는 그것이 좋은 거래라고 생각하지 않습니다.', '앤은 라디오에서 로빈을 인터뷰합니다. 로빈은 자전거 투어에 대해 설명하고 사이클리스트들이 출발할 때 도로를 막지 않을 것이라고 말합니다.', '#Person1#은 #Person2#에게 컴파리와 젓는 컴파리를 제공하고, 젓는 컴파리를 추천합니다. #Person1#은 싱거를 추천하고, #Person2#는 그것을 주문합니다.', '에릭은 그레고리에게 점심을 제안하지만 그레고리는 집에서 먹고 싶어한다. 그레고리는 에릭이 자기 중심적이라고 생각하지만 에릭은 그렇지 않다고 생각한다. 그들은 번지 점프에 대해 이야기하고 에릭은 그레고리에게 가르칠 수 있다고 생각하지만 그레고리는 그렇지 않다고 생각한다. 그들은 에릭이 지갑을', '#Person2#는 #Person1#이 노르망디 상륙작전에 대한 정보를 찾는 데 도움을 줍니다.', '#Person2#는 웨이트를 사용하고 싶지만 어디서 시작해야 할지 모르고 있습니다. #Person1#는 #Person2#에게 팁을 주고 웨이트를 사용하는 방법을 알려줍니다.', '#Person2#는 #Person1#에게 캠퍼스 내에 주차할 수 있는 공간이 있다고 말하고, 그 공간이 가득 찼지 않았다고 말한다.', '수잔은 에밀리에게 그녀의 급여 명세서에 대해 설명하고, 그녀의 급여에 대한 몇 가지 질문에 답한다. 수잔은 에밀리에게 연방 공제, 주 공제, 그리고 소득세에 대해 설명한다. 에밀리는 영국에서 똑같은 것이라고 생각하지만, 그녀는 별로 신경 쓰지 않았다.', '#Person1#은 기계로 간식을 사고 싶어하지만 기계는 신뢰할 수 없다.', '#Person2#는 겨울 휴가를 태국에서 여자친구와 보내려고 합니다. #Person1#는 이것이 빠르다고 생각하고 #Person2#의 말이 맞을 수 있다고 생각합니다.', '케이트는 돈을 모아 새로운 가구와 장식을 사고 장식을 다시 했다. 제임스는 그것들을 칭찬하지만 카펫은 예전 것이라고 생각한다. 케이트는 그것이 새 것이라고 말한다.', '#Person2#는 빌에게 하루 운동 스케줄을 알려줍니다. 빌은 그것이 어렵다고 생각합니다.', '#Person1#은 과학 과목에 등록하고 싶지만 지도학이 약하다. 마르켓은 #Person1#에게 비과학 전공자를 위한 좋은 입문 과목을 추천한다.', '팀은 프로젝트를 위해 친환경적인 삶을 어떻게 이끌어갈 것인지에 대해 이야기하고 있다. 팀은 자신과 가족들이 친환경적으로 살 수 있는 방법, 학교에서 친환경적으로 행동하는 방법, 그리고 학교 카페테리아에 대한 생각에 대해 이야기한다.', '#Person1#은 크리스마스 때 일하는 것이 너무 불쾌하다고 생각하고 그런 이유를 토니에게 말한다.', '빌은 수에게 케이크를 제공하지만 수는 다이어트 중이기 때문에 먹지 않습니다. 빌은 수에게 케이크를 먹으라고 제안하지만 수는 알레르기 반응을 피하기 위해 다른 음식을 먹지 않습니다. 빌은 수에게 뜨거운 수프를 가져다 줄 것이지만 수는 파티를 즐기고 있습니다.', '#Person2#는 여름 옷을 사고 싶어합니다. #Person1#는 20% 할인을 제공하고 섹션을 보여줍니다. #Person2#는 센스를 선택합니다.', '#Person1#은 예약 확인을 하지 않아 티켓을 찾지 못했습니다. #Person2#는 다른 티켓을 제안합니다.', '#Person1#과 #Person2#는 부활절 파티에 참석하고 있습니다.', '#Person1#은 자신의 아들이 나쁜 습관을 가지고 있다고 생각하고, #Person2#는 그에게 인내심, 애정, 존중을 가지고 대해야 한다고 제안한다. #Person2#는 또한 처벌을 강조하지 않고 원하는 행동을 거부하면 처벌하지 않는 것을 제안한다.', '#Person1#은 친구들인 줄리와 알렉스가 결혼할 것이라고 #Person2#에게 알렸다. #Person1#은 알렉스의 베스트맨과 이야기했고, 그들은 남자들만의 파티를 준비하고 있다. #Person2#는 스트립 클럽에 가지 않을 것이라고 생각하지만, #Person1#은 그것이 무해하다고 생각한다. 그들은 웬디가 결혼하고 있다는 것에', '#Person1#은 #Person2#에게 투표용지를 어떻게 받아야 하는지 알려줍니다.', '#Person1#은 회사가 인력을 줄일 예정이라고 #Person2#에게 말한다. 그들은 누가 해고될지에 대해 논의하고 상사가 너무 엄격하다고 생각한다.', \"#Person1#과 #Person2#는 중국 TV 시리즈 '이혼이라'를 보고 있다. 그들은 이혼률이 계속 상승하고 있다는 것에 동의하지만, 그들은 결혼에 대한 다른 관점을 가지고 있다.\", '주디는 #Person1#에게 여행 예산을 보여주고 교통비와 숙박 비용에 대해 이야기한다.', '#Person1#은 #Person2#에게 메리가 제로드와 결혼했다고 말한다.', '#Person2#는 택시에서 지갑을 잃어버렸다. #Person1#는 #Person2#에게 돈을 빌려주고 책을 사고 주유소에 갈 때 #Person2#와 함께 갈 것이다.', '#Person1#은 #Person2#에게 머피 뮤직과 U-튠즈가 합병했다고 말합니다. #Person2#는 그것이 소문일 것이라고 생각하지만, #Person1#은 그것이 사실이라고 생각합니다.', '톰은 새로운 비서가 도움이 된다고 생각하지만, 조는 그녀가 거만하다고 생각한다.', '사라는 회의에서 밥이 자신의 제안으로 모두를 방해하고 다른 사람들이 말하려는 것을 듣지 않았다고 화가 났습니다. #Person1#은 사라에게 짧고 간결하게 말하고 회의 후에 직접 관련된 사람들과 이야기하라고 제안했습니다.', '#Person1#과 #Person2#는 이슬람에 대한 프로그램을 보고 있습니다. 그들은 하즈, 사고, 그리고 다른 신앙의 순례에 대해 이야기합니다.', '테드는 제니에게 반했지만 그녀에게 고백하는 것을 두려워한다. 마이크는 테드에게 용기를 내고 그녀에게 말하라고 격려한다.', '#Person2#는 화가 날 때 음악을 듣고 운동을 하는 것을 제안합니다.', '#Person1#은 #Person2#에게 뉴질랜드에 있는 삼촌 빌과 그의 아내, 그리고 빌의 두 딸에 대해 묻습니다. #Person2#는 그들이 언제 우리를 방문할 것인지도 알려줍니다.', '#Person1#은 스튜어트 씨의 우승을 축하하고 그들이 경기를 봤다고 말합니다.', '#Person2#는 아이들과 아내를 위한 선물을 고르고 있습니다. #Person1#는 멋진 운동화와 DENY 브랜드의 향수를 추천합니다. #Person2#는 그것들을 사기로 합니다.', '홍은 #Person1#에게 현지 SIM 카드를 사서 영국에 전화를 걸 수 있다고 말한다.', '#Person2#는 브라운 씨에게 그녀의 월급과 그녀가 원하는 월급에 대해 이야기합니다. 브라운 씨는 #Person2#에게 그녀가 고용되면 처음에는 한 달에 2,500 위안을 받을 것이라고 말합니다.', '#Person1#과 #Person2#는 배리와 폴에 대해 이야기하고 자신들의 성격에 대해 이야기한다. 그들은 금요일에 파티에 갈 예정이다.', '#Person1#은 집을 사고 싶어하고 #Person2#에게 몇 가지 정보를 알려줍니다. #Person2#는 딱 맞는 집을 찾아보겠다고 합니다.', '그랜트 씨는 #Person2#에게 샘플을 여기에 남겨두고 다음 주에 전화하라고 말합니다.', '#Person2#는 #Person1#에게 PHS에서 Sons까지 가는 버스 노선을 알려줍니다.', '#Person1#은 씨로 불리며 워드 여사님을 집까지 태워주고 있습니다.', '#Person1#은 #Person2#의 상태를 진단하고 있습니다. #Person2#는 어깨가 아프고 다른 부위는 아프지 않습니다. #Person1#은 #Person2#가 병원에 하룻밤 머무르는 것이 좋다고 생각합니다.', '셸리는 고객 서비스 센터에 전화를 걸어 신용 카드를 잃어버렸다고 말합니다. 셸리는 카드를 잃은 시간과 장소를 알고 있습니다. 셸리는 도움을 청하고 셸리의 FRCM 일부 세부 사항을 받아서 도와줄 것입니다.', '#Person1#은 피곤하다. #Person2#는 #Person1#을 깨울 것이다.', '#Person1#은 #Person2#에게 중국 음식을 먹고 싶은지 묻고, 그 후 #Person2#는 여기서 먹고 싶어합니다. #Person1#은 #Person2#에게 음료를 선택하고 고추장을 먹고 싶은지 묻습니다. #Person2#는 고추장을 먹고 싶어합니다.', '#Person1#과 #Person2#는 식사를 하기 위해 줄을 서고 있습니다.', '루시는 노래 부는 것을 좋아하지 않지만 스탠리가 노래하는 것을 듣고 싶어합니다.', '#Person1#과 #Person2#는 영화관의 개념을 혁신하는 것이 필요하다고 생각합니다.', '#Person1#은 #Person2#에게 갈색 드레스를 추천하지만, #Person2#는 가벼운 드레스를 원합니다. #Person1#은 흰색 드레스를 추천합니다.', '조슈아는 아빠가 용돈을 잊어버렸다고 말하고, 그는 돈을 어떻게 사용할 것인지 아빠에게 말한다.', '#Person1#과 #Person2#는 마이크의 생일 파티에 초대받았다. 그들은 차를 타고 갈 것이다.', '#Person1#은 #Person2#에게 소포를 우등 우편으로 보내고 싶다고 말하고, 보험과 우표를 원한다고 말합니다.', '#Person1#과 #Person2#는 지진과 태풍에 대해 이야기하고 있습니다. 그들은 지리에 영향을 받지 않는 인간 간의 사랑에 대해 이야기하고 있습니다.', '#Person1#은 습하고 추운 날씨를 견디기 힘들어하지만, #Person2#는 그것에 익숙하다.', '#Person1#과 #Person2#는 올림픽 기념품 가게에 가서 가족들에게 선물을 사기로 결정했습니다. 그들은 올림픽 마스코트를 사고 싶어하며, 그것이 인기가 있다는 것을 알게 됩니다.', '#Person1#은 팬을 사고 싶어하고 #Person2#의 도움으로 가벼운 나무 핸들이 달린 알루미늄 팬을 구매합니다.', '#Person1#과 #Person2#는 일하러 돌아가고 있습니다.', '#Person1#은 베커 씨의 사무실을 보고 왜 워싱턴의 공무원들이 자신들의 일을 즐기는지 이해하게 되었습니다. 베커 씨는 그들이 보람 있고 안정적인 경력을 가지고 있다고 말합니다.', '#Person1#은 피트와 헨리를 소개하고 그들이 중국에서 생활하는 외국인이라는 것을 알게 된다. 그들은 저녁 식사를 하고 노래방에 가기로 계획하지만, 피트는 노래방을 싫어하고 맥주를 좋아한다. 그들은 베이징에 수천 개의 바가 있다는 것을 알게 된다.', '줄리는 아픈 몸으로 수업에 참석하지 않았다. 그녀는 식중독을 가지고 있다고 생각하며, 그녀가 몸이 좋지 않아진 이유는 그녀가 점심 식사 후에 프라이드 치킨을 먹었기 때문이라고 말한다. 그녀는 다른 사람들은 아무도 아프지 않았다고 말한다. 그녀는 다른 사람들이 그녀에게 노트를 가져다 줬고, 인터넷으로', '#Person1#은 오늘 저녁에 친구들이 오는 것을 준비하고 있다. 마이크는 도움을 제안하고 커피, 물, 과일 주스, 콜라, 설탕, 사과를 사러 갈 것이다.', '#Person1#과 #Person2#는 베를린에서 만났다. #Person2#는 런던에서 베를린으로 버스를 타는 여행이 불편했다고 말하고, 다음에는 비행기를 탈 것이라고 말한다.', '#Person1#은 #Person2#에게 직업 면접을 하고 있습니다. #Person2#는 이 종류의 일을 해본 적이 없지만 잘할 수 있다고 생각합니다. #Person2#는 여행을 좋아하고 사람들을 만나는 것을 좋아합니다. #Person2#는 외국어를 할 줄 알고', '지미는 어제 저녁에 제니와 빌이 초대해서 소풍에 갔고 에이미는 그녀의 책을 돌려주기 위해 지미에게 전화했다.', '피터는 정원에 물을 줘야 하지만 #Person1#은 차를 마시고 싶어합니다. 그들은 비가 오기 때문에 차를 마시고 정원에 물을 줄 필요가 없다는 것을 알게 됩니다.', '#Person1#은 켄이 돌아오지 않아도 비상 회의를 소집하라고 #Person2#에게 지시합니다.', '#Person2#는 편지를 보낼 때 필요한 우표를 #Person1#에게 구입합니다.', '스미스 씨는 심한 감염을 가지고 있습니다. #Person1#은 그에게 항생제와 가려움증과 화상을 완화시키는 크림을 처방하고 약국에서 할인을 받는 방법을 알려�', '#Person2#는 중국의 예술과 공예품을 추천해달라고 #Person1#에게 요청합니다. #Person1#는 종이절편, 자수, 바틱을 추천하고 #Person2#는 자수품을 보고 싶어합니다.', '#Person1#은 #Person2#에게 에펠탑에 대해 설명합니다.', '#Person1#은 브라이언에게 영어, 미국 체류, 그리고 캘리포니아와 라스베가스에 대한 여행 경험에 대해 묻습니다.', '#Person2#는 아직 돌아오지 않은 남자친구를 걱정하고 있습니다. #Person1#는 #Person2#에게 그를 걱정하지 말라고 말합니다.', '#Person1#은 #Person2#가 하는 일에 문제가 있다고 생각하지만, #Person2#는 그렇지 않다고 생각한다.', '#Person1#과 #Person2#는 존이 그녀에게 반한 것이라고 생각한다.', '#Person1#과 #Person2#는 런던의 역사적 인물들과 유명한 건물들에 대해 이야기합니다. 그들은 런던 타워, 웨스트민스터 대성당, 넬슨 기념비, 보아디케아의 동상, 유명한 성과 감옥, 그리고 마담 투소의 밀랍 인형 박물관을 언급합니다.', '다니엘은 이번 학기에 학교에서 몇 가지 새로운 과목을 추가했다고 #Person2#에게 말합니다. 다니엘은 과학을 가장 좋아하며, 그 이유는 그 과목을 통해 우리 주변의 세계에 대해 더욱 명확하게 알 수 있기 때문입니다.', '#Person1#은 베이비 샤워에 참석하고 있습니다. #Person2#는 #Person1#에게 베티와 칼라가 준 선물을 보여줍니다. #Person1#은 방금 양수가 터진 것 같아 병원에 가야 합니다.', '#Person1#은 중국에 관광하고 싶어하지만 #Person2#는 지금은 안돼.', '팀과 카렌이 서로 인사를 나눕니다.', '#Person2#는 마이클의 새로운 오토바이를 시도해보고 좋아했지만, 자전거를 사고 싶어한다.', '#Person2#는 중국어, 영어, 프랑스어를 할 수 있습니다. #Person2#는 영어를 충분히 잘해서 영어권 국가 사람들과 의사소통이 가능하다고 생각합니다.', '낸시가 나오미를 위해 전화를 받고 메시지를 받아들입니다.', '#Person1#은 뉴욕행 비행기가 취소되어 다른 항공사에 자리를 예약하려고 합니다. #Person2#은 #Person1#에게 50% 할인을 제공하고 줄을 서는 것을 제안합니다.', '#Person1#과 #Person2#는 버거퀸에 가서 점심을 먹기로 결정했다. 그들은 버거퀸의 치즈버거, 바닐라 밀크쉐이크, 프렌치 프라이, 그리고 튀김 음식에 대해 이야기한다.', '#Person1#은 #Person2#의 짐이 초과하고 있다고 말하고, #Person2#는 초과 수하물 요금을 내고 취약한 물품 표', '#Person1#은 목이 말라 죽겠다고 생각하고 소다를 마시고 싶어합니다. #Person2#는 소다가 몸에 좋지 않다고 말하고 물을 마시는 것을 제안합니다.', '왕 묘가 그린 씨의 사과 메세지를 전하고 그린 씨가 다시 약속을 잡을 것이라고 량 씨에게 전화를 걸었습니다.', '#Person1#은 유광 가죽 신발을 사고 싶어하고, #Person2#는 그것이 늘어납니다.', '벤자민은 프로젝트 보고서를 어떻게 써야 하는지 모르고 있다. #Person1#은 그에게 보고서의 항목, 형식, 그리고 마이크로소프트 워드 사용법에 대해 알려준다.', '#Person2#는 피자 주문을 하고 있습니다. #Person1#는 특별 메뉴를 추천하고 #Person2#는 해산물 피자를 주문합니다.', '#Person1#은 새우 칵테일, 양파 스테이크, 계란 수프, 미네랄 워터, 그리고 블랙 커피를 주문했습니다.', '#Person1#은 #Person2#에게 집의 주요 특징을 소개합니다.', '#Person2#는 스테레오에 대한 문제를 #Person1#에게 제기하고 그것이 어떻게 대처될 것인지 묻습니다. #Person1#는 다른 모델로 교환하는 것을 제안하지만, #Person2#는 만족하지 않습니다.', '#Person1#은 #Person2#에게 기숙사 보증금을 내는 데 한 시간이나 걸렸다고 말한다. #Person2#는 캠퍼스 밖에서 살 생각을 하고 있다. #Person1#은 #Person2#에게 돈을 많이 절약하기 위해 도서관에서 공부하는 것을 제안한다.', '#Person1#과 #Person2#는 중고 서점에서 책을 찾고 있습니다. #Person1#은 책에 서명이 있는 것을 발견하고 그 서명이 유명한 사람의 것일 수 있다고 생각합니다. #Person2#는 그것이 더 나은 구매라고 생각합니다.', '#Person2#는 베이징 레스토랑에 왔습니다. #Person1#은 #Person2#에게 중앙 테이블을 보여주고 주문을 받습니다. #Person2#는 친구를 기다리기 위해 음식을 20분 후에 준비해 달라고 요청합니다.', '#Person1#은 아들이 편지를 받게 하고 싶어합니다. #Person2#는 공인 우편을 제안하고 소포를 보낼 때 보험을 들어야 한다고 말합니다.', '톰이 샐리와 존에게 편지를 보냈습니다. 톰은 샐리와 존이 도시에 오면 픽업하러 갈 것이라고 말합니다.', '#Person1#은 컴퓨터로 과제를 하는 것이 어렵다고 생각합니다. #Person2#는 스스로 컴', '#Person1#과 #Person2#는 가을 날씨를 즐기고 있습니다. 그들은 일주일 동안 비가 없었다고 생각하고 소풍을 가기로 결정했습니다.', '#Person1#은 컴퓨터에 대한 일반적인 정보를 찾고 싶어합니다. #Person2#는 #Person1#에게 어떻게 찾는지 보여줍니다.', '#Person2#는 프렌치 가든 레스토랑에 왔습니다. #Person3#는 #Person2#에게 주스, 콜라, 그리고 참치 샌드위치와 야채 수프를 주문하도록 도와줍니다.', '#Person1#은 #Person2#에게 레모네이드, 바비큐 윙, 베이비 백 립을 주문하도록 도와줍니다.', '#Person1#은 #Person2#에게 커피와 물을 제공하고 디저트 주문을 나중에 할 수 있다고 말합니다.', '#Person1#과 #Person2#는 각자 다른 사람에게 데이트를 받는 것, 로또에 당첨되는 것, 그리고 엄마에게 결혼하는 것에 대해 어떻게 대답할 것인지에 대해 이야기한다.', '#Person1#은 잭에게 새로운 강아지의 사진을 보여줍니다.', '#Person1#은 엄마에게 제인 이모가 톰에게 새 자전거를 사줬다고 말한다. 그들은 톰이 예의 바르다고 생각하지만 #Person1#은 그렇지 않다고 생각한다. 그들은 버스를 기다리는 것이 지루하다고 생각하고 차를 사고 싶어한다.', '#Person2#는 최신 치마를 입어보고 싶지만 그것이 너무 비싸서 사지 않을 것입니다.', '#Person2#는 #Person1#에게 #Person2#의 도시가 200년 전에 작은 마을이었지만 석탄 발견 후 빠르게 성장했다고 말합니다. 그 마을의 몇몇 건물들은 여전하며, 그 중 많은 건물들은 여행자들을 위한 여관이었습니다.', '#Person1#과 #Person2#는 세계에 많은 환경 문제가 있다고 생각합니다. 그들은 세계 지도자들이 모여서 행동 계획에 동의하는 것이 환경 문제를 해결하는 데 도움이 될 것이라고 생각합니다. 그들은 대기 오염, 숲 파괴, 사막화, 그리고 사람들 사이의 갈등을 논의합니다. #Person2#는 환경 개선 프로젝트에 참여하고 싶어합니다.', '데니스는 채팅방에서 사람들과 많은 시간을 보내고 있지만 아직 누군가를 만나지 않았다. 데니스는 16살 소녀로 가장해서 사람들이 그와 이야기하려고 하게 했다. 데니스는 금요일 밤에 만나기로 한 새로운 온라인 친구를 사귀고 있다. 데니스는 그 사람이 그를 여자로 생각하고 있다고 생각하고 #Person2#', '네이선은 엄마에게 시카고로 연습하러 갈 준비가 되었다고 말한다. 엄마는 네이선이 큰 도시에서 어떻게 할 것인지 걱정하지만, 네이선은 그것에 대해 걱정하지 않고 사람들로부터 많이 배울 수 있다고 생각한다. 엄마는 네이선이 직장에서의 훈련을 받을 수 있을 것이라고 생각한다.', '#Person2#는 차를 빌리고 싶어합니다. #Person1#은 #Person2#에게 차의 색상을 선택하고 신분증을 보여달라고 요청합니다. #Person2#는 검정색과 빨간색을 선택하지 않습니다. #Person1#은 #Person2#에게 차 키를 주고 반납 시간을 알려줍니다.', '#Person2#는 #Person1#에게 뉴욕에서 볼 것과 뉴욕의 대학교에 대한 추천을 해줍니다. #Person2#는 도시의 지도를 가지고 있습니다.', '#Person1#은 #Person2#에게 필름을 현상해 달라고 요청합니다.', '#Person1#은 #Person2#에게 비행기 지연의 이유와 지연 정도에 대해 묻습니다. #Person2#는 지연 정도를 알 수 없지만, 날씨가 변하고 있다고 말합니다.', '#Person2#는 #Person1#에게 베이징 대학교로 가는 길을 알려줄 수 없다고 말합니다.', '#Person2#는 신문에 나쁜 소식이 많고 일기 예보는 맑고 따뜻하다고 #Person1#에게 말합니다. #Person2#는 은행 강도들을 찾지 못했고 스포츠 란을 읽어보라고 제안합니다.', '#Person1#은 컴퓨터 게임이 폭력적이기 때문에 싫어하지만, #Person2#는 그것이 괜찮다고 생각한다.', '#Person1#과 짐은 맥주를 마시는 것에 대해 이야기하고 있다. 그들은 운동장에 가서 노래를 부르고 친구들을 만나는 것을 제안하고 그들과 함께 춤을 추러 가는 것을 제안하기로 합의한다.', '#Person1#과 #Person2#는 닭발, 와인, 맥주를 주문하고 있습니다.', '#Person2#는 미국에서 온 관광객 그룹을 안내했습니다.', '#Person1#은 잭이 예약을 하는 것을 도와줍니다.', '질이 마크에게 전화를 걸어 그의 결석에 대해 묻고 수염의 아내가 딸을 낳았다는 소식을 알려줍니다. 그들은 내일 축하하기 위해 다시 만나기로 합니다.', '#Person1#은 #Person2#에게 놀자고 제안하지만, #Person2#는 남편이 좋아하지 않을 것이기 때문에 거절한다.', '#Person1#과 #Person2#는 볼티모어 야구 경기를 보고 있습니다. 그들은 경기를 보러 오는 것이 좋은 생각이라고 생각합니다.', '#Person1#은 #Person2#를 도와주고 친구 같게 대합니다.', '#Person2#는 #Person1#에게 #Person2#의 나라의 천연자원 수출, 수입, 그리고 발견된 귀중한 돌에 대해 이야기합니다. #Person2#는 장기 프로젝트에 돈을 투자하는 것이 돈을 잘 쓰는 것이라고 생각합니다.', '#Person1#과 #Person2#는 예술에 대한 각자의 관점을 공유합니다. 그들은 내일 국립 갤러리에서 열리는 전시회에 함께 가기로 합니다.', '#Person2#는 책을 반납하고 비디오를 대출하고 싶어합니다.', '#Person1#은 #Person2#에게 볼링 게임의 규칙을 소개합니다.', '#Person2#는 은행과 증권사 간의 송금 서비스에 대해 #Person1#에게 묻고, 고객이 주식 투자자인 경우 추가 혜택을 받을 수 있다는 것을 알게 됩니다.', '#Person1#은 체크아웃 후에 도시의 몇몇 장소를 더 가보고 싶어합니다. #Person2#는 #Person1#에게 짐을 보관할 수 있는 공간이 있다고 말하고 보증금을 지불하라고 요청합니다.', '#Person2#는 #Person1#에게 파티에 세 명이 참석할 것이라고 말합니다. #Person1#는 뷔페 가격과 음식 배치에 대해 #Person2#에게 알려줍니다.', '#Person2#는 해외에서 공부하기 위해 대출을 받고 싶어합니다. #Person1#는 #Person2#에게 대출자의 나이 제한, 대출자의 대출자, 그리고 부모님의 보증에 대해 알려줍니다.', '#Person2#는 #Person1#에게 영어 노래가 있다고 말하고 찾는 데 몇 분이 더 걸릴 것이라고', '#Person1#은 #Person2#에게 직무 면접을 합니다. #Person2#는 자신의 경험을 소개하고 이 직무에 관심을 가진 이유를 설명합니다.', '#Person1#과 잭은 면접 결과를 적극적으로 물어보는 것에 대해 논의하고 있습니다. 잭은 문의서를 작성하고 답변을 놓치지 않도록 주의를 기울이는 것을 제안합니다.', '#Person2#는 #Person1#에게 집을 보여주고 옥수수 이삭을 깎는 방법을 설명합니다.', '#Person1#은 뉴욕에서 하루를 보내고 있습니다. #Person2#는 #Person1#에게 보증금을 납부하고 수하물을 맡길 수 있다고 말합니다. #Person1#은 그것이 문제가 될 것이라고 생각합니다.', '#Person1#은 브랜든에게 신뢰할 수 없는 웹사이트에 대해 경고하고 브랜든의 컴퓨터를 꺼라고 요청한다. 브랜든은 이해하지 못하고 그 사이트가 무료라고 생각한다.', '#Person1#과 #Person2#는 교장이 새로운 실험실 건물을 지을 것이라고 생각하지만, 돈이 문제가 될 수 있다고 생각합니다.', '케이트는 카드로 소고기를 사는 것이 기쁘다고 생각하지만, 헨리는 그것이 조심해야 하는 것이라고 생각한다.', '#Person1#은 스미스씨에게 내일 방문할 마을을 선택하라고 요청합니다. 스미스씨는 산악 지역의 마을을 방문하는 것을 선호합니다.', '벳은 스트레스와 우울증을 다루기 위해 오이를 먹고 잠을 자는 것을 사용합니다. 그녀는 아기를 가지고 있기 때문에 자유를 잃었지만, 그녀는 아기를 사랑하고 그녀와 함께하는 가장 좋은 부분은 아기가 모든 단계를 거치면서 그녀를 사랑하는 사람이 있다는 것을 알고 있다는 것입니다. 벳은 변호사가 되고 싶고, 결혼하고 싶어합니다. 그녀는 가족의 전통을 유지하고 싶어합니다. 벳은 청소년들에게 천천히 즐기고 스스로 결정하라고 조언합니다.', '#Person2#는 9년 동안 우표 수집에 관심을 가지고 있습니다. #Person1#와 #Person2#는 우표 수집이 부자들이 모두 즐길 수 없는 큰 즐거움을 드린다고 생각합니다.', '톰은 친환경 제품을 판매하는 회사의 관리자로서 성공한 사업가가 되었습니다. 그는 웹 디자인 회사를 시작하고 돈을 벌기 시작했습니다. 그는 주식을 받는 모든 직원들과 함께 회사를 운영하고 있습니다. 톰은 자신이 낭비적인 일을 한 적이 있다고 생각하지만, 그것이 배우고 성장할 기회를 줍니다.', '#Person1#은 존 데이 형사 부장이 북런던의 경찰이 살인으로 다루고 있는 40대 남자의 죽음에 대해 묻고 있습니다. 존은 그 남자의 행동에 대해 알고 있는 것을 설명하고, 그 남자가 술집을 떠나고 지하도에서 발견되었다고 말합니다. 존은 그 남자가 지하도 입구 근처에 두 여자와 취한 남자가 있었을 수 있다고 생각하며, 그들이 그를 보았을 수 있다고 생각합니다.', '셰리는 밥에게 내년 여름에 퀘벡을 방문할 예정이라고 말한다. 밥은 셰리에게 몬트리올과 퀘벡 시에 대한 정보를 알려준다. 셰리는 몬트리올에 머무를 예정이고 퀘벡 시를 방문할 예정이다.', '톰은 제인에게 수영하러 가자고 제안하지만 제인은 논문 마감이 있어서 거절한다. 그들은 그릴에서 저녁 식사를 하고 그릴에서 함께 시간을 보내기로 합의한다.', '#Person1#은 아직도 등에 통증이 있다. #Person2#는 #Person1#이 약을 복용하', '#Person1#은 휴대폰이 먹통이 되어 돈을 빌리고 싶어한다. 프레드는 그것이 안타깝다고 생각하고 돈을 빌려준다.', '#Person1#은 글씨를 개선하고 싶지만 아무런 변화가 없어서 불평합니다. #Person2#은 #Person1#에게 인내심을 가지고 계속 연습하라고 격려합니다.', '#Person1#은 #Person2#가 속눈썹을 집는 것이 원시적인 고문 방법 같다고 생각하지만, #Person2#는 그것이 그저 속눈썹을 위로 뻗', '#Person2#는 주말 운전 수업에 관한 몇 가지 질문을 #Person1#에게 합니다.', '티나는 8년 동안 피아노를 배웠고 아직도 그 선생님에게 배우고 있습니다. #Person1#은 그 선생님에게 배우고 싶어하고 티나는 그녀를 소개해 줄 것입니다.', '#Person1#은 #Person2#에게 #Person2#의 장점, 약점, 그리고 5년 후의 예상된 미래에 대해 묻습니다. #Person1#은 #Person2#가 우리가 찾고 있는 사람일지도 모른다고 생각합니다.', '스테파니는 머리가 아프고 피곤해 보인다. 조지는 그녀에게 젠킨스 선생님에게 보고서 제출 시한을 연장해달라고 부탁하고 도움을 제안한다.', '#Person1#은 데이비드에게 호수에서 스케이트를 타자고 제안하지만 데이비드는 뉴욕에 있고 싶어한다. #Person1#은 데이비드의 아빠가 조용한 크리스마스를 원한다고 말하고 데이비드는 그것이 지루할 것이라고 생각한다.', '밥과 #Person1#은 지난 주말에 무엇을 했는지 이야기한다. 밥은 댄스 파티에 갔고, #Person1#은 TV를 보고 쇼핑을 갔다. 밥은', '#Person1#은 일자리를 찾고 있지만 아버지 농장에서 일하는 것을 싫어하기 때문에 #Person2#에게 50달러를 빌려달라고 요청한다. #Person2#는 #Person1#에게 행운을 주기로 한다.', '#Person1#은 #Person2#에게 식당에서 재킷과 넥타이를 빌릴 수 없다고 말합니다. #Person2#는 회의 시간을 미루기 위해 회의에서 떠나고 재킷과 넥타이를 가져오기 위해 돌아갈 것입니다.', '#Person2#는 #Person1#에게 어린 아이들이 휴가 캠프에서 어떻게 지냈는지, 그들이 어떤 활동을 했는지, 그리고 그들이 어떻게 느꼈는지 말해줍니다.', '#Person2#는 직장을 그만두고 컴퓨터 프로그래밍 쪽으로 진출하려고 생각하고 있습니다. #Person1#는 #Person2#를 도와줄 수 있다고 말합니다.', '칼리나가 클라크 교수님에게 전화를 걸어 차 사고로 인해 학교를 쉬게 될 것이라고 알립니다.', '#Person2#는 집주인과 수리 비용에 대해 합의를 이루지 못하고 있습니다. #Person2#는 집주인이 수리 비용을 지불하지 않는 것이 공정하지 않다고 생각합니다.', '#Person2#는 터너 인테리어에서 왔습니다. #Person1#는 #Person2#에게 사유리 베드에서 온 수출용 L / C를 서명하라고 말합니다.', '미르달은 찰리에게 지갑을 잃어버렸다고 말한다. 찰리는 그들이 핫도그 판매대로 가서 찾아보자고 제안한다.', '#Person1#은 설거지를 하고 있고 #Person2#에게 번갈아서 하는 것을 제안한다.', '#Person1#과 #Person2#는 이 관계가 어디로 가고 있는지 묻고 있습니다. 그들은 서로 사랑하고 있다는 것을 발견합니다.', '#Person1#과 #Person2#는 정부가 사회 문제를 효율적으로 다루는 것이 어렵다고 생', '#Person1#은 화려한 복장 파티에 참석하기 위한 복장을 구하기 위해 #Person2#에게 쇼핑 동반자로 도움을 청하고 있습니다.', '#Person2#는 #Person1#에게 베이징의 야간 생활을 추천하고 춤추러 가는 것을 제안합니다. #Person1#는 빠른 음악에 맞춰 춤추는 것을 좋아하며, 디스코 댄스가 가장 좋아하는 춤이라고 말합니다.', '#Person1#은 농장을 가지고 싶어하고, #Person2#는 그것이 힘든 일이라고 생각하지만 휴가를 보낼 것이라고 생각한다.', '#Person1#은 맨에게 하이네켄, 버드와이저, 나초, 그리고 모짜렐라 스틱을 주문했습니다.', '메리는 어제 밤에 앤과 큰 싸웠다. 앤은 남자친구가 계획을 세우기 때문에 여행을 취소했다. 메리는 앤이 우리의 우정을 전혀 신경 쓰지 않는다고 생각하지만, #Person1#은 그녀도 좀 이해해주는 게 좋다고 생각한다.', '#Person2#는 #Person1#에게 담배와 기념품을 구입하는 방법을 알려줍니다.', '톰과 캐서린은 패스트 푸드 문화에 대해 이야기하고 있습니다. 캐서린은 패스트 푸드 문화가 건강에 좋지 않다고 생각하고, 톰은 패스트 푸드 레스토랑에서 건강한 메뉴 옵션이 있다고 생각합니다. 그들은 미국인들이 패스트 푸드를 최대한 활용하는 방법을 찾아야 한다고 생각합니다.', '#Person1#은 #Person2#에게 버스 요금을 받고 버스 노선을 알려줍니다. #Person2#는 버스가 올바른 노선을 따르고 있다고 생각하고 탑승합니다.', '#Person1#과 #Person2#는 9-11 테러 공격 당시에 어디에 있었는지 이야기합니다. #Person1#의 삼촌은 테러 공격 때 사망했습니다. #Person1#과 #Person2#는 테러 행위가 고의적이고 치명적이며, 모든 삶의 영역에 영향을 미칠 수 있다고 생각합니다.', '칼과 척 존스는 이웃이 되었습니다. 칼은 시카고 출신이지만 더 평화로운 공동체에서 살기 위해 미네소타로 이사 왔습니다.', '#Person2#는 #Person1#에게 삶은 계란, 진한 토스트, 그리고 나중에 오렌지 주스를 주문했습니다.', '#Person1#은 스티븐에게 자기 때 지하실 문을 닫아달라고 요청하고 잘 자고 싶어합니다.', '#Person1#은 제인과 다음 주 월요일 오후 세 시에 만나기로 합의했다.', '#Person2#는 5주년을 맞이하는 여자친구에게 선물을 고르고 싶어합니다. #Person1#는 몇 가지 제안을 하고 #Person2#는 결혼을 제안하기로 결정합니다.', '#Person1#은 새 차를 사고 싶어합니다. #Person2#는 포드 포커스를 추천하고 그것의 특징과 가격을 소개합니다. #Person1#은 그것을 좋아하고 시승해보기로 합니다.', '#Person1#은 발람에게 컴퓨터 엔지니어 직위를 제안하고 월급을 논의합니다. 발람은 가족을 부양하기 위해 월 4,000 위안을 받고 싶어합니다. #Person1#은 그것이 괜찮다고 합니다.', '#Person1#은 #Person2#에게 혜택 등에 대해 설명하고 그들의 문제를 해결하기 위해 가입하는 것을 제안합니다.', '#Person1#은 배가 고프다. #Person2#는 #Person1#에게 샌드위치를 만들어 먹으라고 제안한다.', '#Person2#는 #Person1#의 백혈구 수치를 확인하기 위해 피를 뽑고 있습니다.', '스티븐은 전기가 나간 후 셀러 씨에게 전화를 걸어 어떻게 해야 하는지 물어봅니다. 셀러 씨는 스티븐에게 퓨즈를 교체하라고 말합니다.', '파울라는 코너스 씨가 전체 임대료를 지불하지 않았다고 위협하고 있다고 말합니다. #Person2#는 파울라와 함께 코너스 씨와 이야기하고 문제를 해결하기로 합니다.', '#Person1#과 #Person2#는 사무실의 많은 문제들에 대해 불평하고 있습니다. 그들은 수리공에게 전기 배선, 화장실 변기, 그리고 주차장을 고치도록 요청할 것입니다.', '#Person1#과 #Person2#는 일자리를 찾고 있다. 그들은 전기기사 수습생 프로그램을 다시 한 번 확인할 것이다.', '#Person2#는 #Person1#에게 #Person2#와 사장님의 업무 관계, 그리고 사장님의 장점에 대해 이야기합니다.', '탕 씨는 자격증을 제출하고 외국어 능력을 소개합니다.', '#Person2#는 시계를 보고 싶어합니다. #Person1#는 순금 시계를 추천하고 그 가격을 알려줍니다. #Person2#는 그 가격이 비싸다고 생각하지만 결국 그것을 사기로 합니다.', '톰은 딸이 고열이 나서 병원에 갈 예정입니다. 사라는 톰의 아들을 돌봅니다.', '에이미는 #Person1#에게 그녀의 첫 직장이 어디였는지, 그녀가 무엇을 했는지, 그녀가 그 일을 즐겼는지, 그녀가 그곳에서 얼마나 오래 있었는지 말해줍니다.', '#Person1#은 앤드류에게 앤드류가 크리스마스 때 많이 살이 찐 것 같다고 말한다. 앤드류는 와푸 다이어트를 하고 있다고 말하지만, #Person1#은 그것이 사기라고 생각한다. #Person1#은 앤드류에게 올바른 식습관을 가지고 패스트푸드를 끊고 설탕을 줄이는 것을 제안한다.', '그렉 손더스는 메리에게 전화를 걸어 그렉의 성적 평균과 그렉의 스포츠 관심에 대해 묻습니다. 그렉은 메리에게 결정을 곧 알려줄 것이라고 말합니다.', '#Person1#은 택시를 타고 기차역으로 가고 있습니다. #Person2#는 출퇴근 시간이라 천천히 조심해서 운전하겠다고 말합니다.', '#Person1#은 브라이언에게 영어, 미국 체류, 그리고 캘리포니아와 라스베가스에 대한 여행 경험에 대해 묻습니다.', '#Person2#는 새로운 건강보험에 가입하기 위해 연간 건강검진을 받으러 왔습니다. #Person1#는 #Person2#의 폐, 심장, 혈액 수치, 눈, 귀, 코를 검사하고 알레르기 검사를 할 것입니다.', '#Person1#과 #Person2#는 복권에 당첨되는 것이 흥미롭다고 생각하지만, 그들은 그런 일이 일어날 것이라고 생각하지 않습니다. 그들은 그들의 현재 삶에 대해 이야기하고 한 잔 더 마시기로 합니다.', '#Person1#은 결혼하기 위해 준비가 되지 않았다고 생각하고 두려워하고 있다. #Person2#는 #Person1#에게 에이미를 떠나지 않고 결혼하는 것을 제안한다. #Person1#은 동의하고 준비를 하기로 한다.', '#Person1#은 #Person2#에게 명함을 인쇄하도록 요청하고, 그들은 명함의 양, 사용하던 명함과 같은 것을 원하는지, 그리고 추가 비용에 대해 논의합니다.', '브라이언은 여행 준비를 마치고 #Person1#에게 회의 시간과 프로그램에 대해 알려줍니다.', '#Person1#은 폴에게 추수감사절 저녁 파티에 초대하고 폴은 파이를 가져갈 것이다. #Person1#은 폴에게 빈손으로 오지 않도록 하고 폴은 좋은 와인 한 병을 가져갈 것이다.', '존은 수잔에게 그의 사촌을 돌봐달라고 요청하고, 그녀는 그녀가 좋아하는 것에 대해 묻습니다. 수잔은 눈이 오지 않는 한 그녀를 돌봐줄 것이라고 합니다.', '#Person1#과 벤은 저녁 수업 정보를 확인하고 있습니다. 그들은 인도 요리 과정을 좋아하고 그들만의 인도 음식 파티를 열기로 결정합니다.', '#Person1#과 #Person2#는 어떤 고기를 먹을지에 대해 논의하고 있습니다. 그들은 결국 내일 저녁에 캐롯츠에 가기로 결정합니다.', '진은 운전 면허 시험을 볼 예정입니다. 그는 운전을 하기 위해 필요하기 때문이며, 그는 안전 기능이 있는 차를 사고 싶어합니다.', '#Person1#은 #Person2#의 펜을 사고 카드로 결제합니다.', '#Person2#는 #Person1#에게 기금 모금 행사가 잘 진행되었다고 말합니다. 그들은 미국 암 협회를 위한 마라톤을 후원하고 돈을 모금하기 위해 파트너십을 맺었습니다. 이 행사는 회사의 이미지를 향상시키고 기금 모금을 도움으로써 좋은 성과를 거두었습니다.', '#Person2#는 #Person1#에게 피크 트램으로 가는 방법을 알려줍니다. #Person1#는 그 방법을 적기 위해 연필을 원합니다.', '#Person1#은 #Person2#에게 샌들우드 부채를 보여줍니다. #Person2#는 작은 것 두 개와 큰 것 하나를 구매합니다.', '#Person2#는 #Person1#에게 회사의 관점에 영향을 미치는 요인에 대해 이야기합니다.', '#Person1#과 #Person2#는 주제를 다루기 위해 모두 다시 모이고 작업에 얼마나 많은 시간을 할애해야 할지에 대해 논의합니다.', '#Person1#은 #Person2#에게 자연 풍경을 보는 하루짜리 여행을 추천합니다.', '#Person2#는 #Person1#에게 소고기 버거, 프렌치 프라이, 그리고 바나나 맛 밀크 쉐이크를 주문했습니다.', '#Person1#과 #Person2#는 등 축제에 참석하고 있습니다. 그들은 퍼즐을 풀고 있는 사람들, 거대한 등, 그리고 중국 시가 적힌 등을 보고 있습니다.', '#Person1#은 티나에게 ABC 컴퍼니와의 첫 두 라운드 면접에 성공적으로 통과했다고 말한다. 그들은 오늘 저녁에 축하 파티를 할 예정이다.', '팀과 카렌이 만나서 얘기했다.', '#Person1#은 #Person2#에게 부서 회의에 필요한 물건들을 어디에서 찾을 수 있는지 알려줍니다. #Person2#는 #Person1#에게 이 사무실에서 일하는 것을 즐긴다고 말하고 부서 회의에서 논의하는 주요 주제에 대해 이야기합니다.', '#Person1#은 버튼과 다른 스위치를 어떻게 사용하는지 #Person2#에게 물어봅니다.', '#Person2#는 #Person1#에게 베스트셀러 진열대의 위치를 알려줍니다. #Person2#는 #Person1#에게 일본 소설을 추천합니다.', '#Person1#은 #Person2#에게 친구에게 읽는 법을 가르치는 것에 대해 묻습니다. #Person2#는 동의합니다.', '#Person1#은 티켓을 예약하고 #Person2#에게 티켓 가격과 결제 방법을 물어봅니다.', '#Person1#과 #Person2#는 오늘 저녁 식사를 같이 만들기로 합의했습니다. #Person1#은 건강한 음식을 만드는 법을 가르칠 수 있습니다. 그들은 매운 치킨 커리를 만들기로 결정했습니다.', '#Person2#는 #Person1#에게 두 대의 전화기를 어떻게 사용하는지 알려줍니다.', '톰은 중고 물품을 사는 것이 좋다고 생각하지만, 그것은 상황에 따라 다르다고 생각한다.', '#Person1#은 모건에게 중국 사람들이 남은 음식을 집으로 가져가는지 묻고, 그들은 그것이 낭비라고 생각하지만 그것이 중국의 전통이라고 말한다. 그들은 족발을 먹는 것에 대해 이야기하고, 모건은 그것을 먹는 것을 좋아하지만 #Person1#은 그것을 먹는 것이 괜찮다고 생각한다.', '해리는 중국의 거리 시장에서 바가지를 썼다. #Person2#는 흥정을 통해 가격을 낮추는 것이 자유 거래의 규칙이라고 생각하며, 해리는 그것이 불편하다고 생각한다. #Person2#는 해리에게 슈퍼마켓에서 가격표를 확인하고 흥정하는 것을 추천한다.', '#Person1#은 #Person2#에게 영어 교육과 다른 언어에 대해 묻습니다.', '#Person2#는 새로운 계좌를 개설하고 싶어합니다. #Person1#는 #Person2#에게 신청서와 몇 가지 서류를 작성하고 여권을 제출하라고 말합니다. #Person1#는 #Person2#에게 두 계좌 모두 ATM에서 사용할 수 있는 카드가 포함되어 있다고 말합니다. #Person2#는 초과 인출에 대한 벌금에 대해 묻고, #Person1#는 이에 대한 정보를 알려줍니다.', '#Person2#는 #Person1#에게 특별 할인 쿠폰을 어떻게 받을 수 있는지 알려줍니다. #Person1#는 설탕 9봉지를 사고 쿠폰 3장을 받기로 합니다.', '로빈슨 부인이 스티브에게 쟈니를 돌봐줘서 고마워한다.', '스미스는 기차 표를 잃어버렸다. #Person1#은 그에게 표를 다시 구매하라고 제안하지만, 스미스는 지갑이 훔쳐져 있다. #Person1#은 그에게 4마오를 넘어주고 편안한 좌석을 사는 데 도움을 준다.', '앤은 미국 여행 중에 항공 웰빙 프로그램을 사용하여 시차 적응을 잘 했다. #Person1#은 앤의 조언에 따라 그 프로그램을 사용할 것이다.', '메리는 맥도날드에서 일하고 있지만 다른 일을 찾고 싶어한다. 톰은 그의 아버지의 회사가 여름 동안 일할 사람들을 필요로 한다고 메리에게 알렸다.', '해리는 차에 치일 뻔 했지만 운전자는 사라져버렸다. #Person1#은 그런 운전자들이 경찰에게 처벌을 받아야 한다고 생각하고 해리는 동의한다.', '#Person1#은 자신만의 자전거 상점을 운영하고 싶어하는 스티븐 케인씨를 인터뷰합니다. 케인씨는 자전거를 좋아하고 사업 대출을 받아 자신만의 사업을 시작했습니다. 케인씨는 함께 일할 직원을 고용하고 있습니다.', '#Person1#과 #Person2#는 자신들이 중년이라고 생각하지만, 그들은 실제로 늙었고 늙어가고 있습니다.', '#Person1#은 #Person2#와 그의 친구들이 완벽한 식사를 마무리하는 데 도움을 줍니다. #Person2#는 사과 크리스프, 초콜릿 무스 케이크, 차 네 잔을 주문합니다.', '#Person1#과 #Person2#는 방에 있는 침대, 스테레오, 책상을 어떻게 배분할지 계획하고 있습니다. 그들은 동전을 던져서 결정하고, 그 후에 계획을 세우고 짐을 풀기로 합니다.', '머레이 씨는 도서관 카드를 발급받고 싶어합니다. #Person2#는 머레이 씨에게 신청서를 작성하고 도서관의 규정과 벌금에 대해 알고 있는지 묻습니다.', '#Person2#는 #Person1#에게 #Person2#의 근무일, 초과근무 수당, 휴식 시간, 그리고 일하는 장소에 대해 이야기합니다.', '닉은 옷을 빨래해 본 적이 없고 옷을 빨래하는 방법을 모른다. 앨리스는 닉에게 기계를 사용하는 방법을 가르친다.', '#Person1#과 #Person2#는 오늘 밤에 전화할 예정이다.', '#Person1#은 케이티에게 평가서를 봐달라고 요청하고 케이티에게 늦지 않고 고객이 없을 때 일하라고 요청한다.', '#Person1#과 #Person2#는 다음 주에 할아버지의 생일 파티를 위해 준비하고 있습니다. 그들은 음식, 선물, 그리고 파티 날짜에 대해 논의하고 있습니다.', '지안 루카 도나텔리와 지나는 회의에서 자신들을 소개하고 서비스 제공업체에 대한 기사를 조사하기 위해 이 회의에 참석했다고 말합니다.', '캐시와 #Person2#는 북캐롤라이나 산맥에서 새들의 울음소리에 대해 이야기하고 있다. 캐시는 이것이 끔찍하다고 생각하고, #Person2#는 이것이 동부에만 있을 것이라고 생각한다.', '#Person1#은 대니스에게 칠면조 샌드위치, 채소가 들어간 소고기 스프, 그리고 다이어트 콜라를 주문하는 데 도움을 줍니다.', '제임스는 기차를 타기 위해 짐을 싸고 있지만, 그는 짐을 싸는 것보다 사진을 찍는 것을 더 좋아한다. #Person1#은 제임스에게 쿠키를 가져가 할아버지와 할머니에게 선물로 주도록 요청한다. 제임스는 데이비드가 걸어서 여기 오는 것을 기다리고 있다.', '#Person1#과 테드는 올해 휴가 계획에 대해 이야기하고 있습니다.', '#Person1#은 헬렌 아주머니가 항상 데려가는 영화관에 가자고 제안하고, #Person2#는 그것이 좋다고 생각한다.', '#Person2#의 집이 털렸고 모든 가구가 훔쳐갔습니다. #Person1#은 #Person2#에게 경찰에', '잭은 찰리에게 새 비디오 게임을 하러 오라고 초대하고 그것이 어떤 게임이고 어떻게 하는지 설명한다.', '#Person2#는 처음으로 레코드 플레이어를 구입하고 그 후로 컨트리 음악 레코드를 더 많이 사기 시작했습니다. #Person2#는 라디오 프로그램을 제안하고 그 노래들의 배경을 설명하는 기사를 쓰라는 요청을 받았습니다.', '#Person1#은 옷을 빨고 싶지만 옷을 빨아본 적이 없습니다. 앨리스는 #Person1#에게 비누를 사고 옷을 빨는 방법을 알려줍니다. 그들은 옷을 빨는 방식에 대해 이야기합니다.', '스티브는 집을 찾고 있고 매튜에게 도움을 청한다. 매튜는 다우 부인의 아파트를 추천하고 스티브에게 다우 부인에게 언제 아파트를 보여줄 수 있는지 물어보고 알려줄 것이다.', '프랭크가 벳시에게 승진 후 열리는 파티에 초대하고 그 파티가 큰 일이라고 말한다. 벳시는 그것이 재미 있을 것이라고 생각하고 가고 싶어한다.']\n"
     ]
    }
   ],
   "source": [
    "print(fname_list)\n",
    "print(summary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>#Person1#은 더슨 씨에게 내부 메모를 받아쓰도록 요청하고, 모든 통신이 이메...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>#Person2#는 교통 체증에 걸렸다. #Person1#는 #Person2#에게 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>#Person1#은 케이트에게 마샤와 히어로가 이혼하려고 하며 이혼이 새해 초에 확...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>#Person1#은 브라이언의 생일 파티에 참석하고 춤을 추고 술을 마시며 즐겼다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>#Person1#과 #Person2#는 올림픽 스타디움을 방문하고 있습니다. #Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>test_495</td>\n",
       "      <td>잭은 찰리에게 새 비디오 게임을 하러 오라고 초대하고 그것이 어떤 게임이고 어떻게 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>test_496</td>\n",
       "      <td>#Person2#는 처음으로 레코드 플레이어를 구입하고 그 후로 컨트리 음악 레코드...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>test_497</td>\n",
       "      <td>#Person1#은 옷을 빨고 싶지만 옷을 빨아본 적이 없습니다. 앨리스는 #Per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>test_498</td>\n",
       "      <td>스티브는 집을 찾고 있고 매튜에게 도움을 청한다. 매튜는 다우 부인의 아파트를 추천...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>test_499</td>\n",
       "      <td>프랭크가 벳시에게 승진 후 열리는 파티에 초대하고 그 파티가 큰 일이라고 말한다. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fname                                            summary\n",
       "0      test_0  #Person1#은 더슨 씨에게 내부 메모를 받아쓰도록 요청하고, 모든 통신이 이메...\n",
       "1      test_1  #Person2#는 교통 체증에 걸렸다. #Person1#는 #Person2#에게 ...\n",
       "2      test_2  #Person1#은 케이트에게 마샤와 히어로가 이혼하려고 하며 이혼이 새해 초에 확...\n",
       "3      test_3     #Person1#은 브라이언의 생일 파티에 참석하고 춤을 추고 술을 마시며 즐겼다.\n",
       "4      test_4  #Person1#과 #Person2#는 올림픽 스타디움을 방문하고 있습니다. #Pe...\n",
       "..        ...                                                ...\n",
       "494  test_495  잭은 찰리에게 새 비디오 게임을 하러 오라고 초대하고 그것이 어떤 게임이고 어떻게 ...\n",
       "495  test_496  #Person2#는 처음으로 레코드 플레이어를 구입하고 그 후로 컨트리 음악 레코드...\n",
       "496  test_497  #Person1#은 옷을 빨고 싶지만 옷을 빨아본 적이 없습니다. 앨리스는 #Per...\n",
       "497  test_498  스티브는 집을 찾고 있고 매튜에게 도움을 청한다. 매튜는 다우 부인의 아파트를 추천...\n",
       "498  test_499  프랭크가 벳시에게 승진 후 열리는 파티에 초대하고 그 파티가 큰 일이라고 말한다. ...\n",
       "\n",
       "[499 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'fname': fname_list,\n",
    "    'summary': summary_list,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../prediction/output.csv', encoding='utf-8-sig', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
