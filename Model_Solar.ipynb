{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/meta-llama/llama-recipes/blob/v0.0.3/recipes/quickstart/finetuning/quickstart_peft_finetuning.ipynb 를 복사해서 수정함.\n",
    "\n",
    "pip install llama-recipes 실행 시, 0.0.3 버전이 설치 되기 때문에,\n",
    "quickstart_peft_finetuning.ipynb 파일도 0.0.3 버전을 사용해야 문제 없이 실행이 됨!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "This software may be used and distributed according to the terms of the Llama 2 Community License Agreement.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/meta-llama/llama-recipes/blob/main/recipes/finetuning/quickstart_peft_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEFT Finetuning Quick Start Notebook\n",
    "\n",
    "This notebook shows how to train a Meta Llama 3 model on a single GPU (e.g. A10 with 24GB) using int8 quantization and LoRA finetuning.\n",
    "\n",
    "**_Note:_** To run this notebook on a machine with less than 24GB VRAM (e.g. T4 with 16GB) the context length of the training dataset needs to be adapted.\n",
    "We do this based on the available VRAM during execution.\n",
    "If you run into OOM issues try to further lower the value of train_config.context_length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Install pre-requirements and convert checkpoint\n",
    "\n",
    "We need to have llama-recipes and its dependencies installed for this notebook. Additionally, we need to log in with the huggingface_cli and make sure that the account is able to to access the Meta Llama weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if running from Colab T4\n",
    "# ! pip install llama-recipes ipywidgets\n",
    "\n",
    "# import huggingface_hub\n",
    "# huggingface_hub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"model_name\": \"upstage/SOLAR-10.7B-v1.0\", # 불러올 모델의 이름을 사용자 환경에 맞게 지정할 수 있습니다.\n",
    "        \"output_dir\": \"./solar_finetuning\" # 모델의 최종 출력 값을 저장할 경로를 설정합니다.\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"max_new_tokens\": 250,\n",
    "        \"min_new_tokens\": 30,\n",
    "        # 특정 단어들이 분해되어 tokenization이 수행되지 않도록 special_tokens을 지정해줍니다.\n",
    "        #\"special_tokens\": ['#Person#', '#Person1#', '#Person2#', '#Person3#', '#Person4#', '#Person5#', '#Person6#', '#Person7#', '#Address#', '#SSN#', '#PassportNumber#', '#CardNumber#', '#CarNumber#', '#Email#', '#DateOfBirth#', '#PhoneNumber#']\n",
    "    },\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the model\n",
    "\n",
    "Setup training configuration and load the model and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523953080576421f9f760df27374f4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from llama_recipes.configs import train_config as TRAIN_CONFIG\n",
    "\n",
    "train_config = TRAIN_CONFIG()\n",
    "train_config.model_name = config_data[\"general\"][\"model_name\"]\n",
    "train_config.num_epochs = 1\n",
    "train_config.run_validation = False\n",
    "train_config.gradient_accumulation_steps = 4\n",
    "train_config.batch_size_training = 1\n",
    "train_config.lr = 3e-4\n",
    "train_config.use_fast_kernels = True\n",
    "train_config.use_fp16 = True\n",
    "train_config.context_length = 1024 if torch.cuda.get_device_properties(0).total_memory < 16e9 else 2048 # T4 16GB or A10 24GB\n",
    "train_config.batching_strategy = \"packing\"\n",
    "train_config.output_dir = config_data[\"general\"][\"output_dir\"]\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,  # Add\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "            train_config.model_name,\n",
    "            device_map=\"auto\",\n",
    "            quantization_config=config,\n",
    "            use_cache=False,\n",
    "            attn_implementation=\"sdpa\" if train_config.use_fast_kernels else None,\n",
    "            torch_dtype=torch.bfloat16,     # float16 ==> bfloat16\n",
    "        )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(train_config.model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Check base model\n",
    "\n",
    "Run the base model on an example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize this dialog:\n",
      "#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
      "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
      "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
      "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
      "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
      "#Person2#: 알겠습니다.\n",
      "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
      "#Person2#: 네.\n",
      "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
      "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
      "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
      "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
      "---\n",
      "Summary:\n",
      "Person1 is a doctor and Person2 is a patient. Person2 is having a health checkup. Person2 smokes and the doctor advises him to quit smoking.\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"\n",
    "Summarize this dialog:\n",
    "#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
    "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
    "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
    "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
    "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
    "#Person2#: 알겠습니다.\n",
    "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
    "#Person2#: 네.\n",
    "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
    "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
    "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
    "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
    "---\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    generated = model.generate(**model_input, \n",
    "                               min_new_tokens = config_data['tokenizer']['min_new_tokens'], \n",
    "                               max_new_tokens = config_data['tokenizer']['max_new_tokens'])\n",
    "    \n",
    "    print(tokenizer.decode(generated[0], skip_special_tokens=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the base model only repeats the conversation.\n",
    "\n",
    "### Step 3: Load the preprocessed dataset\n",
    "\n",
    "We load and preprocess the samsum dataset which consists of curated pairs of dialogs and their summarization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "class DatasetForLlamaTrain(Dataset):\n",
    "    def __init__(self, train_csv_fullpath):\n",
    "        df = pd.read_csv(train_csv_fullpath)\n",
    "        \n",
    "        prompt = (\n",
    "            f\"Summarize this dialog:\\n{{dialog}}\\n---\\nSummary:\\n\"\n",
    "        )\n",
    "\n",
    "        def apply_prompt_template(s):\n",
    "            return prompt.format(dialog=s)\n",
    "\n",
    "        df['dialogue'] = df['dialogue'].map(apply_prompt_template)\n",
    "\n",
    "        self.preprocessed_list = []\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            processed_row = {}\n",
    "            \n",
    "            prompt = tokenizer.encode(tokenizer.bos_token + df.iloc[i]['dialogue'], add_special_tokens=False)\n",
    "            summary = tokenizer.encode(df.iloc[i]['summary'] +  tokenizer.eos_token, add_special_tokens=False)\n",
    "            \n",
    "            processed_row = {\n",
    "                \"input_ids\": prompt + summary,\n",
    "                \"attention_mask\" : [1] * (len(prompt) + len(summary)),\n",
    "                \"labels\": [-100] * len(prompt) + summary,\n",
    "            }\n",
    "            \n",
    "            self.preprocessed_list.append(processed_row)\n",
    "        \n",
    "        self.len = len(self.preprocessed_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.preprocessed_list[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/llama_recipes/model_checkpointing/checkpoint_handler.py:17: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead\n",
      "  from torch.distributed._shard.checkpoint import (\n",
      "Preprocessing dataset: 100%|██████████| 12956/12956 [00:00<00:00, 31404.68it/s]\n"
     ]
    }
   ],
   "source": [
    "#from llama_recipes.configs.datasets import samsum_dataset\n",
    "from llama_recipes.data.concatenator import ConcatDataset\n",
    "from llama_recipes.utils.config_utils import get_dataloader_kwargs\n",
    "#from llama_recipes.utils.dataset_utils import get_preprocessed_dataset\n",
    "\n",
    "train_dataset = DatasetForLlamaTrain('../../data/train_dev.csv')    # train + dev dataset\n",
    "\n",
    "train_dl_kwargs = get_dataloader_kwargs(train_config, train_dataset, tokenizer, \"train\")\n",
    "\n",
    "if train_config.batching_strategy == \"packing\":\n",
    "        train_dataset = ConcatDataset(train_dataset, chunk_size=train_config.context_length)\n",
    "\n",
    "# Create DataLoaders for the training and validation dataset\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    num_workers=train_config.num_workers_dataloader,\n",
    "    pin_memory=True,\n",
    "    **train_dl_kwargs,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Prepare model for PEFT\n",
    "\n",
    "Let's prepare the model for Parameter Efficient Fine Tuning (PEFT):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, prepare_model_for_kbit_training, LoraConfig\n",
    "from dataclasses import asdict\n",
    "from llama_recipes.configs import lora_config as LORA_CONFIG\n",
    "\n",
    "lora_config = LORA_CONFIG()\n",
    "lora_config.r = 8\n",
    "lora_config.lora_alpha = 32\n",
    "lora_dropout: float=0.01\n",
    "\n",
    "peft_config = LoraConfig(**asdict(lora_config))\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Fine tune the model\n",
    "\n",
    "Here, we fine tune the model for a single epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/llama_recipes/utils/train_utils.py:92: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/memory.py:343: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "Training Epoch: 1:   0%|\u001b[34m          \u001b[0m| 0/842 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/opt/conda/lib/python3.10/site-packages/llama_recipes/utils/train_utils.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "Training Epoch: 1/1, step 3368/3369 completed (loss: 0.1310376226902008): : 843it [3:00:27, 12.84s/it]                        2.83s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max CUDA memory allocated was 9 GB\n",
      "Max CUDA memory reserved was 10 GB\n",
      "Peak active CUDA memory was 9 GB\n",
      "CUDA Malloc retries : 0\n",
      "CPU Total Peak Memory consumed during the train (max): 3 GB\n",
      "Epoch 1: train_perplexity=nan, train_epoch_loss=nan, epoch time 10827.905436053872s\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from llama_recipes.utils.train_utils import train\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=train_config.lr,\n",
    "            weight_decay=train_config.weight_decay,\n",
    "        )\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=train_config.gamma)\n",
    "\n",
    "# Start the training process\n",
    "results = train(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    None,\n",
    "    tokenizer,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    train_config.gradient_accumulation_steps,\n",
    "    train_config,\n",
    "    None,\n",
    "    None,\n",
    "    None,\n",
    "    wandb_run=None,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6:\n",
    "Save model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(train_config.output_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7:\n",
    "Try the fine tuned model on the same example again to see the learning progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize this dialog:\n",
      "#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
      "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
      "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
      "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
      "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
      "#Person2#: 알겠습니다.\n",
      "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
      "#Person2#: 네.\n",
      "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
      "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
      "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
      "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
      "---\n",
      "Summary:\n",
      " 스미스씨는 건강검진을 받기 위해 의사를 찾아갑니다. 의사는 스미스씨의 눈과 귀가 괜찮다고 말하고 담배를 끊으라고 제안합니다.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, \n",
    "                                          min_new_tokens = config_data['tokenizer']['min_new_tokens'], \n",
    "                                          max_new_tokens = config_data['tokenizer']['max_new_tokens'])[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 아래를 실행하기 전에 \n",
    "1. 메모리 확보를 위해 커널을 재시작 할 것!\n",
    "2. 제일 위쪽에 config_data 정의하는 코드 블록 실행할것!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    #np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625e8f9e208142989ea4365e058f63d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://huggingface.co/blog/peft 이 글에서 학습한걸 읽는 코드를 참고해서 작성함.\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from llama_recipes.configs import train_config as TRAIN_CONFIG\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "peft_model_id = config_data['general']['output_dir']\n",
    "peftConfig = PeftConfig.from_pretrained(peft_model_id)\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,  # Add\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "            peftConfig.base_model_name_or_path,\n",
    "            device_map=\"auto\",\n",
    "            quantization_config=config,\n",
    "            use_cache=False,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "        )\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "model = model.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(peftConfig.base_model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize this dialog:\n",
      "#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
      "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
      "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
      "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
      "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
      "#Person2#: 알겠습니다.\n",
      "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
      "#Person2#: 네.\n",
      "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
      "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
      "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
      "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
      "---\n",
      "Summary:\n",
      " 스미스씨는 건강검진을 받기 위해 의사를 찾아갑니다. 의사는 스미스씨의 눈과 귀가 괜찮다고 말하고 스미스씨에게 담배를 끊으라고 제안합니다.\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"\n",
    "Summarize this dialog:\n",
    "#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
    "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
    "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
    "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
    "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
    "#Person2#: 알겠습니다.\n",
    "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
    "#Person2#: 네.\n",
    "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
    "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
    "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
    "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
    "---\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    generated = model.generate(**model_input, \n",
    "                               min_new_tokens=config_data['tokenizer']['min_new_tokens'], \n",
    "                               max_new_tokens=config_data['tokenizer']['max_new_tokens'])\n",
    "    \n",
    "    print(tokenizer.decode(generated[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "class DatasetForLlamaTest(Dataset):\n",
    "    def __init__(self, train_csv_fullpath):\n",
    "        df = pd.read_csv(train_csv_fullpath)\n",
    "        \n",
    "        prompt = (\n",
    "            f\"Summarize this dialog:\\n{{dialog}}\\n---\\nSummary:\\n\"\n",
    "        )\n",
    "\n",
    "        def apply_prompt_template(s):\n",
    "            return prompt.format(dialog=s)\n",
    "\n",
    "        df['dialogue'] = df['dialogue'].map(apply_prompt_template)\n",
    "\n",
    "        self.fname_list = []\n",
    "        self.preprocessed_list = []\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            #\n",
    "            self.fname_list.append(df.iloc[i]['fname'])\n",
    "            \n",
    "            # tokenizer() 와 tokenizer.encode() 는 다르다!\n",
    "            # tokenizer() 를 사용해야 딕셔너리(input_ids, attention_mask) 형태로 리턴됨.\n",
    "            prompt = tokenizer(df.iloc[i]['dialogue'], return_tensors=\"pt\").to(\"cuda\")\n",
    "            self.preprocessed_list.append(prompt)\n",
    "        \n",
    "        self.len = len(self.preprocessed_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.fname_list[idx], self.preprocessed_list[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetForLlamaTest('../../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/499 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  0%|          | 1/499 [01:58<16:21:00, 118.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  0%|          | 2/499 [02:38<10:01:08, 72.57s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 3/499 [03:09<7:20:43, 53.31s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 4/499 [03:28<5:28:21, 39.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 5/499 [03:53<4:44:11, 34.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|          | 6/499 [05:03<6:23:29, 46.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  1%|▏         | 7/499 [05:29<5:27:46, 39.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 8/499 [06:03<5:11:33, 38.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 9/499 [06:23<4:24:49, 32.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 10/499 [06:45<3:57:26, 29.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 11/499 [07:09<3:43:21, 27.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  2%|▏         | 12/499 [07:31<3:28:50, 25.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 13/499 [07:58<3:32:07, 26.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 14/499 [08:06<2:46:37, 20.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 15/499 [08:33<3:02:00, 22.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 16/499 [08:54<2:58:01, 22.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  3%|▎         | 17/499 [09:09<2:41:51, 20.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▎         | 18/499 [09:20<2:18:02, 17.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 19/499 [09:37<2:17:40, 17.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 20/499 [09:48<2:02:28, 15.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 21/499 [10:13<2:26:00, 18.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  4%|▍         | 22/499 [11:14<4:06:48, 31.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▍         | 23/499 [11:28<3:25:37, 25.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▍         | 24/499 [11:46<3:06:01, 23.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 25/499 [12:06<2:57:34, 22.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 26/499 [13:01<4:13:55, 32.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  5%|▌         | 27/499 [13:19<3:39:37, 27.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 28/499 [13:59<4:08:03, 31.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 29/499 [14:53<5:00:42, 38.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 30/499 [14:59<3:44:55, 28.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▌         | 31/499 [15:26<3:40:20, 28.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  6%|▋         | 32/499 [15:39<3:04:19, 23.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 33/499 [15:58<2:51:31, 22.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 34/499 [16:21<2:53:05, 22.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 35/499 [16:34<2:31:42, 19.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 36/499 [17:02<2:50:48, 22.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  7%|▋         | 37/499 [18:35<5:34:13, 43.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 38/499 [18:42<4:10:20, 32.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 39/499 [19:14<4:07:38, 32.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 40/499 [20:06<4:51:52, 38.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 41/499 [20:23<4:04:02, 31.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  8%|▊         | 42/499 [21:13<4:44:58, 37.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  9%|▊         | 43/499 [21:34<4:05:36, 32.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  9%|▉         | 44/499 [22:12<4:19:11, 34.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  9%|▉         | 45/499 [22:39<4:01:54, 31.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  9%|▉         | 46/499 [23:18<4:17:47, 34.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "  9%|▉         | 47/499 [23:42<3:52:32, 30.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 10%|▉         | 48/499 [24:15<3:57:51, 31.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 10%|▉         | 49/499 [24:30<3:19:18, 26.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 10%|█         | 50/499 [25:10<3:49:15, 30.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 10%|█         | 51/499 [25:24<3:11:43, 25.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 10%|█         | 52/499 [25:42<2:53:33, 23.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 11%|█         | 53/499 [25:54<2:29:05, 20.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 11%|█         | 54/499 [26:00<1:56:54, 15.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 11%|█         | 55/499 [26:15<1:55:26, 15.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 11%|█         | 56/499 [26:30<1:53:50, 15.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 11%|█▏        | 57/499 [27:08<2:43:33, 22.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 12%|█▏        | 58/499 [27:49<3:24:55, 27.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 12%|█▏        | 59/499 [28:03<2:51:54, 23.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 12%|█▏        | 60/499 [29:24<4:59:10, 40.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 12%|█▏        | 61/499 [29:43<4:10:01, 34.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 12%|█▏        | 62/499 [30:25<4:27:20, 36.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 13%|█▎        | 63/499 [30:55<4:11:48, 34.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 13%|█▎        | 64/499 [31:13<3:35:17, 29.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 13%|█▎        | 65/499 [31:21<2:46:22, 23.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 13%|█▎        | 66/499 [31:26<2:08:05, 17.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 13%|█▎        | 67/499 [31:44<2:07:20, 17.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 14%|█▎        | 68/499 [32:18<2:43:32, 22.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 14%|█▍        | 69/499 [32:30<2:18:56, 19.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 14%|█▍        | 70/499 [32:42<2:02:06, 17.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 14%|█▍        | 71/499 [32:58<1:59:43, 16.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 14%|█▍        | 72/499 [33:49<3:12:44, 27.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 15%|█▍        | 73/499 [34:41<4:06:35, 34.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 15%|█▍        | 74/499 [35:15<4:03:29, 34.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 15%|█▌        | 75/499 [35:36<3:34:31, 30.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 15%|█▌        | 76/499 [36:03<3:27:13, 29.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 15%|█▌        | 77/499 [36:26<3:12:13, 27.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 16%|█▌        | 78/499 [36:39<2:42:35, 23.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 16%|█▌        | 79/499 [37:41<4:03:51, 34.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 16%|█▌        | 80/499 [38:05<3:41:21, 31.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 16%|█▌        | 81/499 [38:20<3:05:02, 26.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 16%|█▋        | 82/499 [38:29<2:27:43, 21.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 17%|█▋        | 83/499 [38:55<2:36:51, 22.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 17%|█▋        | 84/499 [39:31<3:04:42, 26.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 17%|█▋        | 85/499 [39:49<2:45:44, 24.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 17%|█▋        | 86/499 [40:06<2:31:59, 22.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 17%|█▋        | 87/499 [40:38<2:50:39, 24.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 18%|█▊        | 88/499 [42:14<5:17:47, 46.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 18%|█▊        | 89/499 [43:02<5:20:39, 46.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 18%|█▊        | 90/499 [43:23<4:26:27, 39.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 18%|█▊        | 91/499 [43:35<3:30:35, 30.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 18%|█▊        | 92/499 [43:44<2:44:02, 24.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 19%|█▊        | 93/499 [44:06<2:41:00, 23.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 19%|█▉        | 94/499 [44:46<3:11:30, 28.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 19%|█▉        | 95/499 [45:15<3:13:33, 28.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 19%|█▉        | 96/499 [46:12<4:10:22, 37.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 19%|█▉        | 97/499 [46:29<3:27:41, 31.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|█▉        | 98/499 [46:40<2:47:24, 25.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|█▉        | 99/499 [46:51<2:18:24, 20.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|██        | 100/499 [47:18<2:31:45, 22.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|██        | 101/499 [47:47<2:43:34, 24.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|██        | 102/499 [47:57<2:14:21, 20.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 21%|██        | 103/499 [48:09<1:56:28, 17.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 21%|██        | 104/499 [48:16<1:34:50, 14.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 21%|██        | 105/499 [49:20<3:13:15, 29.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 21%|██        | 106/499 [49:56<3:26:23, 31.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 21%|██▏       | 107/499 [50:35<3:38:49, 33.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 22%|██▏       | 108/499 [51:01<3:24:48, 31.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 22%|██▏       | 109/499 [51:17<2:54:48, 26.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 22%|██▏       | 110/499 [51:34<2:33:59, 23.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 22%|██▏       | 111/499 [51:53<2:24:46, 22.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 22%|██▏       | 112/499 [53:19<4:27:15, 41.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 23%|██▎       | 113/499 [53:31<3:29:23, 32.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 23%|██▎       | 114/499 [53:53<3:08:50, 29.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 23%|██▎       | 115/499 [54:00<2:25:50, 22.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 23%|██▎       | 116/499 [54:19<2:18:30, 21.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 23%|██▎       | 117/499 [54:38<2:12:48, 20.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 24%|██▎       | 118/499 [55:28<3:06:50, 29.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 24%|██▍       | 119/499 [57:13<5:30:12, 52.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 24%|██▍       | 120/499 [57:25<4:14:08, 40.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 24%|██▍       | 121/499 [57:40<3:25:45, 32.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 24%|██▍       | 122/499 [58:21<3:40:26, 35.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 25%|██▍       | 123/499 [58:34<2:57:20, 28.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 25%|██▍       | 124/499 [58:41<2:17:49, 22.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 25%|██▌       | 125/499 [58:51<1:54:22, 18.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 25%|██▌       | 126/499 [59:09<1:53:14, 18.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 25%|██▌       | 127/499 [59:42<2:21:42, 22.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 26%|██▌       | 128/499 [59:55<2:02:56, 19.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 26%|██▌       | 129/499 [1:00:05<1:44:25, 16.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 26%|██▌       | 130/499 [1:00:13<1:27:04, 14.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 26%|██▋       | 131/499 [1:00:46<2:01:48, 19.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 26%|██▋       | 132/499 [1:02:11<4:00:18, 39.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 27%|██▋       | 133/499 [1:03:21<4:55:39, 48.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 27%|██▋       | 134/499 [1:03:43<4:06:31, 40.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 27%|██▋       | 135/499 [1:04:08<3:38:41, 36.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 27%|██▋       | 136/499 [1:05:00<4:07:09, 40.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 27%|██▋       | 137/499 [1:05:48<4:19:39, 43.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 28%|██▊       | 138/499 [1:05:55<3:12:33, 32.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 28%|██▊       | 139/499 [1:06:00<2:24:19, 24.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 28%|██▊       | 140/499 [1:06:10<1:58:10, 19.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 28%|██▊       | 141/499 [1:06:53<2:38:51, 26.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 28%|██▊       | 142/499 [1:07:16<2:33:32, 25.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 29%|██▊       | 143/499 [1:08:34<4:05:14, 41.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 29%|██▉       | 144/499 [1:08:54<3:27:23, 35.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 29%|██▉       | 145/499 [1:09:09<2:50:09, 28.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 29%|██▉       | 146/499 [1:09:24<2:26:03, 24.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 29%|██▉       | 147/499 [1:10:09<3:00:34, 30.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 30%|██▉       | 148/499 [1:10:19<2:24:02, 24.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 30%|██▉       | 149/499 [1:10:42<2:19:53, 23.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 30%|███       | 150/499 [1:11:01<2:11:16, 22.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 30%|███       | 151/499 [1:11:18<2:02:13, 21.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 30%|███       | 152/499 [1:11:28<1:41:27, 17.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 31%|███       | 153/499 [1:11:46<1:42:44, 17.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 31%|███       | 154/499 [1:12:01<1:37:22, 16.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 31%|███       | 155/499 [1:12:09<1:21:05, 14.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 31%|███▏      | 156/499 [1:14:22<4:45:07, 49.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 31%|███▏      | 157/499 [1:15:12<4:44:54, 49.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 32%|███▏      | 158/499 [1:16:17<5:09:39, 54.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 32%|███▏      | 159/499 [1:16:31<3:59:58, 42.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 32%|███▏      | 160/499 [1:16:40<3:02:16, 32.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 32%|███▏      | 161/499 [1:17:05<2:49:53, 30.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 32%|███▏      | 162/499 [1:17:57<3:25:44, 36.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 33%|███▎      | 163/499 [1:18:08<2:41:35, 28.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 33%|███▎      | 164/499 [1:18:23<2:19:03, 24.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 33%|███▎      | 165/499 [1:18:30<1:48:44, 19.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 33%|███▎      | 166/499 [1:18:53<1:52:49, 20.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 33%|███▎      | 167/499 [1:19:10<1:47:53, 19.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 34%|███▎      | 168/499 [1:19:56<2:31:49, 27.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 34%|███▍      | 169/499 [1:20:08<2:05:22, 22.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 34%|███▍      | 170/499 [1:21:35<3:49:36, 41.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 34%|███▍      | 171/499 [1:21:46<2:59:35, 32.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 34%|███▍      | 172/499 [1:22:15<2:51:50, 31.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 35%|███▍      | 173/499 [1:23:09<3:27:52, 38.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 35%|███▍      | 174/499 [1:23:20<2:43:36, 30.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 35%|███▌      | 175/499 [1:23:33<2:14:13, 24.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 35%|███▌      | 176/499 [1:24:15<2:41:39, 30.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 35%|███▌      | 177/499 [1:24:20<2:00:49, 22.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 36%|███▌      | 178/499 [1:24:29<1:40:01, 18.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 36%|███▌      | 179/499 [1:24:39<1:25:03, 15.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 36%|███▌      | 180/499 [1:25:08<1:46:11, 19.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 36%|███▋      | 181/499 [1:25:21<1:34:03, 17.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 36%|███▋      | 182/499 [1:25:39<1:34:55, 17.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 37%|███▋      | 183/499 [1:25:48<1:19:58, 15.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 37%|███▋      | 184/499 [1:26:15<1:38:40, 18.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 37%|███▋      | 185/499 [1:26:58<2:16:17, 26.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 37%|███▋      | 186/499 [1:27:07<1:48:14, 20.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 37%|███▋      | 187/499 [1:27:32<1:55:03, 22.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 38%|███▊      | 188/499 [1:27:51<1:50:35, 21.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 38%|███▊      | 189/499 [1:28:33<2:22:10, 27.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 38%|███▊      | 190/499 [1:28:44<1:56:18, 22.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 38%|███▊      | 191/499 [1:28:56<1:39:31, 19.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 38%|███▊      | 192/499 [1:29:26<1:55:17, 22.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 39%|███▊      | 193/499 [1:30:03<2:16:50, 26.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 39%|███▉      | 194/499 [1:30:17<1:57:17, 23.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 39%|███▉      | 195/499 [1:30:46<2:05:56, 24.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 39%|███▉      | 196/499 [1:31:01<1:49:25, 21.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 39%|███▉      | 197/499 [1:31:17<1:40:34, 19.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|███▉      | 198/499 [1:31:36<1:39:40, 19.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|███▉      | 199/499 [1:32:03<1:48:54, 21.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|████      | 200/499 [1:32:29<1:56:02, 23.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|████      | 201/499 [1:33:34<2:57:07, 35.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|████      | 202/499 [1:34:03<2:46:22, 33.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 41%|████      | 203/499 [1:34:11<2:08:05, 25.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 41%|████      | 204/499 [1:35:01<2:43:33, 33.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 41%|████      | 205/499 [1:35:17<2:17:36, 28.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 41%|████▏     | 206/499 [1:35:49<2:22:55, 29.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 41%|████▏     | 207/499 [1:36:05<2:02:46, 25.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 42%|████▏     | 208/499 [1:36:32<2:04:34, 25.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 42%|████▏     | 209/499 [1:37:14<2:27:51, 30.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 42%|████▏     | 210/499 [1:37:29<2:05:48, 26.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 42%|████▏     | 211/499 [1:38:02<2:14:56, 28.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 42%|████▏     | 212/499 [1:38:13<1:49:06, 22.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 43%|████▎     | 213/499 [1:38:27<1:36:16, 20.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 43%|████▎     | 214/499 [1:39:16<2:16:46, 28.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 43%|████▎     | 215/499 [1:40:23<3:10:57, 40.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 43%|████▎     | 216/499 [1:40:30<2:22:41, 30.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 43%|████▎     | 217/499 [1:40:44<2:00:31, 25.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 44%|████▎     | 218/499 [1:41:03<1:50:40, 23.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 44%|████▍     | 219/499 [1:41:19<1:39:08, 21.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 44%|████▍     | 220/499 [1:41:40<1:37:59, 21.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 44%|████▍     | 221/499 [1:42:37<2:28:03, 31.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 44%|████▍     | 222/499 [1:43:17<2:38:47, 34.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 45%|████▍     | 223/499 [1:43:42<2:25:07, 31.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 45%|████▍     | 224/499 [1:43:52<1:55:32, 25.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 45%|████▌     | 225/499 [1:44:00<1:30:41, 19.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 45%|████▌     | 226/499 [1:44:34<1:50:08, 24.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 45%|████▌     | 227/499 [1:44:42<1:27:37, 19.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 46%|████▌     | 228/499 [1:45:23<1:56:28, 25.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 46%|████▌     | 229/499 [1:46:18<2:35:50, 34.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 46%|████▌     | 230/499 [1:46:24<1:56:44, 26.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 46%|████▋     | 231/499 [1:46:32<1:31:51, 20.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 46%|████▋     | 232/499 [1:47:24<2:13:19, 29.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 47%|████▋     | 233/499 [1:47:45<2:01:29, 27.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 47%|████▋     | 234/499 [1:47:53<1:34:19, 21.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 47%|████▋     | 235/499 [1:49:17<2:56:44, 40.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 47%|████▋     | 236/499 [1:49:42<2:36:02, 35.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 47%|████▋     | 237/499 [1:50:37<3:01:40, 41.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 48%|████▊     | 238/499 [1:51:04<2:41:53, 37.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 48%|████▊     | 239/499 [1:51:39<2:38:34, 36.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 48%|████▊     | 240/499 [1:51:57<2:13:21, 30.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 48%|████▊     | 241/499 [1:53:06<3:02:14, 42.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 48%|████▊     | 242/499 [1:53:24<2:29:27, 34.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 49%|████▊     | 243/499 [1:53:51<2:19:02, 32.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 49%|████▉     | 244/499 [1:54:22<2:16:45, 32.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 49%|████▉     | 245/499 [1:54:43<2:01:34, 28.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 49%|████▉     | 246/499 [1:54:58<1:44:31, 24.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 49%|████▉     | 247/499 [1:56:04<2:35:36, 37.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 50%|████▉     | 248/499 [1:56:24<2:13:37, 31.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 50%|████▉     | 249/499 [1:57:17<2:39:43, 38.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 50%|█████     | 250/499 [1:57:42<2:21:58, 34.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 50%|█████     | 251/499 [1:57:57<1:57:23, 28.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 51%|█████     | 252/499 [1:58:07<1:34:54, 23.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 51%|█████     | 253/499 [1:59:11<2:24:35, 35.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 51%|█████     | 254/499 [1:59:41<2:17:54, 33.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 51%|█████     | 255/499 [1:59:53<1:50:12, 27.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 51%|█████▏    | 256/499 [2:00:41<2:15:05, 33.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 52%|█████▏    | 257/499 [2:01:32<2:35:46, 38.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 52%|█████▏    | 258/499 [2:01:49<2:08:53, 32.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 52%|█████▏    | 259/499 [2:01:55<1:37:56, 24.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 52%|█████▏    | 260/499 [2:02:17<1:34:33, 23.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 52%|█████▏    | 261/499 [2:03:02<1:58:37, 29.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 53%|█████▎    | 262/499 [2:03:16<1:39:18, 25.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 53%|█████▎    | 263/499 [2:04:06<2:08:41, 32.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 53%|█████▎    | 264/499 [2:05:31<3:09:20, 48.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 53%|█████▎    | 265/499 [2:06:01<2:47:53, 43.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 53%|█████▎    | 266/499 [2:06:28<2:28:04, 38.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 54%|█████▎    | 267/499 [2:06:59<2:18:59, 35.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 54%|█████▎    | 268/499 [2:07:15<1:55:02, 29.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 54%|█████▍    | 269/499 [2:08:36<2:53:19, 45.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 54%|█████▍    | 270/499 [2:08:48<2:14:22, 35.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 54%|█████▍    | 271/499 [2:09:17<2:07:11, 33.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 55%|█████▍    | 272/499 [2:09:52<2:08:19, 33.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 55%|█████▍    | 273/499 [2:10:14<1:54:51, 30.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 55%|█████▍    | 274/499 [2:10:32<1:39:28, 26.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 55%|█████▌    | 275/499 [2:10:48<1:27:18, 23.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 55%|█████▌    | 276/499 [2:10:54<1:08:05, 18.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 56%|█████▌    | 277/499 [2:11:16<1:12:05, 19.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 56%|█████▌    | 278/499 [2:11:36<1:11:46, 19.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 56%|█████▌    | 279/499 [2:12:00<1:16:12, 20.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 56%|█████▌    | 280/499 [2:12:32<1:27:51, 24.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 56%|█████▋    | 281/499 [2:12:49<1:20:21, 22.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 57%|█████▋    | 282/499 [2:13:11<1:20:01, 22.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 57%|█████▋    | 283/499 [2:13:18<1:02:46, 17.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 57%|█████▋    | 284/499 [2:13:38<1:05:13, 18.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 57%|█████▋    | 285/499 [2:14:10<1:19:44, 22.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 57%|█████▋    | 286/499 [2:14:25<1:12:02, 20.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 58%|█████▊    | 287/499 [2:14:42<1:07:56, 19.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 58%|█████▊    | 288/499 [2:15:22<1:29:48, 25.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 58%|█████▊    | 289/499 [2:15:35<1:16:14, 21.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 58%|█████▊    | 290/499 [2:16:28<1:47:55, 30.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 58%|█████▊    | 291/499 [2:16:49<1:36:50, 27.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 59%|█████▊    | 292/499 [2:16:55<1:14:27, 21.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 59%|█████▊    | 293/499 [2:17:39<1:36:24, 28.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 59%|█████▉    | 294/499 [2:18:36<2:05:45, 36.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 59%|█████▉    | 295/499 [2:19:43<2:36:43, 46.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 59%|█████▉    | 296/499 [2:20:14<2:20:21, 41.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 60%|█████▉    | 297/499 [2:20:53<2:17:08, 40.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 60%|█████▉    | 298/499 [2:21:14<1:56:30, 34.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 60%|█████▉    | 299/499 [2:22:10<2:17:09, 41.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 60%|██████    | 300/499 [2:22:40<2:05:36, 37.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 60%|██████    | 301/499 [2:22:50<1:37:12, 29.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 61%|██████    | 302/499 [2:23:05<1:22:34, 25.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 61%|██████    | 303/499 [2:23:17<1:08:51, 21.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 61%|██████    | 304/499 [2:23:40<1:10:47, 21.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 61%|██████    | 305/499 [2:23:48<56:31, 17.48s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 61%|██████▏   | 306/499 [2:24:08<59:05, 18.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 62%|██████▏   | 307/499 [2:24:28<1:00:18, 18.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 62%|██████▏   | 308/499 [2:24:41<54:43, 17.19s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 62%|██████▏   | 309/499 [2:24:47<43:11, 13.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 62%|██████▏   | 310/499 [2:25:40<1:20:36, 25.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 62%|██████▏   | 311/499 [2:26:13<1:26:51, 27.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 63%|██████▎   | 312/499 [2:26:43<1:28:34, 28.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 63%|██████▎   | 313/499 [2:26:51<1:09:12, 22.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 63%|██████▎   | 314/499 [2:26:59<55:41, 18.06s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 63%|██████▎   | 315/499 [2:27:16<54:12, 17.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 63%|██████▎   | 316/499 [2:27:38<58:03, 19.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 64%|██████▎   | 317/499 [2:27:45<46:38, 15.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 64%|██████▎   | 318/499 [2:28:24<1:07:56, 22.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 64%|██████▍   | 319/499 [2:29:11<1:29:37, 29.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 64%|██████▍   | 320/499 [2:29:19<1:09:13, 23.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 64%|██████▍   | 321/499 [2:29:33<1:00:21, 20.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 65%|██████▍   | 322/499 [2:29:56<1:02:32, 21.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 65%|██████▍   | 323/499 [2:30:03<49:58, 17.04s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 65%|██████▍   | 324/499 [2:30:47<1:13:32, 25.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 65%|██████▌   | 325/499 [2:31:10<1:11:00, 24.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 65%|██████▌   | 326/499 [2:31:25<1:02:20, 21.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 66%|██████▌   | 327/499 [2:31:33<50:27, 17.60s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 66%|██████▌   | 328/499 [2:32:37<1:29:21, 31.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 66%|██████▌   | 329/499 [2:33:25<1:43:02, 36.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 66%|██████▌   | 330/499 [2:34:45<2:19:33, 49.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 66%|██████▋   | 331/499 [2:35:00<1:49:46, 39.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 67%|██████▋   | 332/499 [2:35:19<1:31:51, 33.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 67%|██████▋   | 333/499 [2:35:31<1:14:28, 26.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 67%|██████▋   | 334/499 [2:35:46<1:04:11, 23.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 67%|██████▋   | 335/499 [2:36:05<59:50, 21.89s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 67%|██████▋   | 336/499 [2:36:23<56:09, 20.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 68%|██████▊   | 337/499 [2:36:38<51:21, 19.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 68%|██████▊   | 338/499 [2:36:52<47:04, 17.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 68%|██████▊   | 339/499 [2:37:01<39:48, 14.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 68%|██████▊   | 340/499 [2:37:34<54:10, 20.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 68%|██████▊   | 341/499 [2:37:40<42:40, 16.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 69%|██████▊   | 342/499 [2:38:20<1:00:23, 23.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 69%|██████▊   | 343/499 [2:38:26<46:50, 18.02s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 69%|██████▉   | 344/499 [2:39:09<1:06:07, 25.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 69%|██████▉   | 345/499 [2:40:18<1:39:11, 38.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 69%|██████▉   | 346/499 [2:41:42<2:13:12, 52.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 70%|██████▉   | 347/499 [2:43:21<2:47:23, 66.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 70%|██████▉   | 348/499 [2:43:43<2:13:29, 53.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 70%|██████▉   | 349/499 [2:44:17<1:58:07, 47.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 70%|███████   | 350/499 [2:44:24<1:27:04, 35.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 70%|███████   | 351/499 [2:44:57<1:25:39, 34.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 71%|███████   | 352/499 [2:45:09<1:07:51, 27.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 71%|███████   | 353/499 [2:45:30<1:02:56, 25.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 71%|███████   | 354/499 [2:45:42<52:24, 21.68s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 71%|███████   | 355/499 [2:46:20<1:03:56, 26.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 71%|███████▏  | 356/499 [2:46:29<50:14, 21.08s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 72%|███████▏  | 357/499 [2:46:40<43:06, 18.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 72%|███████▏  | 358/499 [2:46:46<34:11, 14.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 72%|███████▏  | 359/499 [2:47:26<51:54, 22.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 72%|███████▏  | 360/499 [2:47:41<46:32, 20.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 72%|███████▏  | 361/499 [2:48:11<52:34, 22.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 73%|███████▎  | 362/499 [2:48:16<40:18, 17.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 73%|███████▎  | 363/499 [2:48:50<50:51, 22.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 73%|███████▎  | 364/499 [2:49:47<1:13:57, 32.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 73%|███████▎  | 365/499 [2:50:03<1:02:13, 27.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 73%|███████▎  | 366/499 [2:50:16<51:58, 23.45s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 74%|███████▎  | 367/499 [2:50:48<57:09, 25.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 74%|███████▎  | 368/499 [2:51:08<52:49, 24.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 74%|███████▍  | 369/499 [2:51:29<50:13, 23.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 74%|███████▍  | 370/499 [2:51:53<50:35, 23.53s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 74%|███████▍  | 371/499 [2:52:01<40:04, 18.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 75%|███████▍  | 372/499 [2:52:07<31:37, 14.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 75%|███████▍  | 373/499 [2:52:30<36:39, 17.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 75%|███████▍  | 374/499 [2:52:55<40:39, 19.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 75%|███████▌  | 375/499 [2:53:30<49:55, 24.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 75%|███████▌  | 376/499 [2:55:03<1:32:00, 44.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 76%|███████▌  | 377/499 [2:55:33<1:22:26, 40.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 76%|███████▌  | 378/499 [2:55:57<1:11:24, 35.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 76%|███████▌  | 379/499 [2:56:18<1:02:08, 31.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 76%|███████▌  | 380/499 [2:58:37<2:05:48, 63.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 76%|███████▋  | 381/499 [2:59:16<1:50:12, 56.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 77%|███████▋  | 382/499 [3:00:17<1:52:18, 57.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 77%|███████▋  | 383/499 [3:01:29<1:59:35, 61.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 77%|███████▋  | 384/499 [3:02:22<1:53:28, 59.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 77%|███████▋  | 385/499 [3:03:08<1:45:19, 55.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 77%|███████▋  | 386/499 [3:03:17<1:18:09, 41.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 78%|███████▊  | 387/499 [3:03:39<1:06:39, 35.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 78%|███████▊  | 388/499 [3:04:03<59:19, 32.07s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 78%|███████▊  | 389/499 [3:04:23<52:10, 28.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 78%|███████▊  | 390/499 [3:04:49<50:11, 27.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 78%|███████▊  | 391/499 [3:05:18<50:39, 28.14s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 79%|███████▊  | 392/499 [3:06:19<1:07:59, 38.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 79%|███████▉  | 393/499 [3:06:56<1:06:46, 37.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 79%|███████▉  | 394/499 [3:07:14<55:29, 31.71s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 79%|███████▉  | 395/499 [3:07:33<48:36, 28.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 79%|███████▉  | 396/499 [3:07:55<44:39, 26.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 80%|███████▉  | 397/499 [3:08:19<43:06, 25.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 80%|███████▉  | 398/499 [3:09:05<53:32, 31.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 80%|███████▉  | 399/499 [3:09:24<46:22, 27.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 80%|████████  | 400/499 [3:09:44<41:49, 25.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 80%|████████  | 401/499 [3:10:55<1:04:05, 39.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 81%|████████  | 402/499 [3:11:10<51:21, 31.76s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 81%|████████  | 403/499 [3:11:23<42:08, 26.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 81%|████████  | 404/499 [3:11:35<34:59, 22.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 81%|████████  | 405/499 [3:12:07<39:12, 25.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 81%|████████▏ | 406/499 [3:12:15<30:35, 19.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 82%|████████▏ | 407/499 [3:12:41<33:23, 21.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 82%|████████▏ | 408/499 [3:13:21<41:06, 27.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 82%|████████▏ | 409/499 [3:13:51<42:13, 28.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 82%|████████▏ | 410/499 [3:14:06<35:35, 23.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 82%|████████▏ | 411/499 [3:15:05<50:41, 34.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 83%|████████▎ | 412/499 [3:15:18<40:45, 28.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 83%|████████▎ | 413/499 [3:16:44<1:05:19, 45.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 83%|████████▎ | 414/499 [3:17:17<59:08, 41.75s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 83%|████████▎ | 415/499 [3:18:28<1:10:51, 50.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 83%|████████▎ | 416/499 [3:18:44<55:39, 40.24s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 84%|████████▎ | 417/499 [3:18:59<44:37, 32.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 84%|████████▍ | 418/499 [3:19:18<38:29, 28.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 84%|████████▍ | 419/499 [3:19:27<30:11, 22.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 84%|████████▍ | 420/499 [3:20:43<50:50, 38.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 84%|████████▍ | 421/499 [3:21:23<50:36, 38.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 85%|████████▍ | 422/499 [3:21:54<47:09, 36.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 85%|████████▍ | 423/499 [3:22:17<41:08, 32.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 85%|████████▍ | 424/499 [3:22:31<33:49, 27.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 85%|████████▌ | 425/499 [3:22:47<29:22, 23.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 85%|████████▌ | 426/499 [3:23:09<28:16, 23.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 86%|████████▌ | 427/499 [3:23:51<34:34, 28.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 86%|████████▌ | 428/499 [3:24:05<28:37, 24.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 86%|████████▌ | 429/499 [3:24:17<24:02, 20.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 86%|████████▌ | 430/499 [3:24:25<19:18, 16.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 86%|████████▋ | 431/499 [3:24:37<17:29, 15.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 87%|████████▋ | 432/499 [3:24:59<19:32, 17.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 87%|████████▋ | 433/499 [3:25:30<23:31, 21.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 87%|████████▋ | 434/499 [3:25:46<21:32, 19.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 87%|████████▋ | 435/499 [3:31:03<1:56:20, 109.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 87%|████████▋ | 436/499 [3:31:37<1:30:55, 86.60s/it] Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 88%|████████▊ | 437/499 [3:31:53<1:07:24, 65.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 88%|████████▊ | 438/499 [3:32:13<52:41, 51.83s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 88%|████████▊ | 439/499 [3:32:53<48:11, 48.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 88%|████████▊ | 440/499 [3:33:31<44:26, 45.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 88%|████████▊ | 441/499 [3:34:16<43:25, 44.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 89%|████████▊ | 442/499 [3:34:38<36:17, 38.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 89%|████████▉ | 443/499 [3:35:01<31:16, 33.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 89%|████████▉ | 444/499 [3:36:08<40:04, 43.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 89%|████████▉ | 445/499 [3:37:13<45:00, 50.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 89%|████████▉ | 446/499 [3:37:52<41:10, 46.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 90%|████████▉ | 447/499 [3:38:15<34:15, 39.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 90%|████████▉ | 448/499 [3:38:37<29:10, 34.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 90%|████████▉ | 449/499 [3:38:53<23:57, 28.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 90%|█████████ | 450/499 [3:39:44<29:06, 35.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 90%|█████████ | 451/499 [3:40:04<24:41, 30.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 91%|█████████ | 452/499 [3:40:16<19:46, 25.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 91%|█████████ | 453/499 [3:40:24<15:25, 20.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 91%|█████████ | 454/499 [3:40:43<14:40, 19.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 91%|█████████ | 455/499 [3:40:52<12:05, 16.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 91%|█████████▏| 456/499 [3:41:08<11:44, 16.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 92%|█████████▏| 457/499 [3:41:52<17:17, 24.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 92%|█████████▏| 458/499 [3:42:11<15:45, 23.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 92%|█████████▏| 459/499 [3:42:19<12:17, 18.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 92%|█████████▏| 460/499 [3:43:09<18:13, 28.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 92%|█████████▏| 461/499 [3:43:23<14:56, 23.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 93%|█████████▎| 462/499 [3:43:33<12:04, 19.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 93%|█████████▎| 463/499 [3:43:52<11:36, 19.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 93%|█████████▎| 464/499 [3:44:04<09:58, 17.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 93%|█████████▎| 465/499 [3:45:17<19:12, 33.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 93%|█████████▎| 466/499 [3:45:28<14:57, 27.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 94%|█████████▎| 467/499 [3:45:45<12:50, 24.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 94%|█████████▍| 468/499 [3:46:59<20:10, 39.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 94%|█████████▍| 469/499 [3:48:12<24:33, 49.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 94%|█████████▍| 470/499 [3:48:38<20:26, 42.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 94%|█████████▍| 471/499 [3:49:43<22:53, 49.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 95%|█████████▍| 472/499 [3:50:14<19:39, 43.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 95%|█████████▍| 473/499 [3:50:29<15:08, 34.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 95%|█████████▍| 474/499 [3:51:47<19:56, 47.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 95%|█████████▌| 475/499 [3:53:00<22:14, 55.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 95%|█████████▌| 476/499 [3:53:32<18:36, 48.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 96%|█████████▌| 477/499 [3:54:03<15:50, 43.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 96%|█████████▌| 478/499 [3:54:45<14:58, 42.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 96%|█████████▌| 479/499 [3:54:56<11:06, 33.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 96%|█████████▌| 480/499 [3:55:09<08:38, 27.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 96%|█████████▋| 481/499 [3:56:36<13:30, 45.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 97%|█████████▋| 482/499 [3:56:51<10:12, 36.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 97%|█████████▋| 483/499 [3:57:38<10:29, 39.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 97%|█████████▋| 484/499 [3:58:53<12:31, 50.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 97%|█████████▋| 485/499 [3:58:58<08:31, 36.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 97%|█████████▋| 486/499 [3:59:26<07:19, 33.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 98%|█████████▊| 487/499 [4:00:14<07:37, 38.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 98%|█████████▊| 488/499 [4:00:35<06:02, 32.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 98%|█████████▊| 489/499 [4:01:29<06:34, 39.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 98%|█████████▊| 490/499 [4:01:47<04:56, 32.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 98%|█████████▊| 491/499 [4:02:32<04:52, 36.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 99%|█████████▊| 492/499 [4:02:48<03:33, 30.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 99%|█████████▉| 493/499 [4:03:11<02:49, 28.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 99%|█████████▉| 494/499 [4:03:21<01:53, 22.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 99%|█████████▉| 495/499 [4:03:38<01:23, 20.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 99%|█████████▉| 496/499 [4:04:11<01:13, 24.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "100%|█████████▉| 497/499 [4:05:26<01:19, 39.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "100%|█████████▉| 498/499 [4:06:06<00:39, 39.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "100%|██████████| 499/499 [4:06:28<00:00, 29.64s/it]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "fname_list = []\n",
    "summary_list = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for fname, model_input in tqdm(train_dataset):\n",
    "        generated = model.generate(**model_input, \n",
    "                                   min_new_tokens=config_data['tokenizer']['min_new_tokens'], \n",
    "                                   max_new_tokens=config_data['tokenizer']['max_new_tokens'])\n",
    "\n",
    "        decoded_str = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "        \n",
    "        summary = decoded_str.split('Summary:\\n')[1]\n",
    "        \n",
    "        # \\n 제거\n",
    "        summary = re.sub('\\n', '', summary)\n",
    "        \n",
    "        fname_list.append(fname)\n",
    "        summary_list.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_0', 'test_1', 'test_2', 'test_3', 'test_4', 'test_5', 'test_6', 'test_7', 'test_8', 'test_9', 'test_10', 'test_11', 'test_12', 'test_13', 'test_14', 'test_15', 'test_16', 'test_17', 'test_18', 'test_19', 'test_20', 'test_21', 'test_22', 'test_23', 'test_24', 'test_25', 'test_26', 'test_27', 'test_28', 'test_29', 'test_30', 'test_31', 'test_32', 'test_33', 'test_34', 'test_35', 'test_36', 'test_37', 'test_38', 'test_39', 'test_40', 'test_41', 'test_42', 'test_43', 'test_44', 'test_45', 'test_46', 'test_47', 'test_48', 'test_49', 'test_50', 'test_51', 'test_52', 'test_53', 'test_54', 'test_55', 'test_56', 'test_57', 'test_58', 'test_59', 'test_60', 'test_61', 'test_62', 'test_63', 'test_64', 'test_65', 'test_66', 'test_67', 'test_68', 'test_69', 'test_70', 'test_71', 'test_72', 'test_73', 'test_74', 'test_75', 'test_76', 'test_77', 'test_78', 'test_79', 'test_80', 'test_81', 'test_82', 'test_83', 'test_84', 'test_85', 'test_86', 'test_87', 'test_88', 'test_89', 'test_90', 'test_91', 'test_92', 'test_93', 'test_94', 'test_95', 'test_96', 'test_97', 'test_98', 'test_99', 'test_100', 'test_101', 'test_102', 'test_103', 'test_104', 'test_105', 'test_106', 'test_107', 'test_108', 'test_109', 'test_110', 'test_111', 'test_112', 'test_113', 'test_114', 'test_115', 'test_116', 'test_117', 'test_118', 'test_119', 'test_120', 'test_121', 'test_122', 'test_123', 'test_124', 'test_125', 'test_126', 'test_127', 'test_128', 'test_129', 'test_130', 'test_131', 'test_132', 'test_133', 'test_134', 'test_135', 'test_136', 'test_137', 'test_138', 'test_139', 'test_140', 'test_141', 'test_142', 'test_143', 'test_144', 'test_145', 'test_146', 'test_147', 'test_148', 'test_149', 'test_150', 'test_151', 'test_152', 'test_153', 'test_154', 'test_155', 'test_156', 'test_157', 'test_158', 'test_159', 'test_160', 'test_161', 'test_162', 'test_163', 'test_164', 'test_165', 'test_166', 'test_167', 'test_168', 'test_169', 'test_170', 'test_171', 'test_172', 'test_173', 'test_174', 'test_175', 'test_176', 'test_177', 'test_178', 'test_179', 'test_180', 'test_181', 'test_182', 'test_183', 'test_184', 'test_185', 'test_186', 'test_187', 'test_188', 'test_189', 'test_190', 'test_191', 'test_192', 'test_193', 'test_194', 'test_195', 'test_196', 'test_197', 'test_198', 'test_199', 'test_200', 'test_201', 'test_202', 'test_203', 'test_204', 'test_205', 'test_206', 'test_207', 'test_208', 'test_209', 'test_210', 'test_211', 'test_212', 'test_213', 'test_214', 'test_215', 'test_216', 'test_217', 'test_218', 'test_219', 'test_220', 'test_221', 'test_222', 'test_223', 'test_224', 'test_225', 'test_226', 'test_227', 'test_228', 'test_229', 'test_230', 'test_231', 'test_232', 'test_233', 'test_234', 'test_235', 'test_236', 'test_237', 'test_238', 'test_239', 'test_240', 'test_241', 'test_242', 'test_243', 'test_244', 'test_245', 'test_246', 'test_247', 'test_248', 'test_249', 'test_250', 'test_251', 'test_252', 'test_253', 'test_254', 'test_255', 'test_256', 'test_257', 'test_258', 'test_259', 'test_260', 'test_261', 'test_262', 'test_263', 'test_264', 'test_265', 'test_266', 'test_267', 'test_268', 'test_269', 'test_270', 'test_271', 'test_272', 'test_273', 'test_274', 'test_275', 'test_276', 'test_277', 'test_278', 'test_279', 'test_280', 'test_281', 'test_282', 'test_283', 'test_284', 'test_285', 'test_286', 'test_287', 'test_288', 'test_289', 'test_290', 'test_291', 'test_292', 'test_293', 'test_294', 'test_295', 'test_296', 'test_297', 'test_298', 'test_299', 'test_300', 'test_301', 'test_302', 'test_303', 'test_304', 'test_305', 'test_306', 'test_307', 'test_308', 'test_309', 'test_310', 'test_311', 'test_312', 'test_313', 'test_314', 'test_315', 'test_316', 'test_317', 'test_318', 'test_319', 'test_320', 'test_321', 'test_322', 'test_323', 'test_324', 'test_325', 'test_326', 'test_327', 'test_328', 'test_329', 'test_330', 'test_331', 'test_332', 'test_333', 'test_334', 'test_335', 'test_336', 'test_337', 'test_338', 'test_339', 'test_340', 'test_341', 'test_342', 'test_343', 'test_344', 'test_345', 'test_346', 'test_347', 'test_348', 'test_349', 'test_350', 'test_351', 'test_352', 'test_353', 'test_354', 'test_355', 'test_356', 'test_357', 'test_358', 'test_359', 'test_360', 'test_361', 'test_362', 'test_363', 'test_364', 'test_365', 'test_366', 'test_367', 'test_368', 'test_369', 'test_370', 'test_371', 'test_372', 'test_373', 'test_374', 'test_375', 'test_376', 'test_377', 'test_378', 'test_379', 'test_380', 'test_381', 'test_382', 'test_383', 'test_384', 'test_385', 'test_386', 'test_387', 'test_388', 'test_389', 'test_390', 'test_391', 'test_392', 'test_393', 'test_394', 'test_395', 'test_396', 'test_397', 'test_398', 'test_399', 'test_400', 'test_401', 'test_402', 'test_403', 'test_404', 'test_405', 'test_406', 'test_407', 'test_408', 'test_409', 'test_410', 'test_411', 'test_412', 'test_413', 'test_414', 'test_415', 'test_416', 'test_417', 'test_418', 'test_419', 'test_420', 'test_421', 'test_422', 'test_423', 'test_424', 'test_425', 'test_426', 'test_427', 'test_428', 'test_429', 'test_430', 'test_431', 'test_432', 'test_433', 'test_434', 'test_435', 'test_436', 'test_437', 'test_438', 'test_439', 'test_440', 'test_441', 'test_442', 'test_443', 'test_444', 'test_445', 'test_446', 'test_447', 'test_448', 'test_449', 'test_450', 'test_451', 'test_452', 'test_453', 'test_454', 'test_455', 'test_456', 'test_457', 'test_458', 'test_459', 'test_460', 'test_461', 'test_462', 'test_463', 'test_464', 'test_465', 'test_467', 'test_468', 'test_469', 'test_470', 'test_471', 'test_472', 'test_473', 'test_474', 'test_475', 'test_476', 'test_477', 'test_478', 'test_479', 'test_480', 'test_481', 'test_482', 'test_483', 'test_484', 'test_485', 'test_486', 'test_487', 'test_488', 'test_489', 'test_490', 'test_491', 'test_492', 'test_493', 'test_494', 'test_495', 'test_496', 'test_497', 'test_498', 'test_499']\n",
      "[' 실장님은 더슨 씨에게 내부 및 외부 통신에 적용되는 새로운 정책을 메모로 전달하도록 요청합니다. 더슨 씨는 많은 직원들이 고객과 즉시 메시지를 사용하고 있다고 말하고, 실장님은 그들이 의사소통 방법을 바꾸어야 한다고 생각합니다. 실장님은 즉시 메시지를 계속 사용하는 직원에게 경고를 먼저 하고 직무 정지에 처할 것이며, 두 번째 위반 시에는 해고될 것이라고 말합니다.', ' #Person2#는 교통 체증에 걸렸고 자유를 즐기기 위해 자동차를 운전하고 있습니다. #Person1#는 #Person2#에게 대중교통을 이용하고 자전거로 출근하는 것을 제안합니다. #Person2#는 동의합니다.', ' #Person1#은 케이트에게 마샤와 히어로가 이혼하고 있다고 말한다. 케이트는 이혼이 놀랍다고 생각하며, 그들이 언제 이혼을 확정하는지 묻는다.', ' #Person1#은 브라이언의 생일을 축하하고 그와 춤을 추고 싶어한다. 그들은 서로의 옷차림에 대해 칭찬한다.', ' #Person1#과 #Person2#는 올림픽 스타디움에 있습니다. #Person2#는 스타디움의 완공 시기, 관람석의 수, 그리고 영어로 번역된 표지판에 대해 #Person1#에게 알려줍니다.', ' #Person1#은 회사에서 일하는 것이 짜증나서 자신의 회사를 창업하기로 결정했다. #Person2#는 #Person1#에게 사업 계획서를 작성하는 방법을 알려주고 그것이 어렵다고 말한다. #Person1#은 그냥 예전 일을 계속하는 것이 좋다고 생각한다.', ' #Person2#는 걸리고 있고, #Person1#는 그것이 수두라고 생각한다. #Person2#는 그것이 두드러기나 알레르기일 수도 있다고 생각하고, #Person1#는 그것이 위험하다고 생각한다.', ' #Person2#는 체크아웃하고 있습니다. #Person1#는 #Person2#에게 청구서를 제공하지만, #Person2#는 세탁 서비스 비용이 잘못 추가되었다고 생각합니다. #Person1#는 실수를 인정하고 청구서를 수정할 것입니다.', ' #Person1#은 스티븐에게 아내와의 불륜을 속이고 아내를 속이기 위해 도움을 청한다. 스티븐은 최선을 다하겠다고 약속한다.', ' #Person2#는 에이브러햄 링컨을 건전한 성격을 지닌 유명인사로 생각합니다. #Person2#는 링컨의 용기, 비전, 그리고 겸손함을 존경합니다.', ' #Person1#은 허베이에서 심각한 모래폭풍이 일어나고 있다고 #Person2#에게 말한다. 그들은 모래폭풍이 모두에게 문제가 되는 것 같다고 생각한다.', ' #Person2#는 프란시스의 생일 파티에 참석하고 그에게 리모컨 자동차 모델을 선물로 준다. 프란시스는 감사하고 동시에 #Person2#를 비판한다.', ' 토니는 부정행위를 하고 걸렸다. 그는 아버지가 그를 죽일 것이라고 생각하고 공부하지 않았다. 스티븐은 그가 실수에서 배우는 것이 충분하다고 생각한다.', ' #Person1#은 아홉시 반 기차를 타야 하지만 톰은 그렇지 않다고 생각한다.', ' #Person1#은 삶을 어떻게 조정해야 할지 모르겠다고 #Person2#에게 조언을 구합니다. #Person2#는 #Person1#에게 충분한 수면을 취하고 운동을 하며 미래를 걱정하지 않도록 조언합니다.', ' #Person1#은 #Person2#에게 루오지아가 어제 결혼했다고 말하고 오늘 밤 그녀의 집에서 파티에 가고 싶다고 말한다.', ' #Person1#은 친구들을 만들기 위해 몇몇 적들을 만들고 싶어하지만 #Person2#는 그것이 잔인하다고 생각한다.', ' 마이크는 자신이 누나와 비슷하다고 생각하지만 누나는 그녀만큼 똑똑하지 않다고 생각한다.', ' #Person1#은 머리가 아프고 어지러웠습니다. #Person2#은 #Person1#의 온도를 재고 다음에 부모님 중 한 분이 학교 사무실에 전화하게 할 것입니다.', ' #Person2#는 새로운 휴대폰을 사고 싶어합니다. #Person1#은 #Person2#에게 카메라와 MP3 플레이어가 있는 휴대폰을 추천합니다.', ' 프랭크는 우체국에서 일하게 되었다. 그는 그 일이 힘든 일이라고 생각하지만, 그 일은 훌륭한 건강보혜택을 제공하기 때문에 그것을 선택했다.', ' #Person2#는 컴퓨터 프로그램을 작성할 수 있고, 의사 면허와 운전 면허를 가지고 있습니다. #Person2#는 케임브리지 시험, 첫 번째 자격증, 영어 능력 인증서를 통과했습니다. #Person2#는 사무 기술에 대한 특별한 교육을 받았습니다. #Person2#는 이 직업에 적격하게 만드는 일을 해본 경험에 대해 이야기합니다.', ' #Person1#은 스테이크가 너무 익혀져 있고 좀 질겨서 #Person2#에게 바꾸어 달라고 요청합니다.', ' #Person1#은 톰에게 그의 소설이 노벨상을 받았다고 알려줍니다. 톰은 놀란 느낌을 느끼고 그것이 꿈같다고 생각합니다.', ' #Person2#는 자동차 디자인 전공과 과학 석사 학위를 가지고 있습니다. #Person2#는 학생 엔지니어로서 다양한 재료의 기계적 강도와 부식 저항성을 이해하는 업무를 담당했습니다.', ' #Person1#과 #Person2#는 술 마시는 습관에 대해 이야기합니다. #Person2#는 많은 양의 술을 마시고 돈을 절약하는 방법을 알고 있습니다. #Person1#은 맥주를 좋아하지만 내성을 키워야 합니다. 그들은 내일 같이 나가기로 합니다.', ' 엄마는 피크닉을 준비하고 메이에게 도움을 청하지만 메이는 다니엘의 도움을 거절한다.', ' 제임스와 뮤리엘은 새로운 계정에 대해 이야기하기 위해 만나고 있습니다. 그들은 휴가에 대해 이야기하고 타호에 대해 이야기합니다. 그들은 다시 가고 싶어합니다.', ' #Person1#은 돈을 인출하려 하지만 기계가 세계 야생동물 기금에 10000달러를 이체하려고 합니다. #Person1#은 기계에게 돈을 줘라고 요청하지만 기계는 위험 경보를 발송하고 문을 잠긴 후 도착할 때까지 기다리라고 합니다.', ' #Person2#는 사회적인 사람이며 동료들과 소통하는 전략은 진심이라고 생각합니다.', ' 폴리 씨는 끔찍한 일에서 벗어나고 싶어합니다. #Person1#은 폴리 씨에게 탄산 음료 한 병을 사달라고 제안하지만 그녀는 지갑에 달러가 네 개밖에 없습니다.', ' 프란시스와 모니카는 금요일 오후 1시부터 4시까지 재무 보고서를 읽기 위해 만날 예정입니다.', ' #Person1#과 #Person2#는 면접 수업에 참석하고 있습니다. 그들은 면접에서 중요한 것들에 대해 이야기합니다.', ' #Person1#은 캐릭터의 반응이 그녀의 반응에 맞지 않다고 생각하고, 그들은 다른 방식으로 시도해 볼 것이다.', ' #Person1#은 토드 부인에게 방문을 알리고 그녀의 가게에서 필요한 것이 있는지 묻습니다.', ' 빌은 이번 주에 매일 밤 10시쯤까지 일했습니다. 그의 동생은 미국에 있고 아직 돌아오지 않았습니다. 빌은 5시에 친구를 만나기로 했습니다.', ' 클레오는 핵무기 확산 막기 위한 시위에 참여하지 않고 싶어하지만 사이먼은 그렇게 하고 싶어한다. 사이먼은 클레오에게 시위가 평화로울 것이라고 말하지만 클레오는 그렇지 않다고 생각한다. 사이먼은 클레오에게 학생들에게 시위에 참여하도록 요청하도록 하지만 클레오는 거절한다.', ' #Person1#은 #Person2#가 예상하지 못한 사람을 절대로 들여보내면 안 돼 고 말합니다.', ' 마크는 매기의 노트를 빌리고 싶어하지만 그녀는 그것을 빌려주지 않습니다. 그들은 공부 파트너가 되고 도서관에서 공부하기로 합니다.', ' #Person2#는 터너 교수님의 고급 지질학 과목에 등록하고 싶어합니다. 터너 교수님은 #Person2#가 미국 서부의 지질학을 좋아하고 버먼 교수님의 강의를 쉽게 따랐다는 것을 알고 버먼 교수님에게 말하여 준비가 되었다고 생각하는지 묻을 것입니다.', ' #Person1#은 펜던트가 부러져서 새 것으로 교체하고 싶어합니다. #Person2#은 영수증을 가지고 10시까지 매장으로 오라고 합니다.', ' #Person1#은 선물을 어떻게 갖고 어떻게 바꿀지 결정하는지 #Person2#와 논의하고 있습니다. #Person2#는 경기를 보고 있고 #Person1#은 옷에 대해 이야기하고 있습니다. #Person2#는 #Person1#이 살즈베리 씰즈를 욕했다고 생각합니다.', ' #Person1#은 뉴스 디렉터가 되는 것을 제안하지만 #Person2#는 잡지를 위해 글을 쓰는 것을 선호하고 컴퓨터와 함께 일하는 것을 선호한다.', ' #Person1#과 #Person2#는 지루한 연설을 듣고 있습니다. #Person1#은 일간뉴스에서 일하고 있고 #Person2#는 음악을 들고 싶어합니다. #Person1#은 #Person2#에게 신문을 읽고 십자말풀이를 하라고 제안합니다.', ' 사라는 집을 사고 싶지만 돈이 없다. #Person1#은 그녀에게 더 저렴한 집을 찾는 방법을 제안하고 그 예를 들어준다.', ' #Person1#은 마크 리치를 소개하고 그의 직무와 일상 일정에 대해 묻습니다. 마크는 영국에 오는 사람들에게 어떤 제안을 하는지 알려줍니다.', ' 루시와 린팡은 다른 과목에 대한 각자의 좋아하는 순서를 공유한다. 그들은 낸시와 많이 다르다는 것을 알게 된다.', ' 제임스는 토마스 부인의 집안일을 도와주고 오스카를 산책시키는 것을 제안한다. 토마스 부인은 제임스에게 농구 연습을 위해 자전거를 사려고 하고, 그 후에도 계속 일하는 것을 제안한다.', ' #Person1#과 #Person2#는 봄이 오지만 밤에는 추워서 따뜻해지기 위해 에어컨을 켜야 한다고 생각합니다.', ' #Person1#은 캐릭터가 상처받고 슬퍼하는 것처럼 연기하는 것이 맞지 않다고 생각하지만, #Person2#는 그렇게 생각하지 않습니다. #Person1#은 자신의 방법으로 한 번 해보고 그 후에 다른 방법을 시도해 볼 것입니다.', ' #Person1#은 택시를 타고 프렌드십 호텔로 가고 있습니다. #Person2#은 속도를 높여 도착했습니다.', ' #Person1#은 과자를 사서 잔돈이 없어 다른 버스를 타야 합니다. #Person2#은 #Person1#에게 버스 기사에게 환승을 요청하라고 제안합니다.', ' #Person2#는 #Person1#에게 회사의 위치, 회사의 소유, 그리고 직원 식당의 위치를 알려줍니다.', ' #Person1#은 #Person2#에게 루루와 빅이 헤어졌다고 말한다.', ' 데이브가 짐에게 전화하지만 짐은 집에 없다. 샐리는 데이브에게 짐이 언제 돌아올지 알려준다.', ' #Person2#는 #Person1#에게 시청으로 가는 길을 알려줍니다. #Person1#는 다시 한번 묻고 이해합니다.', ' #Person1#은 여권을 분실했습니다. #Person2#은 신발 매장에 전화해 여권을 찾았는지 확인하지만 여전히 없습니다. #Person2#은 #Person1#에게 분실물 신고서를 작성하고 대사관에 연락하라고 제안합니다.', ' 레아는 콜린스 선생님이 다음 주에야 다시 전화할 수 있다고 나다니엘에게 전화한다. 나다니엘은 폰다 씨와 통화하고 싶어하지만 오늘 오전 11시 30분에 시간이 있다.', ' #Person1#과 #Person2#는 사라가 딕과 같은 남자에게 마음을 두었다는 것에 대해 이야기하고 있습니다.', ' #Person1#과 #Person2#는 파티에서 섹시한 여자들에 대해 이야기하고 있습니다. #Person2#는 금발 여자를 좋아하고, #Person1#은 제니스를 좋아합니다. #Person2#는 여자들과 말하는 것이 긴장되고 자신이 바보처럼 보일 것이라고 생각합니다. #Person1#은 #Person2#에게 제니스를 시도해보라고 제안하고, #Person2#는 다섯 명의 다른 남자들이 제니스를 노리고 있다고 말합니다.', ' 헤이와 잭은 이번 학기 수업에 대해 이야기한다. 잭은 작년에 수업을 들었던 비즈니스 커뮤니케이션 수업을 좋아했다.', ' #Person1#과 #Person2#는 베이징의 날씨에 대해 이야기하고 있습니다. 그들은 베이징의 가을이 아름답지만 여름은 더워서 옷을 더 챙겨 입는 것이 좋다고 생각합니다.', ' #Person1#은 오늘 밤에 #Person2#와 함께 영화를 보러 가자고 제안한다. #Person2#는 공포, 추리, 코미디, 러브 스토리, 전쟁 영화를 제안하지만 결국 전쟁 영화를 보기로 결정한다.', ' 아담은 #Person1#에게 학교의 건물들과 수영장에 대해 설명합니다. #Person1#은 언젠가 여기 학교에 입학하고 싶어합니다.', ' #Person1#은 #Person2#에게 그녀가 임신했다고 말한다. #Person2#는 그것이 행복하다고 생각한다.', ' #Person1#과 #Person2#는 존이 그녀에게 반한 것 같다고 생각합니다.', ' #Person1#은 #Person2#에게 소프트웨어와 하드웨어 업그레이드를 제안합니다. #Person2#는 그것이 좋다고 생각합니다.', ' #Person1#은 #Person2#에게 어디로 가고 있는지, 어디서 왔는지, 그리고 그들의 나이에 대해 묻습니다. 그들은 그들의 혈통과 스페인어 능력에 대해 이야기합니다.', ' #Person1#은 체중이 증가했습니다. #Person2#는 #Person1#에게 운동 수업에 가는 것을 제안합니다.', ' 제임스는 예약을 하고 왔습니다. #Person1#은 직원에게 제임스를 안내하도록 요청합니다.', ' #Person2#는 #Person1#에게 공장의 면적, 설립 시기, 직원 수, 그리고 공장의 주요 업무에 대해 알려줍니다.', ' 레베카는 #Person1#에게 그녀의 첫 직장에 대해 이야기합니다. 그녀는 처음에는 인턴으로 일하고 그 후에 지역 뉴스 기자로 일했습니다. 그녀는 2006년에 런던으로 이사하고 주간 런던에서 일하기 시작했습니다.', ' #Person1#과 #Person2#는 그룹 발표를 위해 포스터를 만들기 위해 필요한 물건을 사기 위해 쇼핑 목록을 만들고 있습니다. #Person1#은 원하는 물건을 찾는 것이 매우 쉽다고 생각하지만, #Person2#는 #Person1#이 근시라고 생각합니다.', ' 메리는 매일 인력시장에 가서 많은 에너지를 소비하고 있다. #Person1#은 인터넷에서 일자리를 찾는 것을 제안하고 메리에게 어떻게 하는지 알려준다. 메리는 시도해 볼 것이다.', ' #Person2#는 쇼핑 예산을 세우고 있습니다. #Person2#는 한 달에 $300만 쓸 수 있습니다. #Person1#는 #Person2#의 예산 계획이 좋다고 생각합니다.', ' 제인은 수잔을 방문하기 위해 병원으로 가고 있다. 헨리는 제인에게 13번 버스를 타는 것을 추천하지만, 그것은 시내 중심에서 출발하기 때문에 제인은 두 마일을 걸어야 한다.', ' #Person1#은 내년 판매 예측에 대해 #Person2#와 이야기하고 싶어합니다. 그들은 다음 주 화요일 오후 2시 30분에 만나기로 합니다.', ' #Person2#는 #Person1#에게 뉴욕에서 투어 가이드를 추천하고 그것이 무엇을 하는지 설명합니다.', ' #Person2#는 회사에 대해 알고 있는 것을 #Person1#에게 말하고 영업 부서에서 일하고 싶다고 말합니다. #Person2#는 현재 직장에서 벌고 있는 돈과 복리후생 혜택에 대해 이야기합니다. #Person1#는 회사의 시작 급여, 보너스, 보험, 그리고 건강보험에 대해 설명합니다.', ' #Person1#은 계약서를 서명하러 왔지만 계약서가 아직 완전히 준비되지 않았습니다. #Person2#은 오늘 저녁에 계약서를 작성하고 서명을 위해 복사본을 만들 것입니다.', ' #Person1#은 차량 사고로 인해 친구가 다쳤습니다. #Person2#은 구급차와 경찰을 불러줄 것입니다.', ' #Person2#는 #Person1#에게 학교 클리닉으로 가는 길을 알려줍니다.', ' #Person2#는 화물용 엘리베이터 소음에 몇 번이나 깨어났습니다. #Person1#는 사과하고 내일 방을 바꿔줄 것입니다.', ' #Person1#은 #Person2#를 베이징 호텔로 데려다주고 오늘 저녁 연회에 초대합니다. #Person2#는 관광을 원하는 경우 몇 가지 관광지를 준비해 줄 것입니다.', ' #Person1#은 길을 잃었습니다. #Person2#은 #Person1#에게 자신의 위치를 알려주고 리우 이창으로 가는 방법을 알려줍니다.', ' #Person2#의 컴퓨터가 잘 작동하지 않고 오늘 오후에 보고서를 완성해야 한다. #Person1#은 수리공에게 전화하는 것을 제안한다.', ' #Person2#는 어머니의 생일 선물로 시계를 사고 싶어합니다. #Person1#는 금 시계를 추천하고 #Person2#는 그것이 너무 화려하다고 생각합니다. 그들은 결국 그 시계를 선택합니다.', ' 피셔 씨와 로스 씨는 그들의 발표에 대해 이야기하고 있습니다. 그들은 발표의 시간과 날짜, 음식, 장비, 그리고 예상된 참석자 수에 대해 논의하고 있습니다.', ' #Person2#는 러시아와 캐나다의 주요 차이점을 #Person1#에게 알려줍니다. 그들은 러시아인들이 본성상 빠르게 움직이는 반면, 캐나다인들은 미국인들보다 더 여유롭다고 생각합니다.', ' #Person2#는 카리브해로 여행을 가려고 하고 인터넷에서 카리브해의 날씨 보고서를 읽었습니다. #Person1#는 작년에 카리브해를 방문했습니다.', ' #Person1#은 소풍 갈 때 과일을 가져가고 싶어합니다. #Person2#은 #Person1#에게 바나나와 포도를 가져가라고 제안합니다.', ' #Person1#은 소형차를 빌리고 싶어합니다. #Person2#은 비용과 운전 면허증을 요청합니다.', ' #Person1#은 미소를 짓는 사람들이 질렸다고 생각하지만, #Person2#은 그들이 #Person1#과 잘 지낸다면 그들의 미소를 보는 것을 좋아할 것이라고 생각합니다.', ' #Person1#과 #Person2#는 월리스가 회장이 된 이후 회사의 성과가 향상되었다고 생각합니다. 그들은 월리스의 기여와 새로운 마케팅 전략이 그들의 성공에 기여했다고 생각합니다.', ' #Person2#는 택시에서 가방을 잃어버렸고, #Person1#에게 돈을 빌려달라고 요청한다. #Person1#는 돈을 빌려주고 #Person2#를 집에 데려다 줄 것이다.', ' 린은 스티븐에게 베이징에서 먹은 식사를 칭찬하고 팁에 대해 이야기합니다. 린은 미터기에 나온 금액만 지불하는 택시 시스템과 호텔 짐꾼에게 팁을 주는 시스템에 대해 이야기합니다. 스티븐은 혁명이 일어날 것이라고 생각합니다.', ' 빌은 오늘 룸메이트에 대해 알아보았다. 그는 브레인 로커라는 사람이 그렇게 생겼다고 #Person1#에게 말했다.', ' 톰 윌슨은 신용카드로 4박 동안의 호텔 청구서를 지불하고 있습니다.', ' 샤워가 캐롤의 전화를 받고 파티에 대한 정보를 알려줍니다.', ' #Person1#은 #Person2#를 알고 있다고 생각하지만, #Person2#는 그렇지 않다고 말한다. #Person1#은 이전에 만난 적이 있다고 생각하지만, #Person2#는 그렇지 않다고 말한다.', ' #Person1#은 트럼프가 다시 대통령이 되는 것을 상상할 수 없다고 생각하지만, #Person2#는 트럼프에게 믿음밖에 없다. #Person1#은 바이든에게 투표할 것이다.', ' #Person2#는 #Person1#에게 ATM 사용법을 알려줍니다. #Person1#는 이를 감사합니다.', ' 수잔은 존에게 그녀의 비서에게 사무 절차에 대한 메모의 복사본을 달라고 요청했지만, 존은 그것을 찾지 못했다.', ' #Person1#은 릴리에게 이번 주말에 강가로 소풍에 참여하도록 초대한다.', ' #Person2#는 중국의 연회에 초대받았습니다. #Person2#는 중국 식사 도구에 익숙해지는 것이 어렵지 않다고 생각하지만, 테이블 에티켓에 대해 애매하다고 생각합니다. #Person1#는 #Person2#에게 젓가락을 밥그릇에 꽂아서는 안 된다고 말합니다.', ' 프랭크와 메리는 여가 시간에 무엇을 좋아하는지에 대해 이야기한다. 그들은 영화를 좋아하고 자주 영화관에 가지만 메리는 보통 무비 살롱에서 영화를 빌려 봐서 거기 회원이다.', ' #Person2#는 녹색당에 가입하고 싶지만 그들이 선거에서 이길 가능성이 없기 때문에 그렇지 않습니다. #Person2#는 작은 정치 단체와 압력 단체들이 큰 정치 당에 영향을 미칠 수 있다고 생각합니다.', ' #Person1#은 윌슨 씨에게 상품에서 실수를 한 것에 대해 사과하고 책임을 지겠다고 합니다. 윌슨 씨는 그것이 더 이상 일어나지 않을 것이라고 생각합니다.', ' #Person2#는 강도를 보았지만 그의 얼굴을 보지 못했습니다. #Person2#는 경찰서로 가서 추가 질문을 받을 수 있습니다.', ' #Person2#는 #Person1#에게 아빠와 엄마가 데이트를 하러 나가고 그들이 일주일에 한 번씩 데이트를 할 것이라고 말한다.', ' #Person1#은 새해 결심을 하고 캐롤에게 그것을 말했다. 캐롤은 그것을 믿지 않고 그들은 그냥 기다려볼 것이다.', ' 카렌은 비교문학 287 수업에 등록하려 했지만 수업이 가득 찼습니다. #Person1#은 카렌에게 비교문학 학생들을 위해 대학 컴퓨터 시스템이 추가 자리를 남겼다고 말하고, 카렌에게 특별 코드를 주어 수업에 들어갈 수 있게 합니다.', ' #Person1#은 비에 대해 #Person2#에게 묻고, 그들은 같은 방향으로 걸어갈 것입니다.', ' 잭은 데이지에게 그의 새 차가 그의 이전 차보다 빠르고 더 비싸다고 말한다. 그들은 그 차가 고무를 태울 수 있다고 생각한다.', ' #Person2#는 #Person1#에게 불이 밤 10시쯤에 발생했다고 말했다.', ' #Person2#는 현금으로 지불할 수 없어서 신용카드로 지불하고 있습니다. #Person1#는 영수증을 준 후 #Person2#에게 또 오라고 말합니다.', ' #Person2#는 #Person1#의 도움으로 차량을 세차하고 싶어합니다. #Person1#는 일반 세차 패키지를 추천하고 #Person2#는 그것을 선택합니다.', ' 해리는 올해 휴가 여행을 어디로 갈지 결정하지 못했습니다. 그는 바다를 통해 여행하는 것이 더 싸지만 시간이 오래 걸릴 수 있다고 생각합니다. 그의 아내는 여행 전에 개를 돌볼 사람, 집을 돌볼 사람, 정원을 돌볼 사람을 찾는 것에 대해 걱정하고 있습니다.', ' 존슨은 신규 회원인 #Person1#에게 트레이닝 카드를 발급하고 카드를 이용하여 기계를 어떻게 사용하는지 알려줍니다. 그들은 다음에 나머지 기계들을 함께 보기로 합니다. 그들은 자신의 한계를 알아내는 것이 중요하다는 것에 동의합니다.', ' #Person1#과 #Person2#는 일자리를 잃었다. 그들은 전기기사 프로그램에 지원하기로 결정했다.', ' #Person1#은 #Person2#에게 강아지들에게 밥을 주고 목욕을 시키고 동물병원 예약을 기억하도록 요청합니다.', ' #Person1#은 집주인에게 돈을 빌리기 위해 에이든에게 돈을 빌리려고 합니다. 에이든은 돈이 부족하지만 50달러를 빌려주고, 그들은 저녁 식사를 함께 하기로 합니다.', ' #Person2#는 자선 단체에서 일한 경험이 #Person2#의 사고 방식에 영향을 미쳤다고 말합니다.', ' #Person1#은 #Person2#에게 결정을 내릴 예정이며 그들은 전화나 이메일로 연락할 것입니다.', ' #Person2#는 #Person1#에게 무탄과 함께 베이징 오리구이를 추천합니다.', ' 안젤라는 댄에게 친구의 결혼식에 초대하고 메건을 초대하도록 댄에게 요청한다.', ' #Person1#과 #Person2#는 각자 다른 디저트를 시작하고 서로의 디저트를 먹어보기로 합니다. 그들은 그들의 디저트의 원산지에 대해 이야기합니다.', ' #Person1#은 스미스 씨에게 대학, 학문, 나이, 그리고 은행에서의 연봉에 대해 묻습니다.', ' #Person1#은 조카를 위해 바비 인형을 구매하고 현금으로 결제합니다.', ' #Person2#는 조던 스포츠 신발을 원합니다. #Person1#는 그것이 세일 중이라고 말합니다.', ' #Person1#은 길을 잃어버려 과학 박물관에 가는 길을 묻고 싶어합니다. #Person2#은 #Person1#에게 티켓 기계를 어떻게 사용하고 기차를 어떻게 타고 내리는지 알려줍니다.', ' 사이먼은 은퇴 후 가족과 여행을 즐겼다. 그는 단계적 은퇴라는 프로그램에 참여하고 있다. 이 프로그램은 회사가 임시 직원을 고용하는 대신 은퇴한 직원들이 접근할 수 있는 웹사이트에 채용 공고를 올리는 것이다. 사이먼은 이로써 회사가 유연성을 얻는다고 생각한다.', ' #Person1#은 로키에게 그녀의 타입의 여자를 찾으라고 제안하지만, 로키는 집에 있어서 요리하고 청소하는 여자를 선호한다. 그들은 그들의 완벽한 여자에 대한 생각에 대해 이야기한다. 그들은 그들의 타입이 다르다는 것을 알게 된다.', ' #Person1#과 #Person2#는 어제 밤의 폭풍에 대해 이야기하고 있습니다. 그들은 날씨가 좋지 않다고 생각하지만 3월은 좋았다고 생각합니다.', ' #Person1#은 집에 있는 것이 더 좋다고 생각하지만, #Person2#는 밖에 나가는 것이 더 좋다고 생각한다. 그들은 함께 음악을 할 것이다.', ' 벤은 새로운 학교 생활에 대해 떨어 있다. #Person1#은 벤에게 첫 수업이 몇 시에 시작하고 각 수업이 얼마나 걸리는지 알려준다. 벤은 점심시간에 배가 고프다고 생각하지만, #Person1#은 두 번째 수업 후에 뭔가 먹을 것을 사올 수 있다고 말한다.', ' 애덤은 무릎 상태가 좋아졌다. #Person1#은 애덤에게 미시간에 대한 소식과 토요일 경기에서 우리가 기대할 수 있는 것에 대해 알려준다. 그들은 그 후에 미시간의 영상을 보고 애덤의 무릎을 쉬게 할 것이다.', ' #Person1#은 #Person2#에게 프린터를 고치고 편집해달라고 요청합니다.', ' #Person1#은 커튼을 걸고 싶어하고, #Person2#는 도와주기로 합니다.', ' #Person1#은 잭에게 그의 일정을 묻고 그들은 다다음 주말에 캠핑을 계획하고 있습니다.', ' #Person1#은 화를 내어 #Person2#를 화났고, #Person2#는 북쪽에 큰 산불을 끄러 가야 했다. #Person1#은 임신했다는 것을 알게 되었지만, #Person2#는 아기가 자신의 아기가 아니라고 생각한다.', ' #Person2#는 딸이 대학을 결정하지 못하고 그녀와 의견이 다르다고 걱정하고 있습니다. #Person1#는 #Person2#에게 딸이 스스로 결정을 내릴 수 있다고 말합니다.', ' #Person1#은 실수로 직장을 잃을 것이 두려워 생계를 유지하지 못하게 될 것이라고 생각한다. #Person2#는 #Person1#에게 다른 직장을 찾을 때까지 #Person2#와 함께 살 수 있다고 제안한다. #Person1#은 절약하면서 살 수 있다고 생각한다.', ' #Person2#는 친구를 방문하고 있다. #Person2#는 그의 강연 주제를 #Person1#에게 알려주고, #Person1#는 그것이 복잡하다고 생각한다.', ' #Person2#는 아픈 것 같고 잠을 자고 싶어한다. #Person1#는 #Person2#를 위해 스프를 만들어 줄 것이다.', ' 파버 씨가 요크 호텔에 전화하여 3박 동안 더블 룸을 예약하고 그 가격을 알아봅니다.', ' #Person2#는 #Person1#에게 웨스트 더비에 있는 저렴한 단칸방을 추천하지만, #Person1#는 연립 주택에만 관심이 있습니다. #Person2#는 사우스 더비에 있는 친구의 전화번호를 #Person1#에게 알려줍니다.', ' #Person1#과 #Person2#는 누가 잘못했는지에 대해 논쟁하고 있다.', ' 달린은 댄에게 전화해 주문이 지연되었다고 말하고 스티브에게 전화해 그에게 알리기 위해 댄에게 스티브의 전화번호를 요청한다.', ' #Person2#는 워싱턴 포스트, 뉴욕 타임즈, 그리고 로스앤젤레스 타임즈의 창립 시기를 #Person1#에게 알려줍니다.', ' #Person2#는 첨부파일이 이메일 용량을 초과해서 이메일을 보낼 수 없다. #Person1#는 #Person2#에게 압축해서 보내라고 제안한다.', ' #Person1#은 #Person2#에게 주말 즐거웠었는지 묻고, 다음에 또 함께 머무르길 바랍니다.', ' #Person1#은 뭘 먹고 싶어하는지 모르고 있습니다. #Person2#는 판다 익스프레스에서 중국 음식을 사는 것을 제안합니다.', ' 메리는 톰에게 판매 직원 자리를 다른 사람에게 제공하기로 결정했다고 알렸다. 톰은 재고를 요청했다.', ' #Person1#은 #Person2#에게 전화를 끊으라고 경고합니다. #Person2#는 그렇지 않을 것입니다.', ' #Person2#는 음악 선생님이 되고 싶어합니다. #Person2#는 음악과 예술 분야의 학사와 석사 학위를 가지고 있습니다. #Person2#는 클래식 음악을 좋아하며, 학생들이 클래식 음악을 듣는 것이 스트레스를 줄이는 데 도움이 된다고 생각합니다. #Person1#는 #Person2#에게 인터넷에서 클래식 음악을 찾아보라고 제안합니다.', ' #Person2#는 미국인 여자를 만났고 그녀가 싱글이라는 것을 알게 되었습니다. #Person2#는 그녀를 저녁 식사에 초대하고 싶어하며, 그녀에게 전화해서 오늘 밤에 시간이 되는지 물어볼 것입니다.', ' #Person1#은 미렐라가 캘리포니아에서 일하는 방식에 영향을 받아 사무실에서 집처럼 편하게 지내고 있다고 생각한다. #Person2#는 미렐라가 캐주얼한 재킷과 바지를 입을 수 있다고 생각하지만, 경영진은 그녀에게 네 벌의 새로운 흰색 원피스를 줬다.', ' #Person2#는 자신만의 법률 사무소를 세우고 있습니다. #Person1#는 #Person2#에게 도움을 제안하고 성공을 기원합니다.', ' 케이트는 어젯밤에 피터가 어디 있었는지 묻고, 피터는 온라인에 있었다고 말한다.', ' #Person1#과 #Person2#는 배와 보트가 예전처럼 교통수단으로 중요하지 않다고 생각합니다. 그들은 배와 보트의 속도가 너무 느리게 느껴지기 때문이라고 생각합니다.', ' 패니는 악몽을 꿨고 엄마가 그녀를 깨웠다. 그녀는 미시간 대학교에 들어가는 것에 대해 걱정하고 있다. 앤디는 만약 그들이 패니를 받아주지 않는다면, 다른 학교가 패니를 받아줄 것이라고 생각한다.', ' #Person1#과 어니는 밴드를 시작하고 바닐라 아이스의 노래를 연주할 것이다.', ' #Person1#은 #Person2#에게 뉴올리언스 여행에 대해 묻고 그들은 저녁에 극장에 가기로 결정했다.', ' #Person1#은 신용카드로 옷을 구매하고 #Person2#의 도움으로 서명을 합니다.', ' #Person1#은 블레이크 씨에게 포스터 씨가 훈련 매뉴얼을 보내달라고 요청하였습니다. 블레이크 씨는 내일 오후에 그것을 포스터 씨에게 가져다 줄 것입니다.', ' 데이비드는 휴가 동안 롱아일랜드로 가서 형의 생일을 축하하고 관광을 할 예정입니다.', ' #Person1#은 파멜라를 만나기 위해 비행기를 타고 있습니다. #Person2#는 #Person1#이 없을 때 파멜라를 돌봐 줄 것입니다. #Person1#은 #Person2#에게 친구라고 생각하고 파멜라에게 편지를 쓸 것입니다.', ' #Person2#는 #Person1#에게 77번 거리로 가는 버스를 어떻게 타야 하는지 알려줍니다.', ' #Person1#과 #Person2#는 이슬람 순례자들이 메카로 가는 프로그램을 보고 있습니다. 그들은 사우디 정부가 사고 가능성을 줄이기 위해 순례자 수를 제한하려고 노력하고 있다고 생각합니다. 그들은 기독교 순례자들이 캔터베리로 가고, 루르드에 뭔가 마법 같은 것이 있다고 생각합니다.', ' #Person2#는 #Person1#에게 센트럴 백화점과 국립은행으로 가는 길을 알려줍니다.', ' #Person1#은 다음 주에 런던에 갈 예정이다. #Person1#은 기차를 타고 가고 싶지만 #Person2#는 차를 타고 가고 싶어한다. 그들은 고속버스를 타는 것에 대해 이야기한다.', ' 톰은 점심 식사에 대해 불평하고 캐서린은 집에서 싸온 점심을 먹었다고 말한다. 그들은 패스트푸드가 라이프 스타일이라고 생각하지만 미국인의 3분의 2는 그런 곳을 피한다는 것에 대해 이야기한다.', ' #Person2#는 #Person1#에게 레모네이드, 바비큐 윙, 베이비 백 립을 주문합니다.', ' #Person2#는 #Person1#에게 더블 치즈버거, 감자튀김, 그리고 펩시콜라를 주문합니다.', ' #Person1#은 아침 식사를 만들고 있다. #Person2#는 아침 식사를 만들 때 아빠가 엄마를 짜증났다고 말한다. #Person1#은 완숙 계란을 먹는 것을 싫어하고, #Person2#는 #Person1#이 가끔 까다론 있다고 생각한다.', ' #Person1#은 #Person2#에게 그랜드 호텔의 위치를 물어봅니다.', ' #Person1#은 #Person2#의 사진을 찍어 아이들에게 미국 경찰이 어떻게 생겼는지 보여주기 위해 합니다.', ' #Person2#는 내일 빈 방을 찾고 싶어합니다. #Person1#은 #Person2#에게 근처에 다른 호텔을 추천합니다.', ' #Person2#는 미국 학생 비자를 신청하고 있습니다. #Person2#는 비자 거절 이유와 대사관이 중국인들에게 더 엄격하는 이유에 대해 #Person1#에게 이야기합니다.', ' 앤은 삼-오에게 그들이 재미없었다고 말하고 두 번째 기회를 거절한다.', ' 메리는 온라인 쇼핑의 장점을 #Person1#에게 소개하고, 어떻게 결제하고 온라인에 물건이 많은지 알려줍니다.', ' #Person2#는 미국식 회계에 익숙하지 않지만 회계 과정의 기본적인 개념을 알고 있습니다.', ' 제인은 피터에게 그들이 여름에 시안에 갈 예정이라고 말한다. 피터는 관심이 있고 그들은 휴가 지역에 대해 이야기한다.', ' #Person2#는 딸에게 보여줄 로맨스 영화를 대여하려고 합니다. #Person1#는 #Person2#에게 멤버십 카드를 발급하고 대여료, 반납 시간, 그리고 연체료에 대해 알려줍니다.', ' #Person1#은 미스터 리의 소포를 찾고 있습니다. #Person2#는 #Person1#에게 책상 위에 두고 서명하라고 말합니다.', ' #Person2#는 #Person1#에게 비행기가 뜨지 않아 공항 호텔에서 밤을 보내라고 말합니다. #Person1#는 불을 켜놓지 않으면 잠을 자지 못하는 습관이 있습니다.', ' #Person1#은 지난주에 #Person2#에게 컴퓨터 문제를 해결해준 #Person2#에게 보답하고 싶어합니다. #Person2#는 식당을 찾아달라고 #Person1#에게 요청합니다.', ' #Person2#는 강의 때문에 불면증을 겪고 있다. #Person1#는 요가 수업, 이완 요법, 음악 듣기 등의 방법을 제안하여 #Person2#의 불안함을 해소하는 데 도움을 준다.', ' #Person1#은 주방을 새롭게 만들고 싶어하지만 #Person2#는 그것이 유행을 따라가는 것이라고 생각합니다.', ' 스털링과 월터는 우드 교수님이 뛰어난 과학자라고 생각하지만 정신이 좀 딴 데 팔려 있다고 생각한다.', ' #Person1#은 검사 결과를 받고 싶어합니다. #Person2#는 검사 결과가 명확하지 않아서 추가 검사를 하고 싶어합니다. #Person1#은 이것이 큰 문제라고 생각하지만, #Person2#는 긴장하지 말라고 말합니다.', ' 마틴은 엘리자 선생님에게 다가오는 시험 준비에 대해 이야기하고, 그의 문제를 해결하는 데 도움을 준 램 선생님에 대해 이야기합니다. 마틴은 학생 복지 클럽에 대해 불만 없습니다.', ' #Person1#은 소포를 한국에 보내고 싶어합니다. #Person2#은 패키지 우편을 추천하고 #Person1#은 그것을 선택합니다.', ' #Person1#은 휴대폰을 잃어버렸고 결혼식에 가야 한다. 린다는 여동생에게 휴대폰 잃어버렸다고 알리고 빵집에 전화할 것이다.', ' #Person1#은 로스앤젤레스 출신으로 여행 중입니다. #Person2#은 #Person1#에게 음료를 더 가져다 줄 것입니다.', ' #Person1#은 여름방학에 쉬고 싶어하지만, #Person2#는 앞으로 성공하고 싶어하고 미래에 대해 생각하고 있다.', ' #Person2#는 개가 자신을 쫓아가는 것을 피하려고 울타리를 뛰어넘었지만 나뭇가지에 부딪혔다.', ' #Person2#는 6년 전과 지금의 생각과 느낌을 비교하고, 회사의 벌, 기술 배우기, 그리고 여행 기회에 대해 #Person1#에게 이야기합니다.', ' #Person1#은 당좌예금 계좌를 개설하고 싶어합니다. #Person2#은 #Person1#에게 이자를 지급하지 않는 이유와 돈을 어떻게 인출하는지 알려줍니다.', ' #Person1#은 중국 요리를 먹고 싶어합니다. #Person2#은 맵고 맛있는 광동 요리를 추천하지만, #Person1#은 멀리 있는 곳을 선호하지 않습니다. #Person2#은 베이징 요리를 추천하고 가장 좋은 곳을 알려줍니다.', ' #Person2#는 #Person1#에게 어제 회의에서 배송 시간에 대해 논의했다고 말합니다. #Person1#는 그들이 오클랜드에 전화해 배송 시간을 정했다고 말합니다. 그들은 계약서를 작성하기로 합니다.', ' #Person1#은 독서등을 깨뜨렸습니다. #Person2#은 #Person1#에게 새 것을 가져다 줄 것입니다.', ' #Person1#은 2006년 회계 연도 마케팅 계획에 대해 이야기하고 있습니다. #Person2#는 그들이 설정한 몇 가지 목표를 기억하고 그들이 그들의 목표를 달성했는지 평가하기 위해 데이터를 보면서 고려해야 할 세 가지를 설명합니다.', ' #Person2#는 유럽을 여행할 계획이며, #Person1#는 #Person2#가 돌아오면 기념품을 사달라고 요청합니다.', ' 지미 폭스는 예약한 중형 차량을 받지 못하고 컴팩트를 받게 됩니다. #Person2#는 그에게 보험료와 대여료에 대한 할인을 제공합니다.', ' #Person1#은 엄마에게 카드 게임을 하도록 요청하지만 엄마는 아빠가 공부방에서 일하고 있기 때문에 거절한다.', ' 앤은 존스 씨에게 이번 주의 회의 시간과 런던에서의 회의 시간을 알려줍니다. 그녀는 또한 폰 씨가 존스 씨와 이야기하고 싶다고 말합니다.', ' #Person1#과 #Person2#는 지리적 특성만 보여주는 지도를 보고 있다. 그들은 수백만 년 동안의 화산 활동, 강이 깊은 계곡, 그랜드 캐년 같은 협곡, 그리고 바다와 풍경이 모두 우리의 기후에 영향을 미친다는 것에 대해 이야기한다.', ' #Person2#는 방에서 담배 냄새가 심해 방을 바꾸고 싶어합니다. #Person1#은 바로 금연 방을 준비해 줄 것입니다.', ' 빌은 젖은 페인트에 손대고 존 샘슨처럼 무심코 행동했다. 교장 선생님은 작업자들에게 공지를 가져오라고 요청했지만 그들은 젖은 시멘트를 잊고 공지를 붙이러 걸어가고 있다.', ' 벤은 엘라의 전화번호를 얻고 엘라에게 전화할 예정입니다.', ' 짐은 빌에게 걔가 아팠어 이탈리아에서 돌아온 후로 아팠어 지금은 좀 나아졌다고 말한다.', ' #Person2#는 최저임금으로 일하고 있지만 야근에 대한 보상을 받지 못하고 있다. #Person1#는 #Person2#의 권리를 알리고 고용주가 공정한 임금을 주도록 요구하는 법이 있다고 말한다. #Person2#는 다른 일자리를 찾지 못하고 있다.', ' 리사는 마크가 다른 여자와 사귀고 있다는 것을 알게 된다. 그녀는 마크에게 그녀가 그녀의 여동생인지 물어보고, 마크는 처음에는 거짓말을 하지만 결국 작은 실수를 인정한다. 리사는 마크에게 진실을 말하거나 그녀와의 관계를 끝내지 않으면 이혼하겠다고 말한다.', ' #Person2#는 의사의 조언에 따라 식단을 정리하고 다이어트에 들어가야 합니다.', ' #Person1#은 더 이상 #Person2#와 함께 있지 않고 싶어하고, #Person2#는 #Person1#을 떠나지 않도록 설득한다.', ' #Person2#는 #Person1#에게 도서관 이용 방법을 알려줍니다. #Person1#는 영어 회화에 관한 두 권의 책을 대출하려고 합니다.', ' #Person1#과 #Person2#는 좋은 날씨에 대해 이야기하고 이번 주말에 해변으로 가기로 결정했습니다.', ' #Person1#은 #Person2#의 카메라를 압수하고 나중에 돌려줄 것입니다. #Person2#는 슬라이드나 그림 엽서를 어디서 살 수 있는지 #Person1#에게 묻습니다.', ' #Person2#는 대출에 대한 정보를 얻고 싶어합니다. #Person1#는 대출 정책의 일반적인 조건을 소개하고 개인 정보, 과거 대출, 자산 및 신용 점수와 같은 기타 관련 정보를 평가하는 방법을 소개합니다. #Person2#는 돈이 그렇게 필요하지 않다고 생각하고 감사합니다.', ' #Person1#은 모니카의 발표에 대해 칭찬하고 그녀의 노력과 동료들의 도움에 대해 묻습니다. 모니카는 그녀가 이 일을 맡은 이유와 그녀가 이것을 해결할 수 있었던 이유에 대해 설명합니다.', ' 톰은 아침에 달리는 것을 좋아하지만, #Person1#은 점심시간에 달리는 것을 선호한다. 톰은 내일 6시 반쯤에 #Person1#을 찾아갈 것이다.', ' #Person2#는 #Person1#에게 일본 레스토랑의 주요 음식과 영업 시간을 알려줍니다.', ' #Person1#은 심슨 씨와 점심을 함께 하기 위해 그를 초대합니다.', ' #Person1#은 데이트를 위해 레스토랑을 찾고 있습니다. #Person2#은 그녀를 위해 그녀의 호텔의 레스토랑을 추천하지만, #Person1#은 다른 레스토랑을 원합니다. #Person2#은 그녀에게 테이블을 예약해 줄 것입니다.', ' #Person1#은 식사 비용을 지불하고 팁을 제공하지만 #Person2#은 거절합니다.', ' #Person1#과 #Person2#는 각자의 나라에서 인기 스포츠에 대해 이야기합니다. 그들은 골프, 익스트림 스포츠, 럭비, 테니스, 탁구, 수영 등에 대해 이야기합니다.', ' #Person2#는 헬싱키로 가는 비행기를 예약하고 싶어합니다. #Person1#는 가장 저렴한 비행기를 추천하고 그 비행기의 출발 시간과 도착 시간을 #Person2#에게 알려줍니다. #Person2#는 채식주의자 식사를 요청합니다.', ' #Person1#은 내일 할머니를 방문하기 위해 플로리다로 가고 있습니다.', ' #Person2#는 호주에 가고 싶어합니다. #Person1#은 #Person2#에게 호주의 물고기에 대해 이야기합니다.', ' 로라는 헬스장에 가고 있고, 그녀는 둘 다 건강과 외모를 위해 운동한다고 말한다. #Person1#은 걸기, 축구, 수영, 자전거 타기를 즐긴다. 그들은 언젠가 헬스장에 같이 가보기로 계획했다.', ' #Person2#는 시카고에서 태어나 윌메트에서 자랐습니다. #Person2#는 링컨 고등학교를 졸업하고 뮌헨에 살았습니다.', ' #Person1#은 새로운 정장을 샀다. #Person2#은 그것이 좋은 거래라고 생각하지 않는다.', ' 앤은 라디오 프로그램에서 로빈에게 산호수 자전거 투어에 대해 묻습니다. 로빈은 이것이 경주가 아니라고 말하고, 평균적인 사이클리스트들이 7시간에서 9시간이 걸리고, 좋은 사이클리스트들은 4시간 안에 완료할 수 있다고 말합니다. 로빈은 올해 1,200명의 사이클리스트가 참가하고, 분산 출발을 통해 도로를 막지 않을 것이라고 말합니다.', ' #Person1#은 #Person2#에게 컴파리를 젓는 걸로 주문하고 싱거를 추천합니다. #Person2#은 그것을 시도해 보고 맛있다고 생각합니다.', ' 에릭은 그레고리에게 점심을 제안하고 지난 주말에 번지 점프를 했다고 말한다. 그레고리는 번지 점프가 무서워서 하고 싶지 않다고 말하고 에릭이 자기 중심적이라고 생각한다. 그레고리는 에릭이 정신이 나간 것 같다고 생각하고 에릭은 지갑을 잃어버렸다고 말한다.', ' #Person1#은 노르망디 상륙작전에 대한 정보를 찾고 싶어합니다. #Person2#은 #Person1#에게 웹사이트를 추천하고 자세한 정보를 위해 역사 책을 읽는 것을 제안합니다.', ' #Person2#는 훈련을 시작하고 싶어합니다. #Person1#는 #Person2#에게 기계를 어떻게 사용하는지 알려주고 체형을 갖기 위해 무게를 줄이는 것을 제안합니다.', ' #Person2#는 #Person1#에게 캠퍼스 서쪽에 주차 구조물이 있다고 말하지만, 그것이 지금 가득 찼는지는 확신할 수 없다.', ' 수잔은 에밀리에게 급여 명세서의 각 부분을 설명하고 주 공제와 연방 공제를 구분해 줍니다. 에밀리는 그것이 영국에서도 똑같을 것이라고 생각하지만 그냥 별로 신경 쓰지 않았을 뿐이라고 말합니다.', ' #Person1#은 기계로 간식을 사고 싶어합니다. #Person2#은 #Person1#에게 돈을 넣고 선택을 하는 방법을 알려줍니다.', ' #Person2#는 겨울 휴가 동안 태국에 여자친구를 만나러 가고 있다. #Person1#는 그들이 빠른 시간 내에 서로를 알게 된 것에 놀란다.', ' 케이트는 돈을 모아 새로운 가구와 카펫을 사고 장식을 다시 했다. 제임스는 그것들을 칭찬하지만 카펫은 예전 것이라고 생각한다. 케이트는 그것이 새 것이라고 말한다.', ' #Person2#는 빌에게 하루 운동 스케줄을 알려줍니다. 빌은 그것이 어렵다고 생각하고 댄스 수업에 대해 불안해합니다.', ' 마르켓은 #Person1#에게 올해 졸업하기 위해 과학 과목을 수강하라고 제안한다. #Person1#은 지도학이 약하다고 말한다.', ' 팀은 프로젝트에서 친환경적인 삶을 어떻게 이끌어내는지에 대해 이야기한다. 팀은 자신의 삶에서 친환경적으로 어떻게 행동하는지, 그리고 학교에서 친환경적인 삶을 어떻게 이끌어내는지에 대해 이야기한다.', ' #Person1#은 크리스마스 때 쇼핑 센터의 장난감 부서에서 일하는 것이 불쾌하다고 토니에게 말한다.', ' 수는 빌의 케이크를 먹지 않는다. 빌은 수가 알레르기 반응을 피하기 위해 다이어트를 하고 있다는 것을 알게 된다. 빌은 수에게 샐러드와 수프를 제공하고, 수는 나중에 식당에 갈 것이다.', ' #Person2#는 여름 옷을 사고 싶어합니다. #Person1#는 20% 할인 중인 티셔츠와 어울리는 치마를 추천합니다. #Person2#는 그것을 좋아하고 구매합니다.', ' #Person1#은 예약을 하지만 재확인하지 않아 티켓을 찾으러 왔습니다. #Person2#은 다른 티켓을 찾아줄 것입니다.', ' #Person1#과 #Person2#는 부활절에 가족이 모인 점심 식사를 즐기고 있다.', ' #Person1#은 토니가 엄마를 걷어차자, 엄마를 때리자, 엄마가 싫어라고 말하는 등 나쁜 습관을 가지고 있다고 생각한다. #Person2#는 토니에게 인내심, 애정, 존중을 가지고 대하고 좋은 행동에 대한 보상을 주어 협력하도록 동기를 부여하는 것을 제안한다.', ' #Person1#은 #Person2#에게 친구들이 결혼하고 남자들만의 파티를 준비하고 있다고 말한다. #Person2#는 그것이 과하다고 생각하지만, 그들은 결국 동의한다.', ' #Person1#은 #Person2#에게 투표용지를 주고 투표 부스로 가서 투표하라고 말합니다.', ' #Person1#과 #Person2#는 회사가 인력을 줄일 것이라는 소문을 듣고 누가 해고될지 예상하고 있습니다. 그들은 조지, 앤디, 리사, 마이클, 그리고 그들 자신들이 아닌 누군가일 것이라고 생각합니다.', ' #Person1#과 #Person2#는 중국 TV 시리즈를 논의하고 있습니다. 그들은 이혼률이 계속 상승하고 있다는 것을 알고 있습니다. 그들은 독자 세대가 결혼에 대해 거의 알지 못하는 경향이 있다고 생각합니다.', ' 주디는 #Person1#에게 그들의 여행 예산을 보여주고 저렴한 호텔을 선택하는 것이 좋은 선택이라고 말한다.', ' #Person1#은 #Person2#에게 메리가 결혼했다고 말한다. #Person2#는 놀란다.', ' 헤이는 택시에 타고 있을 때 지갑을 잃어버렸다. #Person1#은 그에게 50달러를 빌려주고 책을 사러 가고 주유소에 갈 것이다.', ' #Person1#은 뉴스에서 머피 뮤직과 U-튠즈의 합병에 대한 소문을 읽었습니다. #Person2#는 그것이 소문일 뿐이라고 생각하지만, #Person1#은 그들이 치열한 경쟁을 계속하는 것보다 합병하는 것이 더 쉽다고 생각합니다.', ' 톰은 새로운 비서가 조에게 도움이 되지 않는다고 생각하지만, 조는 그렇게 생각하지 않습니다.', ' 사라는 회의에서 자신의 아이디어가 밥에 의해 방해되고 밥에게 동의하길 바란 사람들에 대해 화가 나 있다. #Person1#은 사라에게 짧고 간결하게 말하고 중요 포인트를 제기하는 것을 제안한다.', ' #Person1#과 #Person2#는 이슬람 프로그램을 보고 있습니다. 그들은 무슬림들이 하즈를 가는 이유와 사우디 정부가 사고 가능성을 줄이기 위해 순례자 수를 제한하려고 노력하는 것에 대해 이야기합니다. 그들은 영국, 프랑스, 그리고 사우디 아라비아에서 흔한 신앙 순례에 대해 이야기합니다.', ' 테드는 제니를 좋아하지만 그녀에게 고백하는 것을 두려워한다. 마이크는 테드에게 용기를 내고 제니에게 어떻게 느끼는지 말하라고 격려한다.', ' #Person2#는 화가 날 때 먼저 진정하고 음악을 듣는 것을 제안합니다. #Person1#는 그것이 효과가 있다고 생각합니다. #Person2#는 운동도 화를 풀기 좋은 방법이라고 생각합니다.', ' #Person2#는 #Person1#에게 삼촌 빌과 그의 아내와 두 딸에 대해 이야기한다. #Person2#는 그들이 내년에 유럽을 여행하며 그들을 방문할 것이라고 말한다.', ' #Person1#은 스튜어트 씨에게 도시 마라톤에서 우승했다고 축하하고, 그들은 그 경기를 봤다고 말합니다.', ' #Person2#는 아이들과 아내를 위한 선물을 고르고 있습니다. #Person1#는 멋진 운동화를 추천하고 아이들을 위해 5켤레를 사고 싶어합니다. #Person1#는 아내를 위한 선물로 DENY 브랜드의 향수를 추천하고 그것이 미국에서 비싸다고 말합니다. #Person2#는 그것이 가품이 아니라고 생각하고 하나를 사기로 합니다.', ' 홍은 #Person1#에게 현지 SIM 카드를 사서 영국에 전화를 걸 수 있게 도와줍니다.', ' #Person2#는 브라운 씨에게 월급과 휴가에 대해 묻습니다. 브라운 씨는 #Person2#에게 처음에는 한 달에 2,500 위안을 지급하고 매년 한 달 간 유급 휴가를 제공할 것이라고 말합니다.', ' #Person1#과 #Person2#는 배리와 폴의 차이점에 대해 이야기한다. 그들은 자신들이 낯을 가릴 때 어떻게 행동하는지에 대해 이야기한다. 그들은 금요일에 파티에 갈 것이다.', ' #Person1#은 집을 사고 싶어합니다. #Person2#는 #Person1#에게 지역, 크기, 학군, 그리고 호수 근처 집 대신 전망 있는 집을 원하는지 묻습니다.', ' 그랜트 씨는 샘플을 보고 결정을 내리기에 적절한 상황이 아닙니다. #Person2#는 그랜트 씨에게 다음 주에 연락하겠다고 합니다.', ' #Person2#는 #Person1#에게 서쪽으로 가는 268번 버스를 타고 Fair Oaks와 Washington에서 내린 후 261번 버스를 타는 것을 제안합니다.', ' 이 씨가 워드 여사님을 집까지 태워주고 우산을 들어줍니다.', ' #Person1#은 #Person2#의 상처를 살핔다. #Person2#는 오른팔이 아프다고 말하고, #Person1#은 #Person2#를 병원에 머무르게 하는 것을 제안한다.', ' #Person2#는 카드를 잃어버렸습니다. #Person1#는 #Person2#의 FRCM 일부 세부 사항을 받아서 도와줄 것입니다.', ' #Person1#은 잠을 자고 싶어하고 #Person2#는 저녁 식사를 준비하고 있다. #Person1#은 꿈을 꿀 것이 없고 #Person2#는 음식 요리하는 냄새를 맡을 것이다.', ' #Person1#은 #Person2#에게 중국 음식을 먹고 싶은지 물어보고 테이블을 내려주고 두유를 제공합니다. #Person2#는 고추장을 요청하고 고기의 종류를 물어봅니다.', ' #Person1#과 #Person2#는 줄을 서고 있습니다. 그들은 웨이터에게 원하는 것을 말하고 크림 케이크를 많이 먹을 것입니다.', ' 루시는 스탠리가 노래하는 것을 듣고 싶어하고, #Person1#은 그녀가 원하는 것을 충족시키기 위해 그에게 엘비스의 노래를 틀어달라고 요청한다.', ' #Person2#는 영화관이 사람들을 만나는 곳이 되어야 한다고 생각합니다.', ' #Person1#은 갈색 드레스를 추천하지만 #Person2#는 가벼운 것을 원합니다. #Person1#은 다양한 종류의 면 드레스를 추천하고 #Person2#는 흰색을 원합니다.', ' 조슈아는 아빠에게 돈을 요청하지만 아빠는 돈이 없다. 그들은 아빠의 비밀 돈통을 사용하고 그 돈을 어떻게 사용할지에 대해 논의한다.', ' #Person1#과 #Person2#는 내일 마이크의 파티에 갈 예정이다. #Person2#는 차로 가고 #Person1#은 #Person2#의 차에 타고 갈 것이다.', ' #Person1#은 소포를 우등 우편으로 보내고 싶어합니다. #Person2#은 #Person1#에게 보험과 우표를 어떻게 구입하는지 알려줍니다.', ' #Person1#과 #Person2#는 지진과 태풍에 대해 이야기하고 있습니다. 그들은 지진이 더 심각하다고 생각하며, 원춘 지진을 예로 들어 사람들이 그 당시 절대 손하나 까딱하지 않았다고 말합니다.', ' #Person1#은 장마를 견디기 힘들지만 #Person2#는 그런 날씨에 익숙하다.', ' #Person1#과 #Person2#는 배구 경기 후에 올림픽 기념품 가게에 가서 가족들에게 선물을 사기로 결정했습니다. 그들은 빨간색 마스코트 인형 세트를 사고 싶어하지만 할인을 받을 수 없습니다. 그들은 다른 기념품도 볼 예정입니다.', ' #Person1#은 팬을 사고 싶어합니다. #Person2#은 가벼운 알루미늄 팬을 추천하고 #Person1#은 현금으로 결제합니다.', ' #Person1#과 #Person2#는 일하러 돌아가고 있습니다. 그들은 같이 타고 가기로 했습니다.', ' #Person1#은 워싱턴의 공무원들이 자신들의 일을 즐기는 이유를 이해하고 있습니다. 베커 씨는 연방 직원들이 보람 있고 안정적인 경력이 될 수 있다고 말하고, 그들의 급여와 근로조건이 매력적이라고 말합니다.', ' 헨리 존슨은 피트에게 맥주를 마시고 노래방에 가자고 제안하지만, 피트는 노래방을 싫어하고 맥주를 좋아한다. 그들은 맥주를 마시고 바에 가기로 결정한다.', ' 줄리는 아픈 때 맛있는 식사를 먹었고 길거리 가게에서 프라이드 치킨을 먹었다. 그녀는 의사 선생님이 식중독이라고 생각하고 지금은 좀 나아진 것 같다고 말한다. 그녀는 반친구들이 노트를 가져다 주고 인터넷으로 생물학 수업을 다운로드 받을 수 있다고 말한다.', ' 엄마는 오늘 저녁에 친구들을 위해 음료와 과일을 준비하고 있다. 마이크는 친구들이 오기 전에 커피, 설탕, 사과를 사러 갈 것이다.', ' #Person1#은 베를린에서 베를린으로 오는 버스 여행이 불편하다고 생각하지만, #Person2#는 그것이 친환경적이라고 생각한다. #Person2#는 다음에는 비행기를 탈 것이다.', ' #Person2#는 이 일을 맡게 되면 주말에도 일해야 하고, 여행을 좋아하며 외국어를 할 줄 알고, 목소리가 맑고, 공개 연설을 잘한다.', ' 지미는 어제 저녁에 제니와 빌이 소풍에 초대해서 베이하이 공원에 갔다. 그들은 강가에서 점심을 먹고 산책하고 술을 마시고 친구들을 사귀었다. 지미는 책을 돌려주기 위해 에이미와 만날 예정이다.', ' 피터는 정원에 물을 주고 있습니다. #Person1#은 그것이 귀찮다고 생각하고 피터는 작년 여름에 비와 비와 같은 건조한 날씨를 기억합니다. 그들은 비가 오는 것에 대해 기쁘게 생각합니다.', ' 압니다는 비상 회의를 소집하고 켄에게 설명하라고 #Person2#에게 지시했습니다.', ' #Person2#는 편지를 등기로 보내고 싶어합니다. #Person1#는 #Person2#에게 등기와 당일 배송의 총 비용을 알려줍니다.', ' 의사는 스미스 씨에게 항생제와 크림을 처방하고 약국에서 약을 구입하라고 말합니다.', ' #Person2#는 중국의 예술과 공예품을 추천하고 싶어합니다. #Person1#는 종이절편, 자수, 바틱을 추천하고 #Person2#는 자수품을 보고 싶어합니다.', ' #Person1#은 에펠탑에 대해 #Person2#에게 소개합니다.', ' 브라이언은 영어를 할 줄 알고 미국에 3주 동안 있었습니다. 그는 아내와 함께 캘리포니아에 가본 적이 없고 라스베가스에 한 번 갔습니다.', ' #Person2#는 자신의 아들이 한 시간 전에 여기 있어야 했지만 아직 돌아오지 않았다고 걱정하고 있습니다. #Person1#는 그를 걱정하지 말라고 말합니다.', ' #Person1#은 그들이 하는 일에 문제가 있다고 생각하지만, #Person2#는 그렇게 생각하지 않습니다.', ' #Person1#과 #Person2#는 존이 그녀에게 반한 것 같다고 생각한다.', ' #Person1#과 #Person2#는 런던의 역사적 인물들에 대해 이야기합니다. 그들은 런던에서 역사적 인물들을 보기 위해 마담 투소의 밀랍 인형 박물관을 방문할 예정입니다.', ' 다니엘은 이번 학기에 과학을 가장 좋아하고 체육을 좋아한다고 말한다. 다니엘의 부모님은 다니엘이 장난꾸러기라고 생각하지만, 다니엘은 그렇지 않다고 생각한다.', ' #Person1#은 베이비 샤워에 참석하고 있습니다. #Person2#는 #Person1#에게 베티와 칼라가 준 선물을 보여줍니다. #Person1#은 방금 양수가 터진 것 같아 병원에 가야 합니다.', ' #Person1#은 중국에 관광하고 싶어하고 #Person2#를 초대하지만 #Person2#는 바빠서 동행할 수 없다.', ' 팀과 카렌은 다시 만나기를 기대하고 있다. 그들은 이야기를 마치고 팀은 가야 한다.', ' #Person2#는 마이클의 새로운 오토바이를 시도해보았지만 자전거를 사고 싶어합니다. 그 이유는 자전거가 더 안전하기 때문입니다.', ' #Person2#는 중국어, 영어, 프랑스어를 할 수 있습니다. #Person2#는 영어를 충분히 잘해서 영어권 국가 사람들과 의사소통이 가능하다고 생각합니다.', ' 낸시가 앤디의 전화를 받고 나오미에게 메시지를 전할 것이다.', ' #Person1#은 뉴욕행 비행기가 취소되어 다른 항공사로 예약하려 합니다. #Person2#은 줄을 서는 것을 제안하지만 #Person1#은 그것을 싫어합니다. #Person2#은 내일 비행기를 예약하고 50% 할인을 적용하는 것을 제안합니다.', ' #Person1#은 점심에 버거퀸에 가자고 제안하고 그들의 치즈버거, 바닐라 밀크쉐이크, 프렌치 프라이, 그리고 마요네즈 소스를 소개한다. #Person2#은 배가 고프다고 말하고 기다리기로 결정한다.', ' #Person1#은 #Person2#에게 초과 수하물 요금을 내고 취약한 물품 표시를 달라고 요청합니다.', ' #Person1#은 목이 말라 죽겠다. #Person2#은 #Person1#에게 탈수 상태일 때 물을 마시는 것을 제안한다.', ' 왕 묘는 그린 씨가 내일 오늘 해외로 가야 하므로 그린 씨가 량 씨에게 사과하고 다시 약속을 잡을 것이라고 전화했습니다.', ' #Person1#은 신발을 사고 있습니다. #Person2#은 신발이 사용하면서 약간 늘어납니다.', ' 벤자민은 프로젝트 보고서를 어떻게 써야 하는지 모르고 있다. #Person1#은 그에게 보고서의 형식과 내용에 대해 알려주고 마이크로소프트 워드를 어떻게 사용하는지 가르친다.', ' #Person2#는 피자 하우스에서 피자를 주문하고 얇은 도우로 해산물 피자 두 개를 주문합니다. #Person1#는 주소를 물어봅니다.', ' #Person1#은 새우 칵테일, 계란 수프, 양파 스테이크, 그리고 미네랄 워터를 주문합니다.', ' #Person1#은 #Person2#에게 집의 내부 모습에 대해 알려줍니다.', ' #Person2#는 구매한 스테레오에 대한 두 가지 문제를 #Person1#에게 알리고 다른 모델로 교환하도록 요청합니다. #Person1#는 그것이 가능하다고 말하지만, #Person2#는 영수증을 찾지 못하고 그것이 문제가 될 수 있다고 말합니다.', ' #Person1#은 내년 기숙사 보증금을 내고 캠퍼스 밖에서 살 생각을 하고 있다. #Person2#는 캠퍼스 밖에서 살 것이 비용이 더 들 것이라고 생각하지만, 도미토리가 시끄러워서 좀 더 생각해볼 것이다.', ' #Person1#은 오래된 어린이 이야기 책을 보고 있고, #Person2#는 그것이 가치가 있을 수 있다고 생각한다. #Person1#은 윌리엄 셰익스피어의 서명이 있는 것을 보고 그 서명이 누구의 것인지 알아볼 것이다. #Person1#은 그 책을 사서 도서관에서 그와 비슷한 이름을 찾아볼 것이다. #Person2#는 75센트짜리 이야기를 선호한다.', ' #Person2#는 주문을 하고 친구를 기다리기 위해 음식을 20분 후에 준비해 달라고 요청합니다.', ' #Person1#은 중요한 증명서를 보낼 수 있는 방법을 #Person2#에게 묻습니다. #Person2#은 공인 우편을 추천하고 시계의 보험을 묻습니다.', ' 샐리는 편지를 씻는 중이다. #Person1#은 편지를 읽고 톰에게 답장을 적어준다.', ' #Person1#은 컴퓨터로 과제를 하는 것이 어려워서 좌절감을 느끼고 있습니다. #Person2#는 스스로 컴퓨터를 구입할 수 있는 날을 기대하고 있습니다.', ' #Person1#과 #Person2#는 가을의 날씨에 대해 이야기하고 있습니다. 그들은 비가 올 것 같지만 소풍을 가기로 결정합니다.', ' #Person1#은 컴퓨터에 대한 일반적인 정보를 찾고 싶어합니다. #Person2#은 #Person1#에게 잡지를 어떻게 찾는지 보여줍니다.', ' #Person2#는 프렌치 가든 레스토랑에 왔습니다. #Person3#는 #Person2#에게 주스와 수프를 주문하도록 도와줍니다.', ' #Person1#은 #Person2#에게 레모네이드, 바비큐 윙, 베이비 백 립을 주문하도록 도와줍니다.', ' #Person2#는 저녁식사와 함께 커피를 주문하고 디저트 주문은 나중에 하겠다고 #Person1#에게 말합니다.', ' #Person1#과 #Person2#는 로또에 당첨되면 어떻게 할 것인지, 에릭이 데이트를 제안하면 어떻게 대답할 것인지, 그리고 엄마에게 결혼하려고 한다고 말하면 어떻게 반응할 것인지에 대해 논의한다.', ' #Person1#은 새로 태어난 강아지의 사진을 잭에게 보여줍니다.', ' #Person1#은 제인 이모가 톰에게 새 자전거를 사줬다고 #Person2#에게 말한다. #Person2#는 톰이 #Person1#보다 예의 바르다고 생각하지만, #Person1#은 톰이 더 빠르다고 생각한다. #Person1#은 언젠가 #Person2#에게 비행기를 사줄 것이다.', ' #Person2#는 최신 치마를 입어보고 그것이 비싸다고 생각합니다.', ' #Person2#는 #Person1#에게 #Person2#의 도시가 200년 전 작은 마을이었지만 석탄 발견으로 주요 산업 중심지로 성장했다고 말합니다. 그 마을의 몇몇 건물들이 아직도 남아 있고, 성이 있었기 때문에 도시에도 성이 있습니다.', ' #Person1#과 #Person2#는 세계의 환경 문제에 대해 이야기합니다. 그들은 대기 오염, 열대우림의 파괴, 사막화 문제, 그리고 사람들 사이의 갈등에 대해 이야기합니다. 그들은 환경 보호에 헌신하는 조직에 가입하는 것에 대해 생각하고 있습니다.', ' 데니스는 채팅방에서 사람들과 많은 시간을 보내고 있습니다. 그녀는 어제 100명이 넘는 사람들이 그녀와 얘기하고 싶어했습니다. 그녀는 그들이 그녀를 이상적인 여성으로 생각하기 때문에 그녀를 사귀고 싶어한다고 생각합니다. 그녀는 금요일 밤에 새로운 온라인 친구와 만나기로 했습니다. 데니스는 그녀의 친구의 조언을 구하고 있습니다.', ' 네이선은 엄마에게 시카고로 연습하러 갈 예정이라고 말한다. 엄마는 네이선이 큰 도시에서 어떻게 할 것 같은지, 그리고 그가 무엇을 할 것 같은지 묻는다. 네이선은 그들이 능숙한 사람을 찾고 있다고 말하고, 그들이 그의 정규 작가를 알고 있다고 말한다. 엄마는 네이선이 직장에서의 훈련을 받을 수 있을 것이라고 생각한다.', ' #Person2#는 3일 동안 차를 빌리고 싶어합니다. #Person1#는 #Person2#에게 차의 색상을 선택하도록 요청하고 신분증을 보여주도록 요청합니다.', ' #Person2#는 #Person1#에게 뉴욕에서 볼 것과 뉴욕의 대학교에 대해 알려줍니다. #Person2#는 지도를 가지고 있고 관광객 안내소에서 더 많은 정보를 얻을 수 있다고 제안합니다.', ' #Person2#는 #Person1#의 필름을 현상해 줄 것입니다. #Person1#는 내일 다시 올 예정입니다.', ' #Person1#은 비행기 지연 사유와 지연 정도에 대해 #Person2#에게 묻습니다. #Person2#은 날씨가 변덕스럽다고 말하고, #Person1#에게 최근 비행 안내 방송을 꼭 들어보라고 제안합니다.', ' #Person2#는 #Person1#에게 베이징 대학교로 가는 길을 알려주지 못하고 경찰관에게 물어보라고 제안한다.', ' #Person1#과 #Person2#는 신문을 읽고 있습니다. 그들은 범인을 찾지 못했고, 오늘은 맑고 따뜻하고, 내일은 흐리고 비가 올 것입니다.', ' #Person1#은 컴퓨터 게임을 싫어하지만 #Person2#은 그것이 괜찮다고 생각한다.', ' 짐은 맥주를 마시는 것이 건강에 좋지 않다고 생각하고, 그들은 운동장에 가서 노래를 부르고 친구들을 만나는 것을 제안한다. 그들은 메리와 샐리와 함께 춤을 추러 가기로 결정한다.', ' #Person1#과 #Person2#는 닭발과 하우스 레드 와인을 주문했다.', ' #Person2#는 지난 겨울 방학에 미국에서 온 몇몇 외국인 관광객 그룹을 안내했습니다.', ' #Person1#은 잭의 예약을 확인하고 양식을 채워달라고 요청합니다.', ' 질이 마크에게 전화를 걸어 오늘 왜 그녀가 오지 않았는지 설명한다. 그녀는 또한 수염이 아내와 딸이 잘 지내고 있다고 말했다고 말한다. 그들은 내일 다시 술을 마시기로 계획했다.', ' #Person1#은 #Person2#에게 놀러 가자고 제안하지만, #Person2#는 남편이 좋아하지 않을 것 같다고 생각하고 거절한다.', ' #Person1#과 #Person2#는 볼티모어와 필라델피아 사이의 야구 경기를 보고 있습니다. 그들은 여기 팬들이 좋다고 생각하며, 미국인들이 야구를 왜 좋아하는지를 상기시킵니다.', ' #Person1#은 #Person2#에게 도움을 주고 친구 같다고 말합니다.', ' #Person2#는 #Person1#에게 #Person2#의 나라의 천연자원 수출과 수입에 대해 이야기합니다. #Person2#는 정부가 장기 프로젝트에 돈을 투자하는 것이 돈을 잘 쓰는 것이라고 생각합니다.', ' #Person1#은 예술 갤러리를 방문하는 것을 좋아하고 추상 예술을 좋아합니다. #Person2#은 예술 전시회에 가는 것을 좋아하지 않지만 고대 로마나 그리스의 조각을 좋아합니다. 그들은 내일 국립 갤러리에서 그리스와 로마 조각의 전시회를 보기 위해 만날 예정입니다.', ' #Person2#는 책을 반납하고 비디오를 대출하고 싶어합니다. #Person1#는 #Person2#에게 비디오를 잘 관리하도록 요청합니다.', ' #Person1#은 #Person2#에게 볼링 게임의 규칙을 소개하고 게임하면서 더 알려줄 것이라고 말합니다.', ' #Person2#는 전단지에서 새로운 서비스에 대해 읽었습니다. #Person1#는 이 서비스에 대해 자세히 설명하고, 고객이 지점에 직접 방문하지 않고 전화로 상담 서비스를 이용할 수 있다고 말합니다.', ' #Person1#은 짐을 둘 곳이 필요하지만 #Person2#는 보증금을 남겨야 한다고 말합니다. #Person1#은 생각하고 있습니다.', ' #Person2#는 파티에 어른 두 명과 아이 한 명을 데리고 갈 예정입니다. #Person1#은 #Person2#에게 뷔페 가격과 음료 추가 요금에 대해 알려줍니다.', ' #Person2#는 해외에서 공부하기 위해 대출을 받고 싶어합니다. #Person1#는 대출자의 정책과 나이 제한에 대해 #Person2#에게 알려줍니다.', ' #Person2#는 #Person1#에게 영어 노래를 찾는 데 몇 분 더 걸릴 것이라고 말합니다.', ' #Person1#은 #Person2#의 글쓰기 경험에 대해 묻고 있습니다.', ' #Person1#은 면접 결과를 물어보는 것이 최선이라고 생각하고, 잭은 문의서를 작성하고 답변을 놓치지 않도록 주의하는 것이 좋다고 생각한다.', ' #Person2#는 #Person1#에게 집의 마당과 나무에 매달린 옥수수 이삭을 보여줍니다. #Person1#는 이것이 집의 풍요로움을 보여줄 수 있다고 생각합니다.', ' #Person1#은 뉴욕에서의 하루가 거의 시작되지 않았습니다. #Person2#은 #Person1#의 수하물을 보관하기 위해 보증금을 납부하고 신용카드를 제공하라고 제안합니다. #Person1#은 잠시 생각해볼 것입니다.', ' 브랜든은 헤이에게 무료로 글쓰기 기술을 향상시키는 새로운 웹사이트를 알려줍니다. 헤이는 신용카드 정보를 요청하는 것과 영어가 엉망인 것을 발견하고 이것이 사기라고 생각합니다. 브랜든은 헤이가 이해하지 못한다고 생각하고 웹사이트를 계속 사용하려고 합니다.', ' #Person1#과 #Person2#는 교장이 새로운 실험실 건물을 지을 것이라고 생각하지만 돈이 문제라고 생각합니다. 그들은 교장이 지방 정부에게 도움을 청할 것이라고 믿습니다.', ' 케이트는 신용카드로 저녁 식사용 소고기를 사고 있습니다. 헨리는 그녀에게 카드로 얼마나 쓸 수 있는지 알려줍니다.', ' #Person1#은 스미스씨에게 내일의 마을 방문에 대해 알리고, 그들은 산악 지역의 마을을 방문하기로 결정했습니다.', ' 벳은 아기를 가지고 있기 때문에 스트레스와 우울증을 다루는 방법이 변했습니다. 그녀는 아기를 가지는 것 중에서 가장 좋아하는 부분은 아기가 그녀를 존경하는 것입니다. 벳은 변호사가 되고 싶고 유타를 떠나고 싶어합니다. 그녀는 춤과 노래를 계속하고 싶고 아기를 위해 가족의 전통을 유지하고 싶어합니다. 벳은 청소년들에게 천천히 자라고 조언합니다.', ' #Person2#는 9년 동안 우표 수집을 즐겼다. #Person2#는 처음 발행된 우표에 퀸 빅토리아의 사진이 그려져 있다고 말한다. #Person1#는 우표 수집이 부자들이 모두 즐길 수 없는 큰 즐거움을 드릴 수 있다고 생각한다.', ' 톰은 친환경 제품을 판매하는 회사의 관리자로서 자신만의 회사를 가지고 싶어했습니다. 그는 웹 디자인 회사를 시작하고 그 경험을 친환경 회사에 적용했습니다. 톰은 그의 생활에서 친환경적인 부분과 그의 실수에 대해 이야기합니다.', ' #Person1#과 #Person2#는 술집을 나온 후 죽은 남자의 사건에 대해 이야기하고 있습니다. 그들은 그의 죽음 시간, 사망 원인, 그리고 그가 술집을 나온 후 그 지역에 있던 다른 사람들에 대해 이야기합니다.', ' 친구의 결혼식을 위해 친구의 집을 방문하기 위해 친구는 퀘벡 주를 방문할 예정이다. 밥은 친구에게 몬트리올과 퀘벡 시의 어떤 장점이 있는지 알려준다.', ' 제인은 논문 마감 때문에 수영을 할 수 없다. 톰은 저녁 식사 후에 그릴에서 제인과 함께 있고 그릴에서 제인을 집으로 데려다 줄 것이다. 제인은 먼저 집에 가고 그릴에서 만날 예정이다.', ' #Person1#은 아직도 통증이 있고, #Person2#는 그것이 #Person1#이 약을 제대로 복용하지 않았기 때문일 수 있다고 생각한다.', ' #Person1#은 휴대폰이 먹통이 됐고 프레드에게 돈을 빌려달라고 요청한다. 프레드는 동의하고 그들은 조금씩 돈을 모으기로 한다.', ' #Person1#은 글씨를 개선하고 싶어하지만 아무런 변화가 없어서 좌절하고 있습니다. #Person2#은 #Person1#에게 인내심을 가지고 계속 노력하라고 격려합니다.', ' #Person1#은 #Person2#가 속눈썹을 집는 것이 원시적인 고문 방법 같다고 생각한다. #Person2#는 그것이 속눈썹을 위로 뻗게 하는 것이라고 말한다.', ' #Person2#는 주말 운전 수업에 대해 #Person1#에게 묻습니다. #Person1#는 수업 시간, 코치, 그리고 연수용 차량에 대해 #Person2#에게 알려줍니다.', ' 티나는 8년 동안 피아노를 배웠고 아직도 그녀의 선생님에게 배우고 있습니다. #Person1#은 그녀의 선생님에게 배우고 싶어합니다. 티나는 #Person1#을 그녀의 선생님에게 소개할 것입니다.', ' #Person2#는 개인적으로도 단체에서도 잘 일하며, 처음에는 긴장하고 자신감이 없을 수 있다고 말합니다. #Person2#는 5년 후에 안정적인 소득을 가진 결혼하고 일에 능숙해질 것이라고 생각합니다. #Person1#는 #Person2#가 우리가 찾고 있는 사람일 수 있다고 생각합니다.', ' 스테파니는 잠을 못 자고 피곤하다. 젠킨스 선생님이 보고서를 제출하라고 하지만 그녀는 아직 그렇지 않다. 조지는 젠킨스 선생님에게 그녀가 금요일 아침에 제출할 수 있게 해달라고 부탁할 것이다.', ' 데이비드는 뉴욕에 있고 싶어하지만 그의 아빠는 그들을 이 시골 호텔에 보내고 싶어한다.', ' 밥은 친구를 만나러 갔고 댄스 파티에 갔다. #Person1#은 집에 있었고 테니스를 쳤다. 그들은 이번 주말에 게임을 할 예정이다.', ' #Person1#은 일자리를 찾고 있지만 아버지 농장에서 일하는 것을 싫어한다. #Person2#은 #Person1#에게 50달러를 빌려주고 행운을 빕니다.', ' #Person1#은 회의 시간을 미루어 #Person2#가 재킷과 넥타이를 가져올 수 있도록 합니다. #Person2#는 회의에 15명이 참석할 예정입니다.', ' #Person2#는 #Person1#에게 어린 아이들이 휴가 캠프를 즐겼다고 말합니다. #Person2#는 그들이 여행, 홀리로드, 성을 방문하고 운동 활동을 했다고 말합니다. 그들은 마지막 날에 바베큐 파티를 했습니다.', ' #Person1#은 아빠가 컴퓨터 프로그래밍 쪽으로 진출하려고 하고 그 이유는 사업을 시작하기 위함이라고 생각한다.', ' 칼리나는 어제 차를 나무에 박아서 몇 일 동안 학교를 쉬게 될 것입니다. 그녀는 클라크 교수에게 전화로 알려줍니다.', ' #Person2#는 집주인과 수리 비용에 대해 합의를 이루지 못하고 있습니다. #Person2#는 집주인에게 놀랄만한 파티를 열었지만 사람들이 실수로 거실 창문을 깨뜨렸습니다. #Person2#는 수리 비용을 제외하고 집에 대한 돈을 집주인에게 보냈지만 집주인은 수리 비용을 지불하지 않겠다고 했습니다.', ' #Person2#는 사유리 베드에서 온 L / C를 원합니다. #Person1#는 #Person2#에게 서명만 하도록 요청합니다.', ' 미르달은 잃어버린 지갑을 찾기 위해 잃어버린 지갑을 찾기 위해 핫도그 판매대로 가고 있다.', ' #Person1#은 설거지를 하고 있습니다. #Person2#은 #Person1#이 잘 하고 있다고 생각하지만, 그들은 번갈아서 설거지를 하기로 합의했습니다.', ' #Person1#은 그들의 관계에 대해 이야기하고 싶어하지만 #Person2#는 그것에 대해 묻지 않는다. #Person1#은 그들이 이제 끝났을 것이라고 생각하지만 #Person2#는 그들이 사랑하고 있다고 말한다.', ' #Person1#과 #Person2#는 정부가 사회 문제를 효율적으로 다루는 것이 어렵다고 생각합니다.', ' #Person1#은 파티에 어떤 복장을 입을지 #Person2#에게 묻습니다. #Person2#는 카우걸 복장을 제안하고 그것을 어디서 구할 수 있는지 알고 있습니다.', ' #Person1#과 #Person2#는 베이징의 야간 생활에 대해 이야기하고 있습니다. 그들은 댄스홀에 가서 빠른 음악에 맞춰 춤추고 왈츠를 춘 후 음료를 가져다 놓습니다.', ' #Person1#은 사무실에서 일하는 것에 지움이 있고 농장을 가지고 싶어한다. #Person2#은 #Person1#이 농장에서 일하며 휴가를 보내는 것이 좋을 것이라고 생각한다.', ' #Person1#은 헤이 맨에게 하이네켄 한 파인트와 버드 반 파인트, 그리고 애피타이저를 주문했습니다.', ' 메리는 앤과의 싸움에 대해 #Person1#에게 이야기한다. 메리는 앤이 남자친구를 따라하는 것에 대해 화가 났다. #Person1#은 메리에게 앤이 아마 메리만큼 기분이 나쁘다고 말한다. #Person1#은 메리에게 앤과 화해하라고 제안한다.', ' #Person2#는 #Person1#에게 담배와 기념품을 구입하는 방법, 그리고 남자 화장실의 위치를 알려줍니다.', ' 톰과 캐서린은 패스트푸드 네이션에 대해 이야기하고 있습니다. 캐서린은 패스트푸드가 편리함을 갈망하는 라이프스타일이라고 생각하지만 톰은 패스트푸드 레스토랑에서 건강한 메뉴 옵션이 있다고 생각합니다. 그들은 미국인들이 패스트푸드를 최대한 활용하는 방법을 찾아야 한다고 생각합니다.', ' #Person1#은 #Person2#에게 버스에 탑승하고 그것이 워싱턴 스퀘어 파크로 가는 올바른 버스라고 말합니다. #Person2#는 #Person1#에게 도착할 때 알려달라고 요청합니다.', ' #Person1#과 #Person2#는 9-11 테러 공격 당시 자신들의 위치와 그들의 가족 사람들의 위치에 대해 이야기합니다. #Person1#은 그날 삼촌이 사망했다고 말합니다. #Person2#는 테러 행위가 고의적이고 치명적이며, 모든 삶의 영역에 영향을 미칠 수 있다고 생각합니다.', ' 칼과 그의 아내는 시카고에서 이웃들과 친해지지 않았기 때문에 미네소타로 이사 왔습니다.', ' #Person2#는 #Person1#에게 완전히 삶은 계란, 진한 토스트, 그리고 나중에 오렌지 주스를 주문합니다.', ' 스티븐은 가계 예산을 살펴보고 있고, #Person1#은 피곤하다. 스티븐은 자기 전에 문을 닫고 개를 밖에 두기로 했다.', ' #Person1#은 제인과 다음 주 월요일 오후 세 시쯤에 만나서 몇 가지 아이디어를 논의하기로 했다.', ' #Person2#는 제시에게 선물을 사고 싶어합니다. #Person1#는 아메시스트 팔찌를 추천하지만 #Person2#는 더 섬세한 것을 원합니다. #Person2#는 제시에게 결혼을 제안하고 싶어합니다. #Person1#는 약혼 반지를 추천합니다.', ' #Person1#은 새 차를 사고 싶어합니다. #Person2#는 포드 포커스를 추천하고 그것의 특징과 가격을 #Person1#에게 알려줍니다. #Person1#은 그것을 좋아하고 시승해보고 싶어합니다.', ' #Person1#은 발람에게 컴퓨터 엔지니어 직위를 제안하고 월급을 논의합니다. 발람은 가족을 부양하기 위해 월급을 4,000 위안으로 요구하고, #Person1#은 동의합니다.', ' #Person1#은 #Person2#에게 계약의 혜택에 대해 설명하고, 그들은 내일 오전 10시에 모든 서류 작업을 마치는 것을 계획하고 있습니다.', ' #Person1#은 저녁 식사 후에 배가 고프다. #Person2#는 #Person1#에게 샌드위치를 만들어 먹으라고 제안한다.', ' #Person2#는 #Person1#의 백혈구 수치를 확인하기 위해 피를 뽑고 있습니다. #Person1#는 그것이 아프다고 생각합니다.', ' 스티븐이 셀러 씨에게 전기가 나갔다고 전화합니다. 셀러 씨는 스티븐에게 퓨즈를 교체하는 방법을 알려줍니다.', ' 파울라는 코너스 씨가 식기세척기 수리 비용을 임대료에서 차감하고 그녀를 퇴거시키려고 한다고 말합니다. 파울라는 내일 밤 8시에 코너스 씨와 만나기로 했습니다. #Person2#는 파울라를 위해 도움을 줄 것입니다.', ' #Person1#과 #Person2#는 수리공에게 에어컨, 변기, 차단기, 배수로 등의 수리를 요청하고 있습니다.', ' #Person1#과 #Person2#는 일자리를 찾고 있다. 그들은 전기기사 수습생 프로그램에 대해 이야기한다.', ' #Person2#는 #Person1#에게 그들과 사장님의 업무 관계와 그의 장점에 대해 이야기합니다.', ' 핑 씨는 투어 가이드 자격증을 가지고 있습니다. 그는 청소년국제여행사에서 일하고 있습니다.', ' #Person2#는 시계를 보고 싶어합니다. #Person1#는 가격을 알려주고 #Person2#는 그것이 비싸다고 생각합니다. #Person1#는 그것이 싸게 판매되고 있다고 말합니다.', ' 톰이 사라에게 전화를 걸어 마리아가 고열이 나서 병원에 데려가야 하므로 켄을 돌봐달라고 요청한다. 사라는 동의하고 켄을 자신의 집으로 데려가 저녁을 같이 먹을 것이다.', ' 에이미는 #Person1#에게 그녀의 첫 직장에 대해 이야기합니다. 그녀는 그곳에서 1년 동안 일했습니다.', ' 앤드류는 크리스마스 때 앤드류를 본 이후로 앤드류가 많이 살이 찐 것 같다고 생각한다. 앤드류는 그런 다음 앤드류에게 그가 와푸 다이어트를 하고 있다고 말한다. 앤드류는 앤드류에게 더 적은 양을 먹고, 아침 식사를 먹고, 밤늦게 먹지 않고, 패스트푸드를 끊고, 설탕을 줄이고, 물을 마시는 것을 제안한다.', ' 그렉 손더스는 메리에게 전화를 걸어 그녀의 성적 평균, 시험 점수, 그리고 스포츠에 대한 관심을 묻습니다. 그렉은 메리에게 그녀의 결과를 알려줄 것입니다.', ' #Person1#은 택시를 타고 기차역으로 가고 있습니다. #Person2#은 출퇴근 시간이라 길이 많이 막힌다고 말합니다.', ' 브라이언은 영어를 할 줄 알고 미국에 3주 동안 있었습니다. 그는 아내와 함께 캘리포니아에 가본 적이 없고 라스베가스에 한 번 갔습니다.', ' #Person2#는 새로운 건강보험에 가입하기 위해 건강검진을 받으러 왔습니다. #Person1#는 #Person2#에게 폐, 심장, 혈액 수치, 눈, 귀, 코를 확인하고 알레르기 검사를 하고 나중에 천식 검사를 받으러 보내줄 것입니다.', ' #Person1#과 #Person2#는 만약 그들이 복권에 당첨되면 어떻게 지낼 것인지에 대해 이야기하고 있습니다. 그들은 현실로 돌아와 맥주를 마시기로 합니다.', ' #Person1#은 결혼을 두려워하고 에이미를 떠나고 싶어한다. #Person2#은 #Person1#에게 에이미를 떠나지 말고 결혼하라고 말한다. #Person1#은 동의하고 결혼을 시작하기로 한다.', ' #Person1#은 명함을 인쇄하고 싶어합니다. #Person2#은 #Person1#의 이전 명함을 사용하여 명함을 만들 것입니다. #Person1#은 명함을 더 빠르게 원합니다.', ' 브라이언은 회의를 위해 공항으로 데리러 갈 예정입니다. 그는 경영진이 공항에 와서 만나고 회의는 정오에 시작할 것이라고 #Person1#에게 말합니다.', ' 헤이는 폴을 추수감사절 저녁 식사에 초대하지만 폴은 다음 주에 해야 할 일이 많아서 부모님과 함께 가지 않는다. 폴은 파이를 가져오지만 헤이는 여동생이 디저트를 맡았다. 그래서 폴은 좋은 와인 한 병을 가져오기로 결정했다.', ' 존은 수잔에게 그의 사촌을 돌봐달라고 요청한다. 수잔은 그녀를 낮에 돌봐줄 것이다. 그녀는 그녀를 강당에서 음악 축제에 데려갈 것이다. 눈이 오면 수잔은 존에게 전화해서 다른 방법을 찾아볼 것이다.', ' #Person1#은 벤에게 신청한 저녁 수업 정보를 알려줍니다. 그들은 사진, 웹 디자인, 인도 요리 등의 과정을 논의하고 인도 음식 파티를 열기로 결정합니다.', ' #Person1#은 피자 체험, 스테이크하우스, 킹피셔, 캐롯츠 중 어느 것을 먹을지 #Person2#와 함께 논의하고 있습니다.', ' 진은 운전 면허 시험을 볼 예정이며, 그녀는 안전 기능이 있는 차를 사려고 합니다.', ' #Person1#은 펜을 사고 싶어합니다. #Person2#은 #Person1#에게 다른 색의 펜을 보여주고 카드로 결제하는 것을 제안합니다.', ' #Person2#는 #Person1#에게 회사의 기금 모금 행사에 대해 이야기합니다. 그들은 미국 암 협회를 위한 마라톤을 후원하고 수천 달러를 모금했습니다. 이 행사는 회사의 이미지를 향상시키고 작년의 광고 캠페인만큼의 성과를 거두었습니다.', ' #Person2#는 #Person1#에게 피크 트램으로 가는 방법을 알려줍니다. #Person1#는 그 방법을 적기 위해 #Person2#에게 연필을 달라고 합니다.', ' #Person2#는 샌들우드 부채를 사고 싶어합니다. #Person1#는 그것의 가격을 알려줍니다.', ' #Person2#는 회사의 관점에 영향을 미치는 주요 외부 요인과 내부 요인을 소개합니다.', ' #Person1#과 #Person2#는 주제에 대한 준비 회의를 언제 시작하고 작업에 얼마나 많은 시간을 할애해야 할지에 대해 논의하고 있습니다.', ' #Person2#는 짧은 투어를 추천하고 싶어합니다. #Person1#는 자연 풍경을 추천합니다.', ' #Person2#는 #Person1#의 도움으로 바나나 맛의 소고기 버거, 프렌치 프라이, 그리고 밀크 쉐이크를 주문했습니다.', ' #Person1#과 #Person2#는 등 축제에 참가하고 있습니다. 그들은 퍼즐이 적힌 등을 보고 거대한 용 모양의 등을 칭찬합니다. 그들은 거대한 용의 몸통에 적힌 중국 시를 읽습니다.', ' #Person1#은 티나에게 ABC 컴퍼니의 최종 라운드 면접에 성공적으로 통과했다고 알렸다. 그들은 오늘 저녁에 축하 파티를 할 예정이다.', ' 팀과 카렌은 만나서 반가웠지만 늦은 시간 때문에 그들은 다시 만나기로 했다.', ' #Person1#은 #Person2#에게 부서 회의에 필요한 물건들을 어디에서 찾을 수 있는지 알려줍니다. 그들은 그들의 사무실에서 일하는 것을 즐긴다고 말합니다. 그들은 보통 서로 다양한 고객과 잠재적인 고객과의 현재 상황을 서로 알려줍니다.', ' #Person1#은 버튼을 사용하는 방법을 알고 싶어합니다. #Person2#은 #Person1#에게 방에 와서 알려줄 것입니다.', ' #Person2#는 #Person1#에게 기차에서 시간을 보내기 위한 책을 추천해줍니다.', ' #Person1#은 #Person2#에게 친구에게 읽는 법을 가르칠 수 있는지 묻습니다. #Person2#는 동의하고 저녁에 오게 합니다.', ' #Person1#은 티켓을 찾으러 왔습니다. #Person2#은 #Person1#에게 티켓 예약 양식을 작성하고 카드로 결제하라고 요청합니다.', ' #Person1#은 #Person2#와 함께 건강한 음식을 만들어 먹자고 제안하지만, #Person2#는 싸고 편리하며 맛도 괜찮은 냉동 피자를 선호합니다. #Person1#은 그들이 칼라이드 커리를 만들어 먹자고 제안하고, 그들은 재료를 준비하고 칼라이드 커리를 만들기 위한 방법을 알아봅니다.', ' #Person2#는 #Person1#에게 두 대의 전화기를 어떻게 사용하는지 알려줍니다.', ' #Person1#은 돈이 부족해서 중고 컴퓨터를 사려고 합니다. 톰은 중고 물품을 사면서 조심해야 한다고 생각합니다.', ' #Person1#은 중국 사람들이 남은 음식을 집으로 가져가는지 모건에게 묻는다. 모건은 중국의 전통에 따라 사람들이 식당에서 많은 음식을 주문하고 남은 음식을 쓰레기장으로 버린다고 말한다. 그들은 족발을 먹는 것에 대해 이야기하고, #Person1#은 그것을 먹는 것을 괜찮다고 생각한다.', ' 해리는 중국의 거리 시장에서 가방을 사는 경험에 대해 #Person2#에게 이야기합니다. #Person2#는 흥정이 자유 거래의 규칙이라고 생각하며, 고객에게 과다 청구하는 것이 불편하다고 생각합니다. #Person2#는 먼저 슈퍼마켓에서 가격표를 확인하는 것을 추천합니다.', ' #Person1#은 #Person2#에게 회사의 직원들이 영어를 능숙하게 구사해야 한다고 말합니다. #Person2#는 영어를 쓰는 것과 말하는 것 모두에 능숙하다고 생각하며, 다른 언어도 조금 할 줄 알고 있습니다.', ' #Person2#는 새로운 계좌를 개설하고 싶어합니다. #Person1#는 #Person2#에게 신청서를 작성하고 여권을 보여달라고 요청합니다. #Person2#는 초과 인출에 대한 벌금에 대해 묻고, #Person1#는 이율이 낮다고 말합니다. #Person2#는 서류가 괜찮다고 생각합니다.', ' #Person2#는 #Person1#에게 쿠폰을 어떻게 받을 수 있는지, 쿠폰을 어떻게 사용할 수 있는지, 그리고 쿠폰을 어떻게 보유할 수 있는지 알려줍니다.', ' 로빈슨 부인은 스티브에게 쟈니를 돌봐준 것과 부엌을 청소한 것에 대해 감사하다고 말한다.', ' 스미스는 기차표를 잃어버렸고 아내가 그를 절 죽일 것이라고 말합니다. #Person1#은 구매 증거가 없어 스미스가 다시 표를 사야 한다고 말합니다. 스미스는 지갑을 찾고 편안한 좌석을 사기에 충분한 돈이 있습니다. #Person1#은 스미스에게 4마오를 넘어줄 것입니다.', ' 앤은 미국 여행에서 항공 웰빙 프로그램을 해서 시차 적응 문제를 없애고 싶어했다. 그녀는 술과 커피를 마시지 않고, 고기와 기름진 음식을 먹지 않았다. 그녀는 운동을 하고 샴페인을 마셔서 시차 적응을 했다.', ' 메리는 맥도날드에서 일하고 있지만 다른 일을 찾고 싶어한다. 톰은 아버지의 회사에서 일할 사람들이 필요하다고 메리에게 말한다. 메리는 그것을 시도해볼 것이다.', ' 해리는 차에 치일 뻔 했지만 운전자는 사라져 버렸다. #Person1#은 그런 운전자들이 처벌을 받아야 한다고 생각하고, 해리는 앞으로는 신문을 읽으면서 길을 건너지 않을 것이다.', ' 케인씨는 자전거 상점을 인수하고 설립하여 자신의 시간을 자유롭게 지낼 수 있게 되었습니다. 케인씨는 함께 일할 친구들을 고용하고 있습니다.', ' #Person1#은 그들이 중년이라고 생각하지만, #Person2#은 그들이 늙었다고 생각합니다.', ' #Person1#은 #Person2#에게 디저트와 음료를 주문하는 데 도움을 줍니다.', ' #Person1#과 #Person2#는 방에 있는 침대, 스테레오, 책상을 어떻게 배분할지 계획하고 있습니다. 그들은 동전을 던지고 침대를 배분하고, 그 후에 책상을 배분합니다. 그들은 그 후에 상자들을 풀기로 합니다.', ' #Person2#는 머레이 씨에게 도서관 카드를 발급하고 도서관의 규정과 벌금에 대해 설명합니다.', ' #Person2#는 초과근무 수당을 받지 않고 보너스를 받습니다. #Person2#는 한 시간의 휴식 시간을 가지고 있습니다. #Person2#는 서류 작업이 조금 있지만 정보를 컴퓨터에 입력하고 이메일을 통해 서로에게 정보를 보낼 수 있습니다.', ' 닉은 옷을 빨래해 본 적이 없다. 앨리스는 닉이 옷을 빨래하는 방법을 가르친다. 앨리스는 닉이 힘들지만 배워야 한다고 생각한다.', ' #Person1#과 #Person2#는 오늘 밤에 전화하기로 했다.', ' #Person1#은 케이티의 평가서를 살펴보고 있습니다. #Person1#은 케이티가 항상 일할 준비가 되어 있지만 늦게 도착하고 고객이 없을 때는 멍하니 서 있다고 말합니다.', ' #Person1#과 #Person2#는 다음 주에 할아버지의 생일 파티를 계획하고 있습니다. 그들은 파티를 어떻게 하고 샐러드, 책, 그리고 목도리를 선물로 준비할 것입니다. 그들은 파티를 토요일에 계획하고 있습니다.', ' 지안 루카 도나텔리와 지나는 서로 자기 소개를 합니다. 지안은 지나에게 로버트를 소개하고 그들은 서로 일하는 장소에 대해 이야기합니다.', ' 캐시는 시골의 새들이 시끄러워서 끔찍하다고 생각한다. #Person2#는 새들이 여름 내내 그런 소리를 내지 않고, 그들은 대부분 나무 위에 있다고 말한다. 캐시는 이런 소리를 캘리포니아에서 듣지 못했다고 말한다.', ' 대니스는 칠면조 샌드위치, 채소가 들어간 소고기 스프, 다이어트 콜라를 주문하고 거스름돈을 받습니다.', ' 제임스는 기차를 타기 위해 짐을 싸고 있다. #Person1#은 제임스에게 데이비드에게 빌려준 재킷과 쿠키를 가져가라고 말한다. 데이비드는 약 10분 후에 도착할 예정이다.', ' 테드는 아내와 함께 휴가를 보내고 싶지 않고, #Person1#은 중국에서 몇 주를 보낼 예정이다.', ' #Person1#은 오후에 영화관에 가고 싶어하고, #Person2#는 그것이 좋아 보인다. 그들은 그 후에 맥도날드에 가서 맛있는 음식을 즐기기로 했다.', ' #Person2#의 집이 털렸고 도둑들이 #Person2#의 가구를 훔쳤습니다. #Person2#는 경찰에 전화했습니다.', ' 잭은 찰리에게 새 비디오 게임을 하자고 초대한다. 찰리는 숙제을 끝내고 잭의 집으로 갈 것이다.', ' #Person2#는 아내와 함께 레코드 플레이어를 구입하고 그 후 컨트리 음악에 관심을 가지게 되었습니다. #Person2#는 라디오 프로그램을 시작하고 노래들의 배경을 설명하는 기사를 쓰는 데 지쳤습니다.', ' 앨리스는 #Person1#에게 세탁기와 건조기를 어떻게 사용하는지 알려줍니다. #Person1#은 옷을 빨아본 적이 없습니다. 앨리스는 미국 아이들이 더 독립적이라고 생각하지만, #Person1#은 캠퍼스에서 어떻게 살 것인지 모르고 있습니다.', ' 매튜와 스티브는 오랜만에 만났다. 스티브는 집을 찾고 있고 매튜는 다우 부인의 아파트를 추천한다. 매튜는 다우 부인에게 언제 아파트를 보여줄 수 있는지 물어보고 스티브에게 알려줄 것이다.', ' 프랭크는 벳시에게 승진을 알리고 그의 파티에 볼 수 있는 사람들을 묻습니다. 벳시는 그 파티가 기대되는 것 같습니다.']\n"
     ]
    }
   ],
   "source": [
    "print(fname_list)\n",
    "print(summary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>실장님은 더슨 씨에게 내부 및 외부 통신에 적용되는 새로운 정책을 메모로 전달하도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>#Person2#는 교통 체증에 걸렸고 자유를 즐기기 위해 자동차를 운전하고 있습...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>#Person1#은 케이트에게 마샤와 히어로가 이혼하고 있다고 말한다. 케이트는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>#Person1#은 브라이언의 생일을 축하하고 그와 춤을 추고 싶어한다. 그들은 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>#Person1#과 #Person2#는 올림픽 스타디움에 있습니다. #Person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>test_495</td>\n",
       "      <td>잭은 찰리에게 새 비디오 게임을 하자고 초대한다. 찰리는 숙제을 끝내고 잭의 집으...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>test_496</td>\n",
       "      <td>#Person2#는 아내와 함께 레코드 플레이어를 구입하고 그 후 컨트리 음악에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>test_497</td>\n",
       "      <td>앨리스는 #Person1#에게 세탁기와 건조기를 어떻게 사용하는지 알려줍니다. #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>test_498</td>\n",
       "      <td>매튜와 스티브는 오랜만에 만났다. 스티브는 집을 찾고 있고 매튜는 다우 부인의 아...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>test_499</td>\n",
       "      <td>프랭크는 벳시에게 승진을 알리고 그의 파티에 볼 수 있는 사람들을 묻습니다. 벳시...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fname                                            summary\n",
       "0      test_0   실장님은 더슨 씨에게 내부 및 외부 통신에 적용되는 새로운 정책을 메모로 전달하도...\n",
       "1      test_1   #Person2#는 교통 체증에 걸렸고 자유를 즐기기 위해 자동차를 운전하고 있습...\n",
       "2      test_2   #Person1#은 케이트에게 마샤와 히어로가 이혼하고 있다고 말한다. 케이트는 ...\n",
       "3      test_3   #Person1#은 브라이언의 생일을 축하하고 그와 춤을 추고 싶어한다. 그들은 ...\n",
       "4      test_4   #Person1#과 #Person2#는 올림픽 스타디움에 있습니다. #Person...\n",
       "..        ...                                                ...\n",
       "494  test_495   잭은 찰리에게 새 비디오 게임을 하자고 초대한다. 찰리는 숙제을 끝내고 잭의 집으...\n",
       "495  test_496   #Person2#는 아내와 함께 레코드 플레이어를 구입하고 그 후 컨트리 음악에 ...\n",
       "496  test_497   앨리스는 #Person1#에게 세탁기와 건조기를 어떻게 사용하는지 알려줍니다. #...\n",
       "497  test_498   매튜와 스티브는 오랜만에 만났다. 스티브는 집을 찾고 있고 매튜는 다우 부인의 아...\n",
       "498  test_499   프랭크는 벳시에게 승진을 알리고 그의 파티에 볼 수 있는 사람들을 묻습니다. 벳시...\n",
       "\n",
       "[499 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'fname': fname_list,\n",
    "    'summary': summary_list,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../prediction/output.csv', encoding='utf-8-sig', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
